Below is the contents of some of the files in this project/repo.

stamp
 AbstractParticle.browser.ts
  let _scrollsdkLatestTime = 0
  let _scrollsdkMinTimeIncrement = 0.000000000001
  abstract class AbstractParticle {
    protected _getProcessTimeInMilliseconds() {
      // We add this loop to restore monotonically increasing .now():
      // https://developer.mozilla.org/en-US/docs/Web/API/Performance/now
      let time = performance.now()
      while (time 
    
    
      
      
        main
        yo
      
      
        footer
        hi
      
    
  
  `
  
  testStrings.fromXmlParticles = `html
   class main
   subparticles
    head
    body
     style color: red;
     subparticles
      div
       class main
       subparticles
        0 Hello world`
  
  testStrings.fromXml = `
    
    
      Hello world
    
  
  `
  
  testStrings.fromDelimited = `foodName^weight^Pri
  ~Apple~^2.2^1
  ~Banana~^3.2^1`
  
  testStrings.splitTest = `
  thisWillBe ignored
  title This is a test
  content Hello world
  date 2/25/2014
  title This is not a test
  content Hello planet
  date 2/25/2015
  title This is definitely a test
  content Hello earth
  date 2/25/2016
  `
  
  testStrings.delimited = `0
   id 1
   title Some book
   summary An expose, on the result of one "plus" one
  1
   id 2
   title The answer, my friend, is...
   summary "Two"`
  
  testStrings.renameTest = `title b on GitHub
  description
  hideLabels true
  public true
  arrangeables stargazers_count created_at forks_count open_issues_count language
  aliases
   stargazers_count Stars
   created_at Created
   forks_count Forks
   language Language
   open_issues_count Issues
  formats
   stargazers_count 0a
  types
   language string
   created_at date
  x language
  y stargazers_counter
  `
  
  testStrings.csv = `id,title,summary
  1,Some book,"An expose, on the result of one ""plus"" one"
  2,"The answer, my friend, is...","""Two"""`
  
  testStrings.csvNoHeaders = `bob,12,red
  mike,321,blue
  al,1214,green`
  
  testStrings.toTableLeft = `name score color
  bob  12    red  
  mike 321   blue 
  al   1214  green`
  
  testStrings.toTable = `name score color
   bob    12   red
  mike   321  blue
    al  1214 green`
  
  testStrings.ssv = `id title summary
  1 "Some book" "An expose, on the result of one ""plus"" one"
  2 "The answer, my friend, is..." """Two"""`
  
  testStrings.ssvFixedColumnComment1 = "This is some comment with particles"
  testStrings.ssvFixedColumnComment2 = "Each row should be capped to 2 columns"
  testStrings.ssvFixedColumns = `id comment
  123 ${testStrings.ssvFixedColumnComment1}
  456 ${testStrings.ssvFixedColumnComment2}
  `
  
  testStrings.ssvMissingColumns = `state abbreviation population
  california ca 35000000
  texas tx
  washington wa 6000000`
  
  testStrings.renameParticlesBy = `
  0
   name John Doe
   email johndoe@email.com
  1
   name Mary Jane
   email maryjane@email.com
  `
  
  testStrings.newLines = `
  particle
   palm
    green true
  
    location Cali
   pine
  
    location Maine
  bush foo
  `
  
  testStrings.tsv = `id\ttitle\tsummary
  1\tSome book\t\"An expose, on the result of one \"\"plus\"\" one\"
  2\tThe answer, my friend, is...\t\"\"\"Two\"\"\"`
  
  testObjects.tsv = {
    firstName: "John",
    lastName: "Smith",
    isAlive: true,
    lowScore: 0,
    lowestScore: -10,
    age: 25,
    height_cm: 167.6,
    numbers: [12, 132.2, 312, true, null, false, {}, ""],
    address: {
      streetAddress: "21 2nd Street",
      city: "New York",
      state: "NY",
      postalCode: "10021-3100",
      blankString: ""
    },
    phoneNumbers: [
      {
        type: "home",
        number: "212 555-1234"
      },
      {
        type: "office",
        number: "646 555-4567"
      }
    ],
    spouse: null
  }
  
  testParticles.constructorTests = equal => {
    // Assert
    equal(!!Particle, true, "Particle class should exist")
    equal(new Particle() instanceof Particle, true, "Particle should return a particle")
  
    // Arrange/Act
    const particle = new Particle("hello world")
  
    // Assert
    equal(particle.length, 1, "types array should have 1 property")
    equal(particle.indexOf("hello"), 0, "types array should be correct")
    equal(particle.getParticle("hello").content, "world", "Properties should be accessible")
    equal(typeof particle.getParticle("hello").content, "string", "Leafs should be strings")
  
    // Act
    particle.touchParticle("foo").setContent("bar")
  
    // Assert
    equal(particle.getParticle("foo").content, "bar", "Particles should be modifiable")
  
    // Arrange
    const particle2 = new Particle("foobar\n one 1")
  
    // Assert
    equal(particle2.getParticle("foobar").content, undefined, "Value should be empty")
    equal(particle2.getParticle("foobar").getParticle("one").content, "1", "Value should be 1")
  
    equal(typeof particle2.getParticle("foobar"), "object", "Particles should be objects")
    equal(particle2.getParticle("foobar") instanceof Particle, true, "Nested particles should be particles")
  
    // Arrange
    const particle3 = new Particle("list\nsingle value")
  
    // Assert
    equal(particle3.length, 2, "Particle should have 2 names")
    equal(particle3.getParticle("list").length, 0, "A name without a trailing particle should be length 0")
  
    // Arrange
    const particle4 = new Particle("body")
  
    // Assert
    equal(particle4.getParticle("body").length, 0, "A name without a trailing particle should be a particle")
  
    // Arrange
    const particle5 = new Particle({
      foobar: "hello"
    })
  
    // Assert
    equal(particle5.getParticle("foobar").content, "hello", "Particles can be created from object literals")
  
    // Arrange
    const particle6 = new Particle({
      foobar: new Particle("hello world")
    })
  
    // Assert
    equal(particle6.getParticle("foobar hello").content, "world", "Particles can be created from objects mixed with particles")
  
    // Arrange
    const particle7 = new Particle({
      foobar: {
        hello: {
          world: "success"
        }
      }
    })
  
    // Assert
    equal(particle7.getParticle("foobar hello world").content, "success", "Particles can be created from deep objects")
  }
  
  testParticles.multlineConstructorTests = equal => {
    // Arrange
    const particleString = `user
  name Aristotle
  admin false
  stage
  name home
  domain test.test.com
  pro false
  domains
   test.test.com
    images
    blocks
    users
    stage home
    pages
     home
      settings
       data
        title Hello, World
      block1
       content Hello world`
    const particle8 = new Particle(particleString)
  
    // Assert
    equal(particle8.topDownArray.length, 20)
    equal(particle8.numberOfLines, 20)
    equal(particle8.numberOfAtoms, 30)
    equal(particle8.getParticle("domains test.test.com pages home settings data title").content, "Hello, World", "Multiline creation should be okay.")
  
    // Arrange
    const emptyArray = { post: { kind: {}, age: 100 } }
    const expectedStr = `post
   kind
   age 100`
    // Act
    const particle10 = new Particle(emptyArray)
    // Assert
    equal(particle10.asString, expectedStr)
  
    // Arrange
    const particle = new Particle(" ").particleAt(0)
  
    // Act/Assert
    equal(particle.cue, "")
    equal(particle.content, "")
  
    // Arrange
    const spaceChar = " "
    let s = `
  ${spaceChar}
  ${spaceChar}
  ${spaceChar}`
    // Act/Assert
    equal(new Particle(s).particleAt(0).length, 3)
  
    // Arrange
    s = `
  ${spaceChar}${spaceChar}
  ${spaceChar}`
    // Act/Assert
    equal(new Particle(s).particleAt(0).length, 2)
  }
  
  testParticles.ambiguityFixWhenAssignmentAndEdgeCharsMatch = equal => {
    // Arrange
    let test = `
   :
   :`
    // Act/Assert
    class TestParticles extends Particle {
      get atomBreakSymbol() {
        return ":"
      }
    }
    const iHateTypeScriptSometimes = TestParticles
  
    equal(new iHateTypeScriptSometimes(test).particleAt(0).length, 2)
  
    const rootParticle = new iHateTypeScriptSometimes()
    const particle = rootParticle.appendLineAndSubparticles("", new iHateTypeScriptSometimes())
    particle.appendLine("")
    particle.appendLine("")
    const newParticle = new iHateTypeScriptSometimes(rootParticle.asString)
    equal(newParticle.particleAt(0).length, 2)
  }
  
  testParticles.duplicateReferences = equal => {
    // Arrange
    let b = ["abc"]
    let a = {
      one: b,
      two: b
    }
  
    // Act/Assert
    equal(new Particle(a).get("two 0"), "abc")
  
    // Arrange
    let boo = { foo: "bar" }
    let abc = {
      one: boo,
      two: boo
    }
  
    // Act/Assert
    equal(new Particle(abc).get("two foo"), "bar")
  }
  
  testParticles.append = equal => {
    // Arrange
    const particle = new Particle("hello world")
  
    // Act
    particle.appendLine("foo bar")
    particle.touchParticle("foo2").setContent("bar")
  
    // Assert
    equal(particle.getParticle("foo").content, "bar")
  
    // Act
    particle.appendLine("foo two")
  
    // Assert
    equal(particle.length, 4)
  }
  
  testParticles.deleteBlanks = equal => {
    // AAA
    equal(new Particle("hello world\n\n\nhelmet\nthe").deleteBlanks().length, 3)
  }
  
  testParticles.getParticlesByRegex = equal => {
    // AAA
    equal(new Particle("hello world\nhelmet\nthe").getParticlesByRegex(/^he/).length, 2)
  }
  
  testParticles.getAtom = equal => {
    // Arrange
    const particle = new Particle("a b c")
    const aParticle = particle.getParticle("a")
  
    // Act/Assert
    equal(aParticle.getAtom(1), "b")
    equal(aParticle.getAtom(-1), "c")
  }
  
  testParticles.getOneOf = equal => {
    // Arrange
    const particle = new Particle(`tint blue\nColor red`)
  
    // Act/Assert
    equal(particle.getOneOf(["Color", "tint"]), "red")
    equal(particle.getOneOf(["tint", "Color"]), "blue")
    equal(particle.getOneOf(["height"]), "")
  }
  
  testParticles.pick = equal => {
    // Arrange
    const particle = new Particle(`tint blue\nColor red`)
  
    // Act/Assert
    equal(particle.pick(["Color", "tint"]).asString, `tint blue\nColor red`)
    equal(particle.getOneOf(["height"]).toString(), "")
  }
  
  testParticles.setProperties = equal => {
    // Arrange
    const particle = new Particle(``)
    particle.setProperties({ foo: "bar", one: "2" })
  
    // Act/Assert
    equal(particle.get("one"), "2")
  }
  
  testParticles.setPropertyIfMissing = equal => {
    // Arrange
    const particle = new Particle(``)
    particle.setProperties({ foo: "bar", one: "2" })
    particle.setPropertyIfMissing("one", "3")
    particle.setPropertyIfMissing("two", "a")
  
    // Act/Assert
    equal(particle.get("one"), "2")
    equal(particle.get("two"), "a")
  }
  
  testParticles.setAtoms = equal => {
    // Arrange
    const particle = new Particle("a b c")
    const aParticle = particle.getParticle("a")
  
    // Act/Assert
    equal(aParticle.appendAtom("d").asString, "a b c d")
    equal(aParticle.setAtoms(["f", "g"]).asString, "f g")
    equal(aParticle.setAtomsFrom(1, ["h", "i"]).asString, "f h i")
    equal(aParticle.deleteAtomAt(2).asString, "f h")
  }
  
  testParticles.at = equal => {
    // Arrange
    const value = new Particle("hello world\nhow are you\nhola friend")
  
    // Assert
    equal(value.particleAt(0).content, "world")
    equal(value.particleAt(1).content, "are you")
    equal(value.particleAt(2).content, "friend")
    equal(value.particleAt(3), undefined)
    equal(value.particleAt(-1).content, "friend")
  }
  
  testParticles.getAtomBoundaryCharIndices = equal => {
    // Arrange
    const particle = new Particle(`
  a
  web 25 zzzz OK
   notes No notes`)
  
    // Act
    const boundaries = particle.getAllAtomBoundaryCoordinates()
  
    // Assert
    equal(boundaries.length, 9)
  }
  
  testParticles.toDelimited = equal => {
    const test = `name|example
  python|"Hello world"`
    const particle = Particle.fromDelimited(test, "|", "'")
  
    // Act/Assert
    equal(particle.toDelimited("|", undefined, false), test)
  }
  
  testParticles.fill = equal => {
    Object.keys(testStrings).forEach(key => {
      // Arrange
      const particle = new Particle(testStrings[key])
      const filledParticle = particle.clone().fill("x")
      // Act/Assert
      equal(particle.length, filledParticle.length)
      equal(particle.numberOfLines, filledParticle.numberOfLines)
      equal(particle.numberOfAtoms, filledParticle.numberOfAtoms)
    })
  }
  
  testParticles.getAtomProperties = equal => {
    // Arrange
    const particle = new Particle(`
  a
  web 25 zzzz OK
   notes No notes`)
  
    // Act/Assert
    const props = particle.particleAtLine(3).getAtomProperties(2)
    equal(props.startCharIndex, 10)
    equal(props.endCharIndex, 15)
  }
  
  testParticles.getAtomIndexAtCharacterIndex = equal => {
    // Arrange
    const particle = new Particle(`
  a
  web 25 zzzz OK
   notes No notes`)
    const tests = `0
  00
  000011122222333
   000000111222222`
  
    // Act/Assert
    const lineParticles = particle.topDownArray
    tests.split("\n").forEach((testLine, lineIndex) => {
      const particle = lineParticles[lineIndex]
      testLine.split("").forEach((char, charIndex) => {
        if (char !== " ") equal(particle.getAtomIndexAtCharacterIndex(charIndex), parseInt(char), `Character is '${char}'`)
      })
    })
  
    // Arrange
    const nested = new Particle(`a
   b
    c
     d`)
  
    // Act/Assert
    equal(nested.getParticle("a b").getAtomIndexAtCharacterIndex(0), -1)
  }
  
  testParticles.clone = equal => {
    // Arrange/Act
    const a = new Particle("hello world")
    const b = a.clone()
  
    // Assert
    equal(b.getParticle("hello").content, "world")
    equal(a.asString, b.asString, "string unchanged")
  
    // Act
    b.touchParticle("hello").setContent("mom")
  
    // Assert
    equal(a.getParticle("hello").content, "world")
  
    // Arrange
    const c = a
  
    // Assert
    equal(c.getParticle("hello").content, "world")
  
    // Act
    c.touchParticle("hello").setContent("foo")
  
    // Assert
    equal(a.getParticle("hello").content, "foo")
  
    // Arrange
    const d = c
  
    // Assert
    equal(d.getParticle("hello").content, "foo", "foo should be value")
  
    // Act
    d.touchParticle("hello").setContent("hiya")
  
    // Assert
    equal(a.getParticle("hello").content, "hiya", "original unchanged")
  
    // Act
    a.touchParticle("test").setContent("boom")
  
    // Assert
    equal(d.getParticle("test").content, "boom")
  
    // Act
    a.touchParticle("foobar").setSubparticles(new Particle("123 456"))
  
    // Assert
    equal(c.getParticle("foobar 123").content, "456", "expected 456")
  
    // Arrange
    const e = a
  
    // Assert
    equal(e.getParticle("foobar 123").content, "456")
  
    // Arrange
    const f: any = a.clone()
  
    // Assert
    equal(f.getParticle("foobar 123").content, "456")
  
    // Act
    f.hi = "test"
  
    // Assert
    equal((a).hi, undefined)
  }
  
  testParticles.concat = equal => {
    // Arrange
    const a = new Particle("hello world")
    const b = new Particle("hi mom")
  
    // Act
    const newParticles = a.concat(b)
  
    // Assert
    equal(a.getParticle("hi").content, "mom")
    equal(newParticles.length, 1)
  }
  
  testParticles.getParticlesByGlobPath = equal => {
    // Arrange/Act/Assert
    equal(new Particle(testStrings.webpage).getParticlesByGlobPath("* div").length, 5)
    equal(new Particle(testStrings.webpage).getParticlesByGlobPath("*").length, new Particle(testStrings.webpage).length)
    equal(new Particle(testStrings.webpage).getParticlesByGlobPath("body div class").length, 2)
  }
  
  testParticles.particlesThatStartWith = equal => {
    equal(new Particle(testStrings.webpage).particlesThatStartWith("body")[0].particlesThatStartWith("div").length, 5)
  }
  
  testParticles.getParticleByColumns = equal => {
    // Arrange
    const test = new Particle(testStrings.sortByMultiple)
  
    // Act
    const particle = test.getParticleByColumns("name", "Success")
  
    // Assert
    equal(particle.parent.get("key"), "b")
  }
  
  testParticles.delete = equal => {
    // Arrange
    const particle = new Particle()
    particle.touchParticle("name").setContent("Breck")
  
    // Assert
    equal(particle.getParticle("name").content, "Breck", "name is set")
    equal(particle.length, 1, "length okay")
    equal(particle.getFirstParticle().content, "Breck")
  
    // Act
    particle.delete("name")
  
    // Assert
    equal(particle.getParticle("name"), undefined, "name is gone")
    equal(particle.length, 0, "length okay")
  
    // Act
    particle.touchParticle("name").setContent("Breck")
    particle.touchParticle("age").setContent("100")
    particle.touchParticle("table").setContent("true")
    particle.delete("age")
  
    // Assert
    equal(particle.getParticle("age"), undefined, "age is gone")
    equal(particle.length, 2, "expected 2 elements remaining")
  
    // Test deep delete
    // Arrange
    const particle2 = new Particle()
    particle2.touchParticle("earth north_america united_states california san_francisco").setContent("mission")
  
    // Assert
    equal(particle2.getParticle("earth north_america united_states california") instanceof Particle, true, "particle exists")
    equal(particle2.getParticle("earth north_america united_states california san_francisco").content, "mission", "neighborhood is set")
    equal(particle2.getParticle("earth north_america united_states california").length, 1, "length okay")
    equal(particle2.length, 1, "length okay")
  
    // Act
    const deleteResult = particle2.delete("earth north_america united_states california san_francisco")
  
    // Assert
    equal(deleteResult instanceof Particle, true, "returns particle")
    equal(particle2.getParticle("earth north_america united_states california san_francisco"), undefined, "neighborhood is gone")
  
    // Test deleting a non-existant property
    // Arrange
    const particle3 = new Particle("property meta\n")
  
    // Act
    particle3.delete("content")
  
    // Assert
    equal(particle3.getParticle("property").content, "meta", "delete a non existing entry works")
  
    // Delete a property that has multiple matches
    // Arrange
    const particle4 = new Particle("time 123\ntime 456")
  
    // Assert
    equal(particle4.length, 2)
  
    // Act
    particle4.delete("time")
  
    // Assert
    equal(particle4.length, 0)
  
    // Arrange
    const blankTest = `presidents
   class President
  other`
    const particle6 = new Particle(blankTest)
  
    // Act
    particle6.forEach((particle: particlesTypes.particle) => {
      if (!particle.cue.startsWith("p")) return true
      particle.setContent("President")
      particle.delete("class")
    })
  
    // Assert
    equal(
      particle6.asString,
      `presidents President
  other`
    )
  }
  
  testParticles.deleteRegression = equal => {
    // Arrange
    const test = `data
   row
    time 2015/01/02 09:00:00
    count 1
   row
    time 2015/01/02 10:00:00
    count 3
   row
    time 2015/01/02 12:00:00
    count 2
   row
    time 2015/01/02 13:00:00
    count 2
   row
    time 2015/01/02 21:00:00
    count 3
   row
    time 2015/01/02 23:00:00
    count 1
   row
    time 2015/01/03 00:00:00
    count 2
   row
    time 2015/01/03 08:00:00
    count 2
   row
    time 2015/01/16 04:00:00
    count 2
   row
    time 2015/01/16 14:00:00
    count 2
   row
    time 2015/01/16 15:00:00
    count 1
   row
    time 2015/01/16 17:00:00
    count 1`
  
    // Act
    const migrateFn = (str: string) => {
      const board = new Particle(str)
      const dataParticles = board.findParticles("data")
      dataParticles.forEach((particle: particlesTypes.particle) => {
        const rows = particle.findParticles("row")
        if (!rows.length) return
        const mapped = rows.map((row: particlesTypes.particle) => row.toObject())
        const csv = new Particle(mapped).asCsv
        particle.touchParticle("format").setContent("csv")
        particle.touchParticle("content").setContentWithSubparticles(csv)
        particle.delete("row")
      })
      return board.asString
    }
    const result = new Particle(migrateFn(test)).getParticle("data")
  
    // Assert
    equal(result.findParticles("row").length, 0)
  }
  
  testParticles.destroy = equal => {
    const template = `hey ho
  hi
   hello world
  yo hey`
    // Arrange
    const particle = new Particle(template)
  
    // Act
    particle.particleAt(1).destroy()
  
    // Assert
    equal(particle.asString, "hey ho\nyo hey")
  }
  
  testParticles.duplicateProperties = equal => {
    // Arrange
    const particle = new Particle("time 123\ntime 456")
  
    // Assert
    equal(particle.length, 2)
    equal(particle.asString, "time 123\ntime 456")
  }
  
  testParticles.duplicate = equal => {
    // Arrange
    const particle = new Particle(testStrings.fromXmlParticles)
    const lineCount = particle.asString.split(/\n/).length
    const particle2 = particle.getParticle("html")
  
    // Act
    particle2.duplicate()
  
    // Assert
    equal(particle.asString.split(/\n/).length, lineCount * 2)
  }
  
  testParticles.forEach = equal => {
    // Arrange
    const value = new Particle("hello world\nhi mom")
    var count = 0
    var result = ""
  
    // Act
    value.forEach(function (particle: particlesTypes.particle) {
      const property = particle.cue
      const v = particle.content
      result += property.toUpperCase()
      result += v.toUpperCase()
      result += value.length
    })
  
    // Assert
    equal(value.length, 2, "test chaining")
    equal(result, "HELLOWORLD2HIMOM2")
  
    // Test that returning false breaks out of each
    // Arrange
    const value2 = new Particle("hello world\nhi mom")
  
    // Act
    value2
      .filter((particle: particlesTypes.particle) => particle.cue !== "hello")
      .forEach((particle: particlesTypes.particle) => {
        const property = particle.cue
        const value = particle.content
        count++
      })
    // Assert
    equal(count, 1)
  
    // Arrange
    const particle = new Particle("hello world\nhi world")
    var inc = 0
  
    // Act
    particle.forEach((particle: particlesTypes.particle, index: number) => {
      inc = inc + index
    })
  
    // Assert
    equal(inc, 1, "index worked")
  }
  
  testParticles.every = equal => {
    // Arrange/Act/Assert
    equal(
      new Particle(`a 2\nb 2\nc 2`).every((particle: particlesTypes.particle) => particle.getAtom(1) === "2"),
      true
    )
  }
  
  testParticles.extend = equal => {
    // Arrange
    const sourceStr = `name Jane
  color blue`
    const destinationStr = `username jane`
    const source = new Particle(sourceStr)
    const destination = new Particle(destinationStr)
    // Act
    destination.extend(source)
    // Assert
    equal(destination.asString, [destinationStr, sourceStr].join("\n"))
  
    // Test deep
    const original = { person: "Abe", age: "24", items: { car: "blue" } }
    const extension = { person: "Joe", weight: 100, items: { car: "red", foo: "bar" } }
  
    // Act
    const particle = new Particle(original).extend(extension)
    const result = particle.toObject()
  
    // Assert
    equal(result.person, "Joe")
    equal(result.age, "24")
    equal(result.weight, "100")
    equal(result.items.car, "red", "expected deep to work")
    equal(result.items.foo, "bar")
    equal(particle.getParticle("items").length, 2)
  
    // Arrange
    const test = `>foo
   class main`
    const web = `>foo
   >bar
    >bam
     class boom
     ham
      hoom
      vroom`
    // Act
    const extended = new Particle(test).extend(web)
  
    // Assert
    equal(extended.getParticle(">foo >bar >bam class").content, "boom")
  }
  
  testParticles.first = equal => {
    // Arrange
    const value = new Particle("hello world\nhi mom")
  
    // Assert
    equal(value.particleAt(0).content, "world")
  
    // Arrange
    const value2 = new Particle("hello world\nhi mom")
  
    // Assert
    equal(value2.particleAt(0).asString, "hello world")
  }
  
  testParticles.firstProperty = equal => {
    // Arrange
    const value = new Particle("hello world\nhi mom")
  
    // Assert
    equal(value.particleAt(0).cue, "hello")
  }
  
  testParticles.hasDuplicates = equal => {
    // Arrange/Act/Assert
    equal(new Particle(testStrings.sortByMultiple).hasDuplicateCues(), true)
    equal(new Particle().hasDuplicateCues(), false, "empty")
    equal(new Particle("a\na").hasDuplicateCues(), true)
    equal(new Particle("a\n a\n b").particleAt(0).hasDuplicateCues(), false)
    equal(new Particle("a\n b\n b").particleAt(0).hasDuplicateCues(), true)
  }
  
  testParticles.toYaml = equal => {
    // Arrange/Act/Assert
    equal(new Particle(testStrings.lime).asYaml, testStrings.limeToYaml)
  }
  
  testParticles.asGridJson = equal => {
    // Arrange/Act/Assert
    const tests = Object.keys(testStrings).forEach(key => {
      const program = testStrings[key]
      const serialized = new Particle(program).asGridJson
      equal(Particle.fromGridJson(serialized).asString, program)
    })
  }
  
  testParticles.toJson = equal => {
    // Arrange/Act/Assert
    const tests = Object.keys(testStrings).forEach(key => {
      const program = testStrings[key]
      const serialized = new Particle(program).asJson
      equal(Particle.fromJson(serialized).asString, program)
    })
  }
  
  testParticles.firstValue = equal => {
    // Arrange
    const value = new Particle("hello world\nhi mom")
  
    // Assert
    equal(value.particleAt(0).content, "world")
  }
  
  testParticles.toggleLine = equal => {
    // Arrange
    const particle = new Particle("chart").particleAt(0)
    equal(particle.has("hidden"), false)
  
    // Act
    particle.toggleLine("hidden")
  
    // Assert
    equal(particle.hasLine("hidden"), true)
    equal(particle.has("hidden"), true)
  
    // Act
    particle.toggleLine("hidden")
  
    // Assert
    equal(particle.hasLine("hidden"), false)
    equal(particle.has("hidden"), false)
  }
  
  testParticles.pasteText = equal => {
    // Arrange
    const particle = new Particle(`a
   b`)
    // Act
    particle.getParticle("a b").pasteText(`foo
   bar`)
    // Assert
    equal(
      particle.asString,
      `a
   foo
    bar`
    )
  }
  
  testParticles.templateToString = equal => {
    // Arrange
    const templateString = new Particle(`html
   head
    title {title}
    style {height} {width}
   body
    {elements}`)
    // Act
    const str = templateString.templateToString({
      title: "Hello world",
      height: "10",
      width: "20",
      elements: `h1 header
  h2 subheader
  div
   div Some text`
    })
    // Assert
    const expected = `html
   head
    title Hello world
    style 10 20
   body
    h1 header
    h2 subheader
    div
     div Some text`
    equal(str, expected, "templateToString works")
  
    // Act
    try {
      templateString.templateToString({})
      equal(false, true, "template strings currently require all params. should have thrown.")
    } catch (err) {
      equal(true, true, "error caught")
    }
  
    // Act
    let str2 = templateString.templateToString({ title: "", height: "", width: "", elements: "" })
    equal(
      str2,
      `html
   head
    title 
    style  
   body
    `,
      "blanks work"
    )
  }
  
  testParticles.patch = equal => {
    // Arrange
    const one = new Particle(`name Git
  appeared 2012`)
    const two = new Particle(`name Git
  creators Linus Torvalds
  appeared 2005`)
  
    // Act
    const three = one.patch(two)
  
    // Assert
    equal(three.get("appeared"), "2005")
    equal(three.get("creators"), "Linus Torvalds")
  }
  
  testParticles.evalTemplateString = equal => {
    // Arrange
    const templateString = "Hi {firstName} {lastName}! I hope you are enjoying the weather in {address city}!"
    const person = new Particle("firstName Tom\nlastName B\naddress\n city Boston")
  
    // Act
    const result = person.evalTemplateString(templateString)
  
    // Assert
    equal(result, "Hi Tom B! I hope you are enjoying the weather in Boston!")
  }
  
  testParticles.fromCsv = equal => {
    // Arrange/Act
    const particle = Particle.fromCsv(testStrings.csv)
    const withQuotes = Particle.fromCsv('"Date","Age"\n"123","345"')
  
    // Assert
    equal(particle.asString, testStrings.delimited)
    equal(particle.length, 2, "expected 2 rows")
    equal(particle.asCsv, testStrings.csv, "Expected toCsv to output same data as fromCsv")
  
    // Arrange
    const particle2 = Particle.fromCsv("Age,Birth Place,Country\n12,Brockton,USA")
  
    // Assert
    equal(particle2.length, 1)
    equal(particle2.particleAt(0).getParticle("Country").content, "USA")
  
    // Arrange
    const particle3 = Particle.fromCsv("")
  
    // Assert
    equal(particle3.asString, "", "Expected empty string to be handled correctly")
  
    // Assert
    equal(withQuotes.getParticle("0 Date").content, "123", "Expected quotes to be handled properly")
  
    // Arrange
    const particle4 = Particle.fromCsv('height\n"32,323"')
  
    // Assert
    equal(particle4.getParticle("0 height").content, "32,323")
  
    // Test quote escaping
    // Arrange
    const csvWithQuotes = 'name,favoriteChar\nbob,"""."'
  
    // Act
    const particle5 = Particle.fromCsv(csvWithQuotes)
  
    // Assert
    equal(particle5.asString, '0\n name bob\n favoriteChar ".', "Four double quotes should return one double quote")
  
    // Test \r characters
    // Arrange
    const csv = "name,age\r\njoe,21\r\nbill,32\r\n"
  
    // Act
    const testCase = Particle.fromCsv(csv.replace(/\r/g, ""))
  
    // Assert
    equal(testCase.getParticle("1 age").content, "32", "Expected return chars to be removed")
  
    // Act
    testCase.getParticle("1").delete("name")
  
    // Assert
    equal(testCase.getParticle("0").subparticlesToString(), "name joe\nage 21", "property change should not affect other objects")
    equal(testCase.getParticle("1 name"), undefined, "property should be gone")
  }
  
  testParticles.fromCsvNoHeaders = equal => {
    // Arrange
    const a = Particle.fromDelimitedNoHeaders(testStrings.csvNoHeaders, ",", '"')
  
    // Assert
    equal(a.length, 3)
    equal(a.getParticle("1 2").content, "blue")
  }
  
  testParticles.fromDelimited = equal => {
    // Arrange
    const a = Particle.fromDelimited(testStrings.fromDelimited, "^", "~")
  
    // Assert
    equal(a.length, 2)
    equal(a.getParticle("0 weight").content, "2.2")
    equal(a.getParticle("1 foodName").content, "Banana")
  
    // Arrange
    const b = Particle.fromDelimited(
      `name,score
  
  joe,23`,
      ",",
      '"'
    )
  
    // Assert
  }
  
  testParticles.fromDelimitedWindowsLineEndings = equal => {
    // Arrange
    const str = "A,B\n1,3"
    const str2 = "A,B\n\r1,3"
    // Act
    const result = Particle.fromCsv(str)
    const result2 = Particle.fromCsv(str2)
  
    // Assert
    equal(result.get("0 B"), "3")
    equal(result2.get("0 B"), "3")
  }
  
  testParticles.siblingsWithClone = equal => {
    // Arrange
    const test = new Particle(`a
  b
  c`)
  
    // Act
    const clone = test.clone()
  
    // Assert
    equal(test.lastParticle().getOlderSiblings().length, 2)
    equal(clone.lastParticle().getOlderSiblings().length, 2)
  }
  
  testParticles.siblings = equal => {
    // Arrange
    const test = new Particle(`a
  b
  c`)
  
    // Act
    const a = test.getParticle("a")
    const b = test.getParticle("b")
    const c = test.getParticle("c")
  
    // Assert
    equal(a.getSiblings().length, 2)
    equal(a.getOlderSiblings().length, 0)
    equal(a.getYoungerSiblings().length, 2)
    equal(b.getSiblings().length, 2)
    equal(b.getOlderSiblings().length, 1)
    equal(b.getYoungerSiblings().length, 1)
    equal(c.getSiblings().length, 2)
    equal(c.getOlderSiblings().length, 2)
    equal(c.getYoungerSiblings().length, 0)
  
    // Act
    a.appendSibling("a2", "foo")
    a.prependSibling("a-1", "foo")
  
    // Assert
    equal(
      test.asString,
      `a-1
   foo
  a
  a2
   foo
  b
  c`
    )
  }
  
  testParticles.expandLastFromTopMatter = equal => {
    // Arrange
    const test = new Particle(`titleComponent
   class title
  articleComponent hi
   h1 title
  html
   titleComponent
   articleComponent`)
    // Act
    const expanded = test.expandLastFromTopMatter().asString
  
    // Assert
    equal(
      expanded,
      `html
   titleComponent
    class title
   articleComponent hi
    h1 title`
    )
  }
  
  testParticles.replaceParticle = equal => {
    // Arrange
    const test = new Particle(`a
  b`)
    const a = test.getParticle("a")
  
    // Act
    a.replaceParticle((str: any) => str.replace("a", "z"))
  
    // Assert
    equal(
      test.asString,
      `z
  b`
    )
  }
  
  testParticles.replaceWith = equal => {
    // Arrange
    const test = new Particle(`a
  b`)
    const a = test.getParticle("a")
  
    // Act
    a.replaceWith(`c\nd`)
  
    // Assert
    equal(
      test.asString,
      `c
  d
  b`
    )
  }
  
  testParticles.fromSsv = equal => {
    // Arrange/Act
    const a = Particle.fromSsv(testStrings.ssv)
  
    // Assert
    equal(a.asString, testStrings.delimited)
    equal(a.asSsv, testStrings.ssv, "toSsv ok")
  
    // Arrange/Act
    const fixedCol = Particle.fromSsv(testStrings.ssvFixedColumns)
  
    // Assert
    equal(fixedCol.particleAt(0).getParticle("comment").content, testStrings.ssvFixedColumnComment1)
    equal(fixedCol.particleAt(1).getParticle("comment").content, testStrings.ssvFixedColumnComment2)
    equal(fixedCol.particleAt(1).length, 2)
  
    // Arrange/Act
    const missingCols = Particle.fromSsv(testStrings.ssvMissingColumns)
  
    // Assert
    equal(missingCols.particleAt(0).length, 3)
    equal(missingCols.particleAt(1).length, 3)
    equal(missingCols.particleAt(2).length, 3)
  }
  
  testParticles.fromTsv = equal => {
    // Arrange/Act
    const a = Particle.fromTsv(testStrings.tsv)
  
    // Assert
    equal(a.asString, testStrings.delimited, "From TSV worked")
    equal(a.asTsv, testStrings.tsv, "ToTsv Worked")
  
    // Test simple path
    // Act
    const b = Particle.fromTsv("color\tage\theight\nred\t2\t23")
  
    // Assert
    equal(b.getParticle("0 age").content, "2")
    equal(b.getParticle("0 height").content, "23")
  }
  
  testParticles.lengthen = equal => {
    // AAA
    equal(new Particle().lengthen(3).asString, "\n\n")
  }
  
  testParticles.getLine = equal => {
    // Arrange
    const particle = new Particle("hello world")
    const particle2 = particle.getParticle("hello")
    const mtime = particle2.getLineModifiedTime() || 0
  
    // Assert
    equal(particle2.getLine(), "hello world")
    equal(particle.has("hello"), true)
  
    // Act
    particle2.setLine("hi earth")
  
    // Assert
    equal(particle.asString, "hi earth")
    equal(particle2.getLineModifiedTime() > mtime, true)
    equal(particle.has("hello"), false)
  }
  
  testParticles.getIndentation = equal => {
    // Arrange
    const particle = new Particle(testStrings.webpageTrimmed)
  
    // Act/assert
    equal(particle.getParticle("body").indentation, "")
    equal(particle.getParticle("body div").indentation, " ")
    equal(particle.getParticle("body div content").indentation, "  ")
  
    equal(testStrings.webpageTrimmed, particle.topDownArray.map((line: particlesTypes.particle) => line.indentation + line.getLine()).join("\n"))
  }
  
  testParticles.content = equal => {
    // Arrange
    const particle = new Particle("hello world")
  
    // Assert
    equal(particle.getParticle("hello").content, "world")
    equal(particle.get("hello"), "world")
  
    // Act
    // Test get with ints
    particle.touchParticle("2").setContent("hi")
  
    // Assert
    equal(particle.getParticle("2").content, "hi", "Expected int strings to work.")
  
    // Assert
    // Test get with invalid values
    equal(new Particle().getParticle("some"), undefined, "expected undefined")
    equal(new Particle().getParticle("some long path"), undefined)
    equal(particle.getParticle(""), undefined)
  
    // Test get with duplicate properties
    // Arrange
    const particle2 = new Particle("height 45px\nheight 50px\nwidth 56px")
  
    // Assert
    equal(particle2.length, 3)
  
    // Act/Assert
    // When getting a duplicate property last item should win
    equal(particle2.getParticle("height").content, "50px", "Expected to get last value in instance with duplicate property.")
  
    // todo: remove ability of get to take non-strings
    // Arrange
    const particleWithNumbers = new Particle("1 bob\n0 brenda")
  
    // Act/Assert
    equal(particleWithNumbers.getParticle("0").content, "brenda")
    equal(particleWithNumbers.getParticle("1").content, "bob")
  }
  
  testParticles.getInheritanceParticles = equal => {
    // Arrange
    const classes = `abstractParser
  abstractModalParser abstractParser
  helpModal abstractModalParser
  abstractButton abstractParser
  helpButton abstractButton`
  
    // Act
    const inheritanceParticles = new Particle(classes).getInheritanceParticles()
  
    // Assert
    equal(
      inheritanceParticles.asString,
      `abstractParser
   abstractModalParser
    helpModal
   abstractButton
    helpButton`
    )
  }
  
  testParticles.getLines = equal => {
    // Arrange
    const value = new Particle("hello\n world")
  
    // Assert
    equal(value.getLines().join("").indexOf(" "), -1)
  }
  
  testParticles.getParticles = equal => {
    // Arrange
    const value = new Particle("hello world\nhello world")
    const deep = new Particle(`language
   line
    score 2
   line
    score 12`)
  
    // Assert
    equal(value.findParticles("hello").length, 2)
  
    // Act
    const result = value
      .findParticles("hello")
      .map((particle: particlesTypes.particle) => particle.content)
      .join("")
  
    // Assert
    equal(result, "worldworld")
    equal(deep.findParticles("language line score").length, 2)
    equal(
      deep
        .findParticles("language line score")
        .map((particle: particlesTypes.particle) => particle.content)
        .join(""),
      "212"
    )
  }
  
  testParticles.getContentsArray = equal => {
    // Arrange
    const html = new Particle("h1 hello world\nh1 hello world")
  
    // Assert
    equal(html.getContentsArray().join("\n"), "hello world\nhello world")
  }
  
  testParticles.multiply = equal => {
    class MathParticle extends Particle {
      get atomBreakSymbol() {
        return " "
      }
  
      get particleBreakSymbol() {
        return "o"
      }
  
      get edgeSymbol() {
        return "-"
      }
    }
  
    const iHateTypeScriptSometimes = MathParticle
  
    // Arrange
    const two = new iHateTypeScriptSometimes(`o`)
    const three = new iHateTypeScriptSometimes(`oo`)
  
    // Act/Assert
    const result = iHateTypeScriptSometimes.multiply(two, three)
  
    equal(result.asString, "o-o-o-oo-o-o-", "multipling empty structures (in this case 1D primes) works as expected")
  
    // Non blanks
    const four = new Particle(
      `o
   o
   o
  o
   o
   o`
    )
    const five = new Particle(
      `o
  o
  o
  o
  o
  o`
    )
    const twenty = `o
   o
    o
    o
   o
    o
    o
  o
   o
    o
    o
   o
    o
    o
  o
   o
    o
    o
   o
    o
    o
  o
   o
    o
    o
   o
    o
    o
  o
   o
    o
    o
   o
    o
    o
  o
   o
    o
    o
   o
    o
    o`
  
    equal(Particle.multiply(five, four).asString, twenty, "multiplying visible particles works as expected")
  }
  
  testParticles.getExpectingABranchButHittingALeaf = equal => {
    // Arrange
    const value = new Particle("posts leaf")
  
    // Assert
    equal(value.getParticle("posts branch"), undefined)
  }
  
  testParticles.getParticlesByPrefixes = equal => {
    // Arrange
    const test = `id foobar
   link
   link blue
    color orange
   link black
    color green`
    const particle = new Particle(test)
  
    // Act
    const particles = particle.getParticlesByLinePrefixes(["id foobar", "link blue", "color"])
    const particles2 = particle.getParticlesByLinePrefixes(["id foobar", "link bl"])
    const particles3 = particle.getParticlesByLinePrefixes(["id foobar", "ink"])
  
    // Assert
    equal(particles[0].getLine(), "color orange")
    equal(particles2.length, 2)
    equal(particles3.length, 0)
  }
  
  testParticles.getIndex = equal => {
    // Arrange
    const particle = new Particle("r1\n name bob\nr2\n name joe")
    const subparticle0 = particle.getParticle("r1")
    const subparticle1 = particle.getParticle("r2")
  
    // Act/Assert
    equal(subparticle0.index, 0, "Has correct index")
    equal(subparticle1.index, 1, "Has correct index")
  }
  
  testParticles.simpleParticleLanguage = equal => {
    // Arrange
    class MathProgramParser extends Particle {
      // Look! You created a top down parser!
      createParserPool() {
        return new Particle.ParserPool(undefined, { "+": AdditionParticleParser, "-": SubstractionParticleParser })
      }
  
      execute() {
        return this.map((subparticle: any) => subparticle.execute())
      }
    }
  
    class SubstractionParticleParser extends Particle {}
  
    class AdditionParticleParser extends Particle {
      // Look! You created an interpreter!
      execute() {
        return [this.getNumbers().reduce((prev: number, current: number) => prev + current, 0)]
      }
  
      // Look! You created a declarative file format!
      getNumbers() {
        return this.getAtomsFrom(1).map((atom: string) => parseFloat(atom))
      }
  
      // Look! You created a compiler!
      compile() {
        return this.getNumbers().join(" + ")
      }
    }
    const source = `+ 2 7
  + 3 1
  + 15 1.1 200 100`
  
    // Act
    const iHateTypeScriptSometimes = MathProgramParser
    const program = new iHateTypeScriptSometimes(source)
    const compiled = program.compile()
  
    // Assert
    equal(program.length, 3)
    equal(
      compiled,
      `2 + 7
  3 + 1
  15 + 1.1 + 200 + 100`
    )
  
    // Act
    const results = program.execute()
    // Assert
    equal(
      results.join("\n"),
      `9
  4
  316.1`
    )
  
    // Edit the program and assure parsing is correct
    // Assert
    equal(program.getSubparticlesByParser(AdditionParticleParser).length, 3)
    equal(program.getSubparticlesByParser(SubstractionParticleParser).length, 0)
  
    // Act
    program.particleAt(0).replaceParticle((str: any) => str.replace("+", "-"))
  
    // Assert
    equal(program.getSubparticlesByParser(AdditionParticleParser).length, 2)
    equal(program.getSubparticlesByParser(SubstractionParticleParser).length, 1)
    equal(program.getParticleByParser(SubstractionParticleParser) instanceof SubstractionParticleParser, true)
  }
  
  testParticles.getCuePath = equal => {
    // Arrange
    const particle = new Particle(testStrings.every)
    const parent = particle.getParticle("domains test.test.com pages home settings")
    const subparticle = particle.getParticle("domains test.test.com pages home settings data")
    const simple = new Particle("foo bar")
  
    // Assert
    equal(subparticle.getCuePath(), "domains test.test.com pages home settings data")
    equal(subparticle.parent, parent)
    equal(subparticle.root, particle)
    equal(subparticle.getStack().length, 6)
    equal(simple.getParticle("foo").getStack().length, 1)
    equal(subparticle.getCuePathRelativeTo(parent), "data")
  }
  
  testParticles.getPathVector = equal => {
    // Arrange
    const particle = new Particle(testStrings.every)
    const indexPath = [5, 0, 4, 0, 0]
    const namePath = "domains test.test.com pages home settings"
    const parent = particle.getParticle(namePath)
    const subparticle = particle.getParticle("domains test.test.com pages home settings data")
  
    // Assert
    equal(parent.getPathVector().join(" "), indexPath.join(" "))
    equal(subparticle.getPathVector().join(" "), "5 0 4 0 0 0")
    equal(particle.particleAt(parent.getPathVector()), parent)
    equal(particle.particleAt(subparticle.getPathVector()), subparticle)
  
    // Act
    const newNamePath = particle.pathVectorToCuePath([5, 0, 4, 0, 0])
  
    // Assert
    equal(newNamePath.join(" "), namePath)
  }
  
  testParticles.getSlice = equal => {
    // Arrange
    const particle = new Particle(`a
  b
  c
  d`)
    // Act/Assert
    equal(particle.getSlice(3, 4).asString, "d")
  }
  
  testParticles.has = equal => {
    // Arrange
    const particle = new Particle(`hello world
  nested
  foo 
  deep
   test
    2`)
  
    // Assert
    equal(particle.has("hello"), true)
    equal(particle.has("world"), false)
    equal(particle.has("foo"), true)
    equal(particle.has("nested"), true)
    equal(particle.has("deep test 2"), true)
    equal(particle.has("deep test"), true)
    equal(particle.has("deep"), true)
    equal(particle.has("deep test 3"), false)
    equal(particle.has("deep t 2"), false)
  }
  
  testParticles.hasParticle = equal => {
    // Arrange
    const particle = new Particle(testStrings.every)
    equal(particle.hasParticle(`admin false`), true)
    equal(
      particle.hasParticle(`stage
   name home
   domain test.test.com`),
      true
    )
    equal(particle.hasParticle(`name Plato`), false)
    equal(particle.hasParticle(`domain test.test.com`), false)
  }
  
  testParticles.getStackString = equal => {
    const particle = new Particle(
      `Thing
   color
    blue
    green`
    )
    // Act/assert
    equal(
      particle.getParticle("Thing color green").getStackString(),
      `Thing
   color
    green`
    )
  }
  
  testParticles.getGraph = equal => {
    // Arrange
    const particle = new Particle(
      `Thing
   color
  Animal
   dna
   extends Thing
  Monkey
   extends Mammal
   oohoohahah
  Mammal
   extends Animal
   milk`
    )
    // Act/Assert
    equal(particle.getParticle("Monkey").getAncestorParticlesByInheritanceViaExtendsCue("extends").length, 4)
    equal(particle.getParticle("Thing").getAncestorParticlesByInheritanceViaExtendsCue("extends").length, 1)
    equal(particle.getParticle("Animal").getAncestorParticlesByInheritanceViaExtendsCue("extends").length, 2)
  }
  
  testParticles.getGraphConventional = equal => {
    // Arrange
    const particle = new Particle(
      `Thing
   color
  Animal Thing
   dna
  Monkey Mammal
   oohoohahah
  Mammal Animal
   milk`
    )
    // Act/Assert
    equal(particle.getParticle("Monkey").getAncestorParticlesByInheritanceViaColumnIndices(0, 1).length, 4)
    equal(particle.getParticle("Thing").getAncestorParticlesByInheritanceViaColumnIndices(0, 1).length, 1)
    equal(particle.getParticle("Animal").getAncestorParticlesByInheritanceViaColumnIndices(0, 1).length, 2)
  }
  
  testParticles.getGraphLoop = equal => {
    // Arrange
    const particle = new Particle(
      `Thing Animal
   color
  Animal Thing
   dna`
    )
  
    // Act/Assert
    try {
      particle.getParticle("Animal").getAncestorParticlesByInheritanceViaColumnIndices(0, 1)
      equal(true, false, "Expected an error")
    } catch (err) {
      equal(true, true)
    }
  }
  
  testParticles.macroExpand = equal => {
    // Arrange
    const test = `macro red SUBREDDIT
   >reddit SUBREDDIT
    >h2 Top stories in SUBREDDIT
    >pie
    >table
    >line
  use red programming
  use red programmingLanguages`
  
    // Act
    const expanded = new Particle(test).macroExpand("macro", "use")
  
    // Assert
    equal(
      expanded.asString,
      `>reddit programming
   >h2 Top stories in programming
   >pie
   >table
   >line
  >reddit programmingLanguages
   >h2 Top stories in programmingLanguages
   >pie
   >table
   >line`
    )
  }
  
  testParticles.split = equal => {
    // Arrange
    const test = `#file foobar.csv
  name,score
  j,21
  frank,321
  #file index.html
   hi world
  #file foo.css #file
  body {
   }`
    const test2 = test.split("\n").slice(1).join("\n") // Same without leading #file
    const particle = new Particle(test)
    const particle2 = new Particle(test2)
  
    // Act
    const splitParticles = particle.split(`#file`)
    const splitParticles2 = particle2.split(`#file`)
  
    // Assert
    equal(splitParticles.length, 3)
    equal(splitParticles2.length, 3)
    equal(new Particle(`abc\n#find`).split(`#fi`).length, 1, "should not split on partial matches")
    equal(new Particle(`abc\n#find\n`).split(`#find`).length, 2, "should split on end of line")
    equal(splitParticles[1].particleAt(1).getAtom(1), "hi")
  
    // Act/Assert
    equal(splitParticles.join("\n"), test)
    equal(splitParticles2.join("\n"), test2)
  
    // Arrange/Act/Assert
    Object.keys(testStrings).forEach(key => {
      const particle = new Particle(testStrings[key])
      const splitOn = particle.getCues()[0] || "foo"
      equal(particle.split(splitOn).join("\n"), particle.asString, `split join failed for ${key}`)
    })
  }
  
  testParticles.shifts = equal => {
    // Arrange
    const str = `reddit
  table
  chart`
    const particle = new Particle(str)
  
    // Act/Assert
    // Test Noops:
    equal(particle.shiftLeft() && particle.shiftRight() && particle.particleAt(0).shiftLeft() && true, true)
  
    equal(particle.length, 3)
    equal(particle.particleAt(1).shiftRight().parent.getLine(), "reddit")
    equal(particle.length, 2)
  
    // Act/Assert
    equal(particle.particleAtLine(1).shiftLeft().parent.asString, str)
    equal(particle.length, 3)
  
    // Arrange
    const str2 = `reddit
   table
   chart
   pie`
    const particle2 = new Particle(str2)
  
    // Act
    particle2.particleAtLine(2).shiftRight()
    particle2.particleAtLine(3).shiftRight()
    equal(particle2.particleAtLine(1).length, 2)
  
    // Arrange/Act/Assert
    equal(
      new Particle(`file foo.js
  a = 2
  b = 3
  c = 4`)
        .particleAtLine(0)
        .shiftYoungerSibsRight().root.asString,
      `file foo.js
   a = 2
   b = 3
   c = 4`
    )
  
    // Arrange
    const particle9 = new Particle(`#file /foo/test-combined2.delete.js
  foobar
   test
  foo`)
    // Assert
    equal(particle9.particleAt(0).getYoungerSiblings().length, 2, "2 younger sibs")
  
    // Act
    particle9.particleAt(0).shiftYoungerSibsRight()
    // Assert
    const expected = `foobar
   test
  foo`
    equal(particle9.particleAt(0).subparticlesToString(), expected)
  }
  
  testParticles.expandSubparticles = equal => {
    // Arrange
    const particle = new Particle(
      `Thing
   color
   ab
  Animal Thing
   dna
   ab overridden`
    )
    // Act/Assert
    equal(
      particle._expandSubparticles(0, 1).asString,
      `Thing
   color
   ab
  Animal Thing
   color
   ab overridden
   dna`
    )
  
    // Arrange
    const particle2 = new Particle(
      `Thing
   color
  Animal Thing
   dna
  Monkey Mammal
   oohoohahah
  Mammal Animal
   milk`
    )
    // Act/Assert
    equal(
      particle2._expandSubparticles(0, 1).asString,
      `Thing
   color
  Animal Thing
   color
   dna
  Monkey Mammal
   color
   dna
   milk
   oohoohahah
  Mammal Animal
   color
   dna
   milk`
    )
  
    const badMap = new Particle(`foo
  bar foo
  car non-existant`)
    try {
      badMap._expandSubparticles(0, 1)
      equal(true, false, "expanding with missing id should throw")
    } catch (err) {
      equal(err.toString().includes("non-existant"), true, "expanding with missing id throws")
    }
  }
  
  testParticles.expandedShouldAppendNonMaps = equal => {
    // todo: we need to work on extend so its more straightforward
    // Arrange
    const particle = new Particle(
      `constructors
   example
   example foobar`
    )
    // Act/Assert
    equal(particle._expandSubparticles(0, 1).asString, particle.asString, "should have thrown")
  }
  
  testParticles.getCustomIndex = equal => {
    // todo: we need to work on extend so its more straightforward
    // Arrange
    const particle = new Particle(
      `coke
   id 123
   related 456
  pepsi
   type soda
   id 456`
    )
    // Act/Assert
    equal(particle.getCustomIndex("id")["456"][0].get("type"), "soda", "custom indexes work")
    // AA
    equal(particle.toFlatObject()["pepsi.type"], "soda", "to flat object works")
  }
  
  testParticles.htmlDsl = equal => {
    // Arrange
    const html = new Particle("h1 hello world\nh1 hello world")
    var page = ""
  
    // Act
    html.forEach((particle: particlesTypes.particle) => {
      const property = particle.cue
      const value = particle.content
      page += "" + value + ""
    })
  
    // Assert
    equal(page, "hello worldhello world")
  }
  
  testParticles.indexOf = equal => {
    // Arrange
    const particle = new Particle("hello world")
  
    // Assert
    equal(particle.indexOf("hello"), 0)
    equal(particle.indexOf("hello2"), -1)
  
    // Act
    particle.touchParticle("color").setContent("")
  
    // Assert
    equal(particle.indexOf("color"), 1)
  
    // Act
    particle.appendLine("hello world")
  
    // Assert
    equal(particle.indexOf("hello"), 0)
    equal(particle.indexOfLast("hello"), 2)
  }
  
  testParticles.appendUniqueLine = equal => {
    // Arrange
    const particle = new Particle(`city Brockton`)
    // Act
    particle.appendUniqueLine("city Brockton")
    particle.appendUniqueLine("country United States")
  
    // Assert
    equal(particle.length, 2)
    equal(particle.get("country"), "United States")
  }
  
  testParticles.insert = equal => {
    // Arrange
    const particle = new Particle("hello world")
  
    // Act
    particle.insertLine("hi mom", 0)
  
    // Assert
    equal(particle.indexOf("hi"), 0, "Expected hi at position 0")
  
    // Insert using an index longer than the current object
    // Act
    particle.insertLine("test dad", 10)
  
    // Assert
    equal(particle.particleAt(2).content, "dad", "Expected insert at int greater than length to append")
    equal(particle.length, 3)
  
    // Insert using a negative index
    // Act
    particle.insertLine("test2 sister", -1)
  
    // Assert
    equal(particle.particleAt(2).content, "sister")
    equal(particle.particleAt(3).content, "dad")
  }
  
  testParticles.insertLinesAfter = equal => {
    // Arrange
    const particle = new Particle("hello world")
    // Assert
    equal(particle.length, 1)
  
    // Act
    particle.getParticle("hello").insertLinesAfter(`config
   score 2`)
  
    // Assert
    equal(particle.get("config score"), "2", "Expected 2")
    equal(particle.length, 2)
  
    // Empty
    // Act
    particle.getParticle("hello").insertLinesAfter(``)
    equal(particle.length, 3)
  }
  
  testParticles.last = equal => {
    // Arrange
    const value = new Particle("hello world\nhi mom")
    // Assert
    equal(value.particleAt(-1).content, "mom")
  
    // Arrange
    const value2 = new Particle("hello world\nhi mom")
    // Assert
    equal(value2.particleAt(-1).asString, "hi mom")
  }
  
  testParticles.lastProperty = equal => {
    // Arrange
    const value = new Particle("hello world\nhi mom")
    // Assert
    equal(value.particleAt(-1).cue, "hi")
  }
  
  testParticles.lastValue = equal => {
    // Arrange
    const value = new Particle("hello world\nhi mom")
    // Assert
    equal(value.particleAt(-1).content, "mom")
  }
  
  testParticles.createFromArray = equal => {
    // Arrange
    const a = new Particle([1, 2, 3])
    // Assert
    equal(a.asString, "0 1\n1 2\n2 3", "basic array creation")
  
    // Arrange
    const b = new Particle({
      data: [
        {
          charge: 1
        },
        {
          charge: 2
        }
      ]
    })
  
    // Assert
    equal(b.asString, "data\n 0\n  charge 1\n 1\n  charge 2", "creation from objects")
  }
  
  testParticles.createFromObject = equal => {
    // Arrange
    const particle = new Particle(testObjects.tsv)
    const date = new Date()
    const time = date.getTime()
    const particleWithDate = new Particle({ name: "John", date: date })
  
    // Assert
    equal(particle.getParticle("lowestScore").content, "-10")
    equal(particleWithDate.getParticle("date").content, time.toString())
  
    // Test against object with circular references
    // Arrange
    const a: any = { foo: "1" }
    const b = { bar: "2", ref: a }
  
    // Act
    // Create circular reference
    a.c = b
    const particle2 = new Particle(a)
  
    // Assert
    equal(particle2.getParticle("c bar").content, "2", "expected 2")
    equal(particle2.getParticle("c ref"), undefined)
  
    // Arrange
    const particle3 = new Particle()
    particle3.touchParticle("docs").setSubparticles(testObjects.json2particles)
  
    // Assert
    equal(particle3.asString, testStrings.json2particles, "expected json2particles")
  
    // Arrange
    const test4 = new Particle({ score: undefined })
  
    // Assert
    equal(test4.asString, "score", "expected blank")
  }
  
  testParticles.createFromParticle = equal => {
    // Arrange
    const a = new Particle("foo\n bar bam")
    const b = new Particle(a)
  
    // Assert
    equal(a.getParticle("foo bar").content, "bam")
    equal(b.getParticle("foo bar").content, "bam")
  
    // Act
    a.touchParticle("foo bar").setContent("wham")
  
    // Assert
    equal(a.getParticle("foo bar").content, "wham")
    equal(b.getParticle("foo bar").content, "bam")
  }
  
  testParticles.createFromString = equal => {
    // Arrange/Act
    const startsWithSpace = new Particle(" name john")
  
    // Assert
    equal(startsWithSpace.length, 1, "Expected 1 particle")
  
    // Arrange
    const a = new Particle("text \n this is a string\n and more")
  
    // Assert
    equal(a.getParticle("text").contentWithSubparticles, "\nthis is a string\nand more", "Basic")
  
    // Arrange
    const b = new Particle("a\n text \n  this is a string\n  and more")
  
    // Assert
    equal(b.getParticle("a text").contentWithSubparticles, "\nthis is a string\nand more")
    equal(b.asString, "a\n text \n  this is a string\n  and more")
  
    // Arrange
    const string = `first_name John
  last_name Doe
  subparticles
   1
    first_name Joe
    last_name Doe
    subparticles
     1
      first_name Joe Jr.
      last_name Doe
      age 12
  colors
   blue
   red
  bio
   Hello this is
   my multline
   biography
  
   Theres a blank line in there as well
  
   Two blank lines above this one.
  code 
  `
    const c = new Particle(string)
  
    // Assert
    equal(c.getParticle("subparticles 1 subparticles 1 age").content, "12")
    equal(c.asString.length, string.length)
    equal(c.asString, string)
  
    // Arrange
    const d = new Particle("\n\na b\n")
  
    // Assert
    equal(d.asString, "\n\na b\n", "Expected extra newlines at start of string to be preserved")
  
    // Arrange
    const e = new Particle("a b\n\nb c\n")
    // Assert
    equal(e.asString, "a b\n\nb c\n", "Expected extra newlines in middle of string to be preserved")
  
    // Arrange
    const f = new Particle("a b\n\n\n")
    // Assert
    equal(f.asString, "a b\n\n\n", "Expected extra newlines at end of string to be preserved")
  
    // Arrange
    const g = new Particle("hi\n     somewhat invalid")
    // Assert
    equal(g.getParticle("hi ").content, "   somewhat invalid")
  
    const testCase = new Particle(testStrings.newLines)
    equal(testCase.asString.split("\n").length, 11, "All blank lines are preserved")
  }
  
  testParticles.protoRegression = equal => {
    // Arrange
    const a = `__proto__`
    const particle = new Particle(a)
    equal(particle.asString, a, "proto regression fixed")
  
    // Arrange
    const b = `constructor`
    const particle2 = new Particle(b)
    equal(particle2.asString, b, "constructor regression fixed")
  }
  
  testParticles.createFromStringExtraParticles = equal => {
    // Arrange
    const d = new Particle("one\ntwo\n  three\n    four\nfive six")
    // Assert
    equal(d.length, 3)
  }
  
  testParticles.copyTo = equal => {
    // Arrange
    const value = new Particle(
      `chart
   title Hello
  chart2
   title 2`
    )
    const expected = `chart
   title Hello
   chart2
    title 2`
    const expected2 = `chart
   chart2
    title 2
   title Hello`
    const particle0 = value.getSubparticles()[0]
  
    // Act
    const particle = value.getSubparticles()[1].copyTo(particle0, particle0.length)
    value.getSubparticles()[1].destroy()
  
    // Assert
    equal(value.asString, expected)
  
    // Act
    particle.copyTo(particle0, 0)
  
    // Assert
    particle.destroy()
    equal(value.asString, expected2)
  }
  
  testParticles.braid = equal => {
    // Arrange
    const particle = new Particle(`score 1`)
    const particle2 = new Particle(`keyword number`)
  
    // Act/Assert
    equal(
      particle.toBraid([particle2]).asString,
      `score 1
  keyword number`
    )
    equal(particle.toSideBySide([particle2]).asString, `score 1 keyword number`)
    equal(
      particle.toSideBySide([
        `foo
  
  bar`
      ]).asString,
      `score 1 foo
          
          bar`
    )
  }
  
  testParticles.copyToRegression = equal => {
    // Arrange
    const particle = new Particle(
      `>something
   class SomeClass
   css
    red
    green
    blue
   >div`
    )
    const expected = `>something SomeClass
   @red
   @green
   @blue
   >div`
  
    const migrateParticle = (particle: particlesTypes.particle) => {
      if (!particle.cue.startsWith(">")) return true
      if (particle.length) {
        const cla = particle.getParticle("class").content
        if (cla) particle.setContent(cla)
        const css = particle.getParticle("css")
        if (css) {
          const particles = css.getSubparticles()
          const toMove: any = []
          particles.forEach((propParticle: particlesTypes.particle) => {
            const name = propParticle.cue.replace(":", " ")
            propParticle.setCue("@" + name)
            toMove.push(propParticle)
          })
          toMove.reverse()
          toMove.forEach((prop: particlesTypes.particle) => prop.copyTo(particle, 0))
        }
        particle.delete("class")
        particle.delete("css")
        particle.forEach(migrateParticle)
      }
    }
  
    // Act
    particle.forEach(migrateParticle)
  
    // Assert
    equal(particle.asString, expected)
  }
  
  testParticles.insertAtom = equal => {
    // Arrange
    const a = new Particle("? result chekThis 1 2").getParticle("?")
    // Act
    a.insertAtom(2, "checkThis")
    // Assert
    equal(a.getLine(), "? result checkThis chekThis 1 2")
  }
  
  testParticles.setAtom = equal => {
    // Arrange
    const a = new Particle("? result chekThis 1 2").getParticle("?")
    // Act
    a.setAtom(2, "checkThis")
    // Assert
    equal(a.getLine(), "? result checkThis 1 2")
  }
  
  testParticles.particleLanguageDependingOnParent = equal => {
    // Arrange
    class ReverseEtnParticle extends Particle {
      createParserPool() {
        return new Particle.ParserPool(Particle, {})
      }
    }
  
    class TestLanguage extends Particle {
      createParserPool() {
        return new Particle.ParserPool(ReverseEtnParticle, {})
      }
    }
  
    // Act
    // This tests against a regression, it should not throw.
    const iHateTypeScriptSometimes = TestLanguage
    const program = new iHateTypeScriptSometimes(`foo
   bar`)
    // Assert.
    equal(program.length, 1)
  }
  
  testParticles.multiline = equal => {
    // Arrange
    const a = new Particle("my multiline\n string")
    // Assert
    equal(a.getParticle("my").contentWithSubparticles, "multiline\nstring")
  
    // Arrange
    const a2 = new Particle("my \n \n multiline\n string")
    // Assert
    equal(a2.getParticle("my").contentWithSubparticles, "\n\nmultiline\nstring")
  
    // Arrange
    const b = new Particle("brave new\n world")
    // Assert
    equal(b.getParticle("brave").contentWithSubparticles, "new\nworld", "ml value correct")
    equal(b.asString, "brave new\n world", "multiline does not begin with nl")
  
    // Arrange
    const c = new Particle("brave \n new\n world")
    // Assert
    equal(c.getParticle("brave").contentWithSubparticles, "\nnew\nworld", "ml begin with nl value correct")
    equal(c.asString, "brave \n new\n world", "multiline begins with nl")
  
    // Arrange
    const d = new Particle("brave \n \n new\n world")
    // Assert
    equal(d.getParticle("brave").contentWithSubparticles, "\n\nnew\nworld", "ml begin with 2 nl value correct")
    equal(d.asString, "brave \n \n new\n world", "multiline begins with 2 nl")
  
    // Arrange
    const e = new Particle("brave new\n world\n ")
    // Assert
    equal(e.getParticle("brave").contentWithSubparticles, "new\nworld\n", "ml value end with nl correct")
    equal(e.asString, "brave new\n world\n ", "multiline ends with a nl")
  
    // Arrange
    const f = new Particle("brave new\n world\n \n ")
    // Assert
    equal(f.getParticle("brave").contentWithSubparticles, "new\nworld\n\n", "ml value end with 2 nl correct")
    equal(f.asString, "brave new\n world\n \n ", "multiline ends with 2 nl")
  
    // Arrange
    const g = new Particle()
    g.touchParticle("brave").setContentWithSubparticles("\nnew\nworld\n\n")
    // Assert
    equal(g.getParticle("brave").contentWithSubparticles, "\nnew\nworld\n\n", "set ml works")
    equal(g.asString, "brave \n new\n world\n \n ", "set ml works")
  
    // Arrange/Act
    const twoParticles = new Particle("title Untitled\n")
    const k = new Particle()
    k.touchParticle("time").setContent("123")
    k.touchParticle("settings").setContentWithSubparticles(twoParticles.asString)
    k.touchParticle("day").setContent("1")
  
    // Assert
    equal(twoParticles.length, 2)
    equal(k.getParticle("settings").length, 1, "Expected subparticle to have 1 empty particle")
    equal(k.getParticle("settings").contentWithSubparticles, twoParticles.asString, "Expected setContentWithSubparticles and getText to work with newlines")
    equal(k.asString, `time 123\nsettings title Untitled\n \nday 1`)
  
    // Arrange
    const someText = new Particle("a")
    const someParticle = someText.getParticle("a")
  
    // Act
    someParticle.setContentWithSubparticles("const b = 1;\nconst c = 2;")
  
    // Assert
    equal(someText.asString, "a const b = 1;\n const c = 2;")
  }
  
  testParticles.order = equal => {
    // Arrange
    const a = new Particle("john\n age 5\nsusy\n age 6\nbob\n age 10")
    const types = a.getCues().join(" ")
  
    // Assert
    equal(types, "john susy bob", "order is preserved")
  }
  
  testParticles.parseParticle = equal => {
    // Arrange
    class LeafParticle extends Particle {}
    class SubclassParticle extends Particle {
      createParserPool() {
        return new Particle.ParserPool(SubclassParticle, {}, [{ regex: /^leaf/, parser: LeafParticle }])
      }
    }
    class TestLanguageParticle extends Particle {
      createParserPool() {
        return new Particle.ParserPool(TestLanguageParticle, {}, [
          { regex: /^particle/, parser: Particle },
          { regex: /^sub/, parser: SubclassParticle }
        ])
      }
    }
  
    // Act
    const iHateTypeScriptSometimes = TestLanguageParticle
    const particle = new iHateTypeScriptSometimes(
      `foo bar
   foo bar
    particle bar
  sub
   leaf`
    )
  
    // Assert
    equal(particle.getParticle("foo foo particle") instanceof Particle, true)
    equal(particle.getParticle("foo foo") instanceof TestLanguageParticle, true)
    equal(particle.getParticle("sub leaf") instanceof LeafParticle, true)
  }
  
  testParticles.prependLine = equal => {
    // Arrange
    const a = new Particle("hello world")
    // Assert
    equal(a.asString, "hello world")
  
    // Act
    const result = a.prependLine("foo bar")
    // Assert
    equal(a.asString, "foo bar\nhello world")
    equal(result instanceof Particle, true)
  }
  
  testParticles.getLocations = equal => {
    // Arrange/Act
    const a = new Particle(
      `hello
   world
  ohayo
   good
    morning
    sunshine`
    )
    const b = a.getParticle("ohayo good sunshine")
  
    // Assert
    equal(a.getIndentLevel(), 0, "a indent level")
    equal(a.lineNumber, 0)
    equal(b.getIndentLevel(), 3, "b indent level")
    equal(b.lineNumber, 6)
  
    // Arrange
    const reg = new Particle(
      `a
   b
    c
  d
   e`
    )
  
    // Act/Assert
    const result = reg.topDownArray.map((particle: particlesTypes.particle) => particle.lineNumber).join(" ")
    equal(result, "1 2 3 4 5")
    equal(reg.getParticle("a").lineNumber, 1)
  }
  
  testParticles.pushContentAndSubparticles = equal => {
    // Arrange
    const a = new Particle()
  
    // Act
    const result = a.pushContentAndSubparticles("hello world")
  
    // Assert
    equal(a.getParticle("0").content, "hello world")
    equal(result instanceof Particle, true)
  
    // Act
    a.pushContentAndSubparticles(undefined, new Particle())
  
    // Assert
    equal(a.getParticle("1") instanceof Particle, true, "1 is instance of Particle")
  }
  
  testParticles.remap = equal => {
    // Arrange
    const test = `mark
   d 2
   p 3
   c 4
   v 5
   q 6
  mark
   p 7
  
   v 9`
  
    const map = new Particle(
      `d date
  p price
  c cost
  v value
  q quantity`
    )
  
    const expandMapObj = map.clone().toObject()
    const contractMap = map.clone().invert().toObject()
  
    // Act
    const remapped = new Particle(test)
    remapped.forEach((particle: particlesTypes.particle) => particle.remap(expandMapObj))
  
    const expected = remapped.clone()
    expected.forEach((particle: particlesTypes.particle) => particle.remap(contractMap))
  
    // Assert
    equal(test, expected.asString)
  }
  
  testParticles.rename = equal => {
    // Arrange
    const a = new Particle("john\n age 5\nsusy\n age 6\ncandy bar\nx 123\ny 45\n")
    const originalLength = a.length
    const originalString = a.asString
    const index = a.indexOf("john")
  
    // Assert
    equal(index, 0, "index okay")
  
    // Act
    equal(a.rename("john", "breck") instanceof Particle, true, "returns itself for chaining")
    a.rename("candy", "ice")
  
    // Assert
    const index2 = a.indexOf("breck")
    equal(index2, 0, "index okay")
    equal(a.getParticle("breck age").content, "5", "value okay")
  
    // Act
    a.rename("breck", "john")
    a.rename("ice", "candy")
  
    // Assert
    equal(a.length, originalLength, "Length unchanged")
    equal(a.asString, originalString, "String unchanged")
  
    // Arrange
    const b = new Particle(testStrings.renameTest)
    const originalString2 = b.asString
  
    // Act
    b.rename("dimensions", "columns")
  
    // Assert
    equal(b.asString, originalString2)
  
    // Arrange
    const c = new Particle("a\na\n")
  
    // Act
    c.rename("a", "b")
    c.rename("a", "b")
  
    // Assert
    equal(c.asString, "b\nb\n")
    equal(c.has("a"), false)
  }
  
  testParticles.renameAll = equal => {
    // Arrange
    const a = new Particle("hello world\nhello world")
  
    // Act
    a.renameAll("hello", "hey")
  
    // Assert
    equal(a.asString, "hey world\nhey world")
    equal(a.has("hello"), false)
  
    // Arrange
    const b = new Particle(`foo.particle
   age 23
  foo.particle2
   age 24`)
  
    // Act
    b.getParticle("foo.particle2").renameAll("age", "bage")
  
    // Assert
    equal(b.get("foo.particle2 bage"), "24")
  }
  
  testParticles.reorder = equal => {
    // Arrange
    const a = new Particle("hello world")
  
    // Act
    a.touchParticle("hi").setContent("mom")
  
    // Assert
    equal(a.getCues().join(" "), "hello hi", "order correct")
  
    // Act
    a.insertLine("yo pal", 0)
  
    // Assert
    equal(a.getCues().join(" "), "yo hello hi", "order correct")
  
    // Act
    const result = a.insertLine("hola pal", 2)
    equal(result instanceof Particle, true)
  
    // Assert
    equal(a.getCues().join(" "), "yo hello hola hi", "order correct")
  }
  
  testParticles.next = equal => {
    // Arrange
    const a = new Particle(
      `john
   age 5
  susy
   age 6
   score 100
  bob
   age 10`
    )
    const b = a.getParticle("john")
    const c = a.getParticle("susy age")
  
    // Assert
    equal(a.next.asString, a.asString)
    equal(a.previous.asString, a.asString)
    equal(b.previous.cue, "bob")
    equal(b.previous.next.cue, "john")
    equal(b.next.cue, "susy")
    equal(c.next.cue, "score")
    equal(c.previous.cue, "score")
  }
  
  testParticles.reverse = equal => {
    // Arrange
    const particle = new Particle("hi mom\nhey sis\nhey dad")
  
    // Assert
    equal(particle.getParticle("hey").content, "dad")
  
    // Act
    particle.reverse()
  
    // Assert
    equal(particle.asString, "hey dad\nhey sis\nhi mom")
    equal(particle.getParticle("hey").content, "sis")
  
    // Test reverse when using internal types
  
    // Arrange
    const particle2 = Particle.fromCsv("name,age\nbill,20\nmike,40\ntim,30")
  
    // Act
    particle2.particleAt(0).reverse()
  
    // Assert
    equal(particle2.particleAt(0).particleAt(0).cue, "age", "Expected reversed properties")
    equal(particle2.particleAt(1).particleAt(0).cue, "name", "Expected unchanged properties")
  }
  
  testParticles.set = equal => {
    // Arrange
    const particle = new Particle("hello world")
  
    // Assert
    equal(particle.getParticle("hello").content, "world")
    equal(particle.touchParticle("hello").setContent("mom") instanceof Particle, true, "set should return instance so we can chain it")
    equal(particle.getParticle("hello").content, "mom")
  
    // Act
    particle.touchParticle("boom").setContent("")
    // Assert
    equal(particle.getParticle("boom").content, "", "empty string")
  
    // Act
    particle.touchParticle("head style color").setContent("blue")
    // Assert
    equal(particle.getParticle("head style color").content, "blue", "set should have worked")
  
    // Test dupes
    // Arrange
    particle.appendLine("hello bob")
  
    // Act
    particle.touchParticle("hello").setContent("tim")
  
    // Assert
    equal(particle.getParticle("hello").content, "tim", "Expected set to change last occurrence of property.")
  
    // TEST INT SCENARIOS
    // Arrange
    const particle2 = new Particle()
  
    // Act
    particle2.touchParticle("2").setContent("hi")
    particle2.touchParticle("3").setContent("3")
    // Assert
    equal(particle2.getParticle("2").content, "hi")
    equal(particle2.getParticle("2").content, "hi")
    equal(particle2.getParticle("3").content, "3")
  
    // TEST SPACEPATH SCENARIOS
    // Arrange
    const particle3 = new Particle("style\n")
    // Act
    particle3.touchParticle("style color").setContent("red")
    particle3.touchParticle("style width").setContent("100")
  
    // Assert
    equal(particle3.getParticle("style color").content, "red")
    equal(particle3.getParticle("style width").content, "100")
  
    // TEST ORDERING
    // Arrange
    const particle4 = new Particle("hello world")
    // Act
    particle4.touchParticle("hi").setContent("mom")
    // Assert
    equal(particle4.getCues().join(" "), "hello hi", "order correct")
  
    // Act
    particle4.insertLine("yo pal", 0)
    // Assert
    equal(particle4.getCues().join(" "), "yo hello hi", "order correct")
  
    // Act
    particle4.insertLine("hola pal", 2)
    // Assert
    equal(particle4.getCues().join(" "), "yo hello hola hi", "order correct")
  
    // Arrange
    const particle5 = new Particle()
    // Act
    particle5.touchParticle("hi").setContent("hello world")
    particle5.touchParticle("yo").setSubparticles(new Particle("hello world"))
    // Assert
    equal(particle5.getParticle("hi").content === particle5.getParticle("yo").content, false)
  
    // Arrange
    const particle6 = new Particle()
  
    // Act
    particle6.touchParticle("meta x").setContent("123")
    particle6.touchParticle("meta y").setContent("1235")
    particle6.touchParticle("meta c").setContent("435")
    particle6.touchParticle("meta x").setContent("1235123")
  
    // Assert
    equal(particle6.getParticle("meta c").content, "435")
  
    // Arrange
    const particle7 = new Particle("name John\nage\nfavoriteColors\n blue\n  blue1 1\n  blue2 2\n green\n red 1\n")
  
    // Act
    particle7.touchParticle("favoriteColors blue").setContent("purple").asString
  
    // Assert
    equal(particle7.getParticle("favoriteColors blue").content, "purple")
  
    // Act
    particle7.touchParticle(" blanks").setContent("test")
    particle7.touchParticle(" \nboom").setContent("test2")
  
    // Assert
    equal(particle7.getParticle(" blanks").content, "test", "Expected blank paths to be settable")
    equal(particle7.getParticle(" boom").content, "test2", "Expected newlines in path to be sanitized")
  
    // Arrange/Act
    const boom = new Particle("")
    boom.touchParticle("description").setContent("some text with a \nnewline")
  
    // Assert
    equal(new Particle(boom.asString).length, 1)
  
    // Test Blanks
    // Arrange
    const blank = new Particle()
    blank.touchParticle("").setContent("")
  
    // Assert
    equal(blank.length, 1, "Expected blanks to work")
    equal(blank.asString, " ", "Expected blanks to work")
  }
  
  testParticles.setFromArray = equal => {
    // Arrange/Act
    const boom = new Particle([{ description: "some text with a \nnewline" }])
    const output = boom.asString
  
    // Assert
    equal(new Particle(output).length, 1)
  }
  
  testParticles.set = equal => {
    // Arrange
    const particle = new Particle(`title Foo`)
  
    // Act
    particle.set("body div h1", "Hello world")
  
    // Assert
    equal(
      particle.asString,
      `title Foo
  body
   div
    h1 Hello world`
    )
  }
  
  testParticles.setFromText = equal => {
    // Arrange
    const str = `john doe
   age 50`
    const particle = new Particle(str)
    const particle2 = particle.getParticle("john")
  
    // Act
    particle.setFromText(str)
  
    // Assert
    equal(particle.asString, str)
  
    // Act
    particle2.setFromText("john")
  
    // Assert
    equal(particle2.asString, "john")
  }
  
  testParticles.shift = equal => {
    // Arrange
    const particle = new Particle(
      `john
   age 5
  susy
   age 6
  bob
   age 10`
    )
  
    const empty = new Particle()
  
    // Act/Assert
    equal(particle.length, 3, "length ok")
    equal(
      particle.shift().asString,
      `john
   age 5`,
      "expected correct string returned"
    )
    equal(particle.length, 2)
    equal(empty.shift(), null)
  
    // Arrange
    const one = new Particle("first\n nested")
  
    // Act
    one.getParticle("first").shift()
  
    // Assert
    equal(one.getParticle("first").length, 0)
    equal(one.asString, "first")
  }
  
  testParticles.sort = equal => {
    // Arrange
    const particle = new Particle("john\n age 5\nsusy\n age 6\nbob\n age 10")
    // Assert
    equal(particle.getCues().join(" "), "john susy bob")
    // Act
    particle.sort((a: particlesTypes.particle, b: particlesTypes.particle) => (b.cue  {
    // Arrange
    const particle = new Particle("john\n age 5\nsusy\n age 6\nbob\n age 10\nsam\n age 21\nbrian\n age 6")
    // Assert
    equal(particle.getCues().join(" "), "john susy bob sam brian")
  
    // Act
    particle.sortBy(["age"])
  
    // Assert
    equal(particle.getCues().join(" "), "bob sam john susy brian")
  
    // Sort by multiple properties
    // Arrange
    const particle2 = new Particle(testStrings.sortByMultiple)
  
    // Act
    particle2.sortBy(["name", "date"])
  
    // Assert
    equal(particle2.getColumn("key").join(""), "cab")
  
    // Act
    particle2.sortBy(["name", "key"])
  
    // Assert
    equal(particle2.getColumn("key").join(""), "acb")
  }
  
  testParticles.cueSort = equal => {
    // Arrange
    const particle = new Particle(`body
  footer
  div
  header
  div`)
    // Act
    particle.cueSort("header body div footer".split(" "))
    // Assert
    equal(
      particle.asString,
      `header
  body
  div
  div
  footer`
    )
  }
  
  testParticles.syntax = equal => {
    // Arrange
    const test = `person
   name Breck
   country USA
   books
    one SICP
    two Pragmatic
   num 12
   multiline this is a string
    over multiple lines.
       and this one has extra indents
   num 12
  `
    const a = new Particle(test)
    const test2 = `person;=name=Breck;=country=USA;=books;==one=SICP;==two=Pragmatic;=num=12;=multiline=this=is=a=string;==over=multiple=lines.;=====and=this=one=has=extra=indents;=num=12;`
  
    class TestLanguage extends Particle {
      get atomBreakSymbol() {
        return "="
      }
  
      get particleBreakSymbol() {
        return ";"
      }
  
      get edgeSymbol() {
        return "="
      }
    }
  
    // Act
    const iHateTypeScriptSometimes = TestLanguage
    const b = new iHateTypeScriptSometimes(test2)
  
    // Assert
    equal(b.getParticle("person=country").content, "USA")
    equal(a.toString(undefined, b), test2, "syntax conversion works")
  
    // Assert
    equal(a.toString(undefined, b), b.asString)
  
    // Assert
    equal(b.toString(undefined, a), test)
  }
  
  testParticles.toCsv = equal => {
    // Arrange
    const a = new Particle(testStrings.delimited)
    // Act/Assert
    equal(a.asCsv, testStrings.csv, "Expected correct csv")
  
    // Arrange
    const b = new Particle([{ lines: "1\n2\n3" }])
    // Act/equal
    equal(b.asCsv, `lines\n"1\n2\n3"`)
  }
  
  testParticles.getOneHot = equal => {
    // Arrange
    const a = Particle.fromCsv(Particle.iris)
    // Act
    const col = a.getOneHot("species").getColumn("species_setosa")
  
    // Assert
    equal(col.length, 10)
    equal(col[0], "0")
    equal(col[9], "1")
  }
  
  testParticles.deleteColumn = equal => {
    // Arrange
    const a = Particle.fromCsv(Particle.iris)
    // Assert
    equal(a.getColumnNames().length, 5)
  
    // Act
    a.deleteColumn("species")
  
    // Assert
    equal(a.getColumnNames().length, 4)
  }
  
  testParticles.toTable = equal => {
    // Arrange
    const a = Particle.fromCsv("name,score,color\n" + testStrings.csvNoHeaders)
    // Act/Assert
    equal(a.asTable, testStrings.toTableLeft, "Expected correct spacing")
    equal(a.toFormattedTable(100, true), testStrings.toTable, "Expected correct spacing")
  
    // Arrange
    const b = Particle.fromCsv("name\njoe\nfrankenstein")
    // Act/Assert
    equal(b.toFormattedTable(1, false), "n...\nj...\nf...", "Expected max width to be enforced")
  }
  
  testParticles.nest = equal => {
    // Arrange/Act
    const testStr2 = `html
   head
    body
     h3${Particle.nest("", 3)}
     h1${Particle.nest("h2 2", 3)}`
    const test = new Particle(testStr2)
  
    // Assert
    equal(test.getParticle("html head body").length, 3)
    equal(test.getParticle("html head body h2").content, "2")
  
    equal(new Particle(`${Particle.nest("foo bar", 0)}`).getParticle("foo").content, "bar")
    equal(new Particle(`${Particle.nest("foo bar", 1)}`).getParticle(" foo").content, "bar")
    equal(new Particle(`${Particle.nest("foo bar", 2)}`).particleAt([0, 0]).content, "foo bar")
  }
  
  testParticles.hashes = equal => {
    // Arrange/Act/Assert
    equal(typeof new Particle("hi").murmurHash, "string")
  }
  
  testParticles.toDataTable = equal => {
    // Arrange
    const data = [
      ["name", "age", "score"],
      ["coke", 29, 86],
      ["pepsi", 48, 16],
      ["soda", 32, 43]
    ]
  
    // Act
    const particle = Particle.fromDataTable(data)
  
    // Assert
    equal(particle.getParticle("2 age").content, "32")
  
    // Act
    const dt = particle.toDataTable()
  
    // Assert
    equal(dt[2][2], 16)
    equal(dt[0][1], "age")
    equal(dt[3][0], "soda")
  }
  
  testParticles.toObject = equal => {
    // Arrange
    const a = new Particle("hello world")
    const b = new Particle("foo bar")
  
    // Assert
    equal(typeof a.toObject(), "object")
    equal(a.toObject()["hello"], "world")
  
    // Act
    a.touchParticle("b").setSubparticles(b)
    // Assert
    equal(a.toObject()["b"]["foo"], "bar")
  
    // Arrange
    const objectWithParticlesAndValues = `div
   input checked
    type checkbox`
  
    // Act
    const obj = new Particle(objectWithParticlesAndValues).toObject()
  
    // Assert
    equal(typeof obj.div.input, "string")
  }
  
  testParticles.toSsv = equal => {
    // Arrange
    const a = new Particle(testStrings.delimited)
    // Assert
    equal(a.asSsv, testStrings.ssv)
    const b = new Particle([{ name: "john", age: 12 }])
    equal(!!b.asSsv, true)
  }
  
  testParticles.toMarkdownTable = equal => {
    // Arrange
    const test = `event abc
   title ABC 2017
   date 09/18/2017 - 09/10/2017
   location Boston, MA
   website https://www.foobar.com/
  event lala2018
   title Lala 2018
   date 11/02/2018 - 11/03/2018
   location San Fran
   twitter foo
   website http://www.blah.com`
    const expected = `|Title|Date|Location|Website|
  |-|-|-|-|
  |ABC 2017|09/18/2017 - 09/10/2017|Boston, MA|https://www.foobar.com/|
  |Lala 2018|11/02/2018 - 11/03/2018|San Fran|http://www.blah.com|`
    const simpleExpected = `|title|date|location|website|twitter|
  |-|-|-|-|-|
  |ABC 2017|09/18/2017 - 09/10/2017|Boston, MA|https://www.foobar.com/||
  |Lala 2018|11/02/2018 - 11/03/2018|San Fran|http://www.blah.com|foo|`
    const particle = new Particle(test)
  
    // Act
    const simple = particle.asMarkdownTable
    const table = particle.toMarkdownTableAdvanced(["title", "date", "location", "website"], (value: any, row: any, col: any) => (row ? value : Utils.ucfirst(value)))
  
    // Assert
    equal(table, expected, "markdown ok")
    equal(simple, simpleExpected, "markdown simple ok")
  }
  
  testParticles.setContentWithSubparticlesRegression = equal => {
    // Arrange
    const particle = new Particle("hello world")
    const hello = particle.getParticle("hello")
    // Act
    hello.setContentWithSubparticles(
      `brave
   new world`
    )
    hello.setContentWithSubparticles(`earth`)
    // Assert
    equal(particle.asString, "hello earth")
  }
  
  testParticles.sections = equal => {
    // Arrange
    const particle = new Particle(`push
  End of post
  
  push
  footer.scroll
  // done`)
    // Act
    particle
      .getParticles("push")
      .map((particle: any) => particle.section)
      .map((section: any) => section.forEach((particle: any) => particle.destroy()))
    // Assert
    equal(particle.asString, "push\n\npush")
  }
  
  testParticles.toStringMethod = equal => {
    // Arrange
    const particle = new Particle("hello world")
    // Assert
    equal(particle.asString, "hello world", "Expected correct string.")
    equal(particle.toStringWithLineNumbers(), "1 hello world")
    // Act
    particle.touchParticle("foo").setContent("bar")
    // Assert
    equal(particle.asString, "hello world\nfoo bar")
  
    // Arrange
    const particle2: any = new Particle("z-index 0")
    // Act
    particle2["z-index"] = 0
    // Assert
    equal(particle2.asString, "z-index 0")
  
    // Test empty values
    // Arrange
    const particle3 = new Particle()
  
    // Act
    particle3.touchParticle("empty").setContent("")
    // Assert
    equal(particle3.asString, "empty ")
  
    // Arrange
    const a = new Particle("john\n age 5")
    // Assert
    equal(a.asString, "john\n age 5")
  
    // Arrange
    const r = new Particle("joe\njane\njim")
    // Act/Assert
    equal(!!r.asString, true)
  
    // Act
    a.touchParticle("multiline").setContentWithSubparticles("hello\nworld")
    // Assert
    equal(a.asString, "john\n age 5\nmultiline hello\n world")
  
    // Act
    a.touchParticle("other").setContent("foobar")
    // Assert
    equal(a.asString, "john\n age 5\nmultiline hello\n world\nother foobar")
  
    // Arrange
    const b = new Particle("a\n text \n  this is a multline string\n  and more")
    // Assert
    equal(b.asString, "a\n text \n  this is a multline string\n  and more")
  
    // Test setting an instance as a value in another instance
    // Act
    a.touchParticle("even_more").setSubparticles(b)
    // Assert
    equal(a.asString, "john\n age 5\nmultiline hello\n world\nother foobar\neven_more\n a\n  text \n   this is a multline string\n   and more")
  
    // Arrange
    const testCases = ["", "\n", "\n\n", "\n \n ", "   \n   \n", "foo\nbar\n\n", "\n\n foo \nbar\n"]
  
    // Act/Assert
    testCases.forEach(someStr => equal(new Particle(someStr).asString, someStr, "Expected identity"))
  
    // Arrange
    const str = "view\n type bar"
    const particleView = new Particle(str).getParticle("view")
    // Act/Assert
    equal(particleView.asString, str)
  }
  
  testParticles.asHtml = equal => {
    // Arrange
    const particle = new Particle("hello world")
    // Act
    const str = particle.asHtml
    // Assert
    equal(str.includes(" {
    // Arrange
    const a = new Particle(testStrings.delimited)
    // Assert
    equal(a.asTsv, testStrings.tsv)
  }
  
  testParticles.toXml = equal => {
    // Arrange
    const a = new Particle(testStrings.toXml)
    // Assert
    equal(a.asXml, testStrings.toXmlPrettyResult)
  }
  
  testParticles.windowsReturnChars = equal => {
    // Arrange
    const particle = new Particle(
      `one
  \r
  \rtwo
  \r
  \r
  \rthree`
    )
  
    // Assert
    equal(particle.length, 6)
  }
  
  testParticles.traverse = equal => {
    // Arrange
    const traversal = new Particle(
      `0
   01
   02
    020
    021
  1
   10
   11
    110
   12
  2`
    )
  
    // Act
    const preOrder = traversal.topDownArray.map((particle: particlesTypes.particle) => particle.getLine()).join(" ")
    const postOrder = traversal
      .getSubparticlesFirstArray()
      .map((particle: particlesTypes.particle) => particle.getLine())
      .join(" ")
    const breadthfirst = traversal
      .getParentFirstArray()
      .map((particle: particlesTypes.particle) => particle.getLine())
      .join(" ")
  
    // Assert
    equal(preOrder, "0 01 02 020 021 1 10 11 110 12 2", "expected topDown visiting to work")
    equal(postOrder, "01 020 021 02 0 10 110 11 12 1 2", "expected postOrder visiting to work")
    equal(breadthfirst, "0 1 2 01 02 10 11 12 020 021 110", "expected breadthfirst visiting to work")
  
    // Arrange
    const wikipediaBinaryTree = new Particle(
      `f
   b
    a
    d
     c
     e
   g
    i
     h`
    )
  
    // Act
    const wikipreorder = wikipediaBinaryTree.topDownArray.map((particle: particlesTypes.particle) => particle.getLine()).join("")
    const wikibreadthfirst = wikipediaBinaryTree
      .getParentFirstArray()
      .map((particle: particlesTypes.particle) => particle.getLine())
      .join("")
    const wikipostorder = wikipediaBinaryTree
      .getSubparticlesFirstArray()
      .map((particle: particlesTypes.particle) => particle.getLine())
      .join("")
  
    // Assert
    equal(wikipreorder, "fbadcegih")
    equal(wikibreadthfirst, "fbgadiceh")
    equal(wikipostorder, "acedbhigf")
  }
  
  testParticles.toOutline = equal => {
    // AAA
    equal(typeof new Particle(testStrings.every).asOutline, "string")
  }
  
  testParticles.fromJsonSubset = equal => {
    // AAA
    equal(Particle.fromJsonSubset(JSON.stringify(testObjects.json2particles)).asString, new Particle(testStrings.json2particles).getParticle("docs").subparticlesToString())
  }
  
  testParticles.getFiltered = equal => {
    // AAA
    equal(
      new Particle(`a
  a
  a
  b
   a
  b
   a
  c`).getFiltered((particle: particlesTypes.particle) => particle.cue === "a").length,
      3
    )
  }
  
  testParticles.deleteDuplicates = equal => {
    // AAA
    equal(
      new Particle(`a
  a
  a
  b
   a
  b
   a
  c`).deleteDuplicates().length,
      3
    )
  }
  
  testParticles.fromShape = equal => {
    // AAA
    equal(
      Particle.fromShape([2, 2]).asString,
      `0
   0
   1
  1
   0
   1`
    )
  }
  
  testParticles.getFrom = equal => {
    // Arrange
    const particle = new Particle(
      `name
   string title The book of
   string person Jai`
    )
    // Act/Assert
    equal(particle.particleAt(0).getFrom("string person"), "Jai")
  }
  
  testParticles.toOutline = equal => {
    // Arrange
    const particle = new Particle(
      `hello
   world`
    )
  
    // Act/assert
    equal(
      particle.asOutline,
      `└hello
   └world
  `
    )
    equal(
      particle.toMappedOutline((particle: particlesTypes.particle) => "o"),
      `└o
   └o
  `
    )
  }
  
  testParticles.getLineOrSubparticlesModifiedTime = equal => {
    // Arrange
    const a = new Particle(`text
   foo
    bar
  some
   other`)
    const mtime = a.getLineOrSubparticlesModifiedTime()
    const fooTime = a.getParticle("text foo").getLineOrSubparticlesModifiedTime()
  
    // Act
    a.delete("some other")
  
    // Assert
    const newTime = a.getLineOrSubparticlesModifiedTime()
    equal(newTime > mtime, true, `newtime is greater than mtime ${newTime} ${mtime}`)
    equal(a.getParticle("text foo").getLineOrSubparticlesModifiedTime() === fooTime, true, "times are equal")
  
    // Act
    a.getParticle("text foo").setContent("wham")
  
    // Assert
    equal(a.getParticle("text foo").getLineOrSubparticlesModifiedTime() > fooTime, true, "mod subparticle updates")
  
    // Arrange
    const b = new Particle(`foo`)
    b.appendLine("bar")
    const bTime = b.getLineOrSubparticlesModifiedTime()
  
    // Act
    b.getParticle("foo").destroy()
  
    // Assert
    equal(b.getLineOrSubparticlesModifiedTime() > bTime, true, `time increased from ${bTime} to ${b.getLineOrSubparticlesModifiedTime()}`)
  }
  
  testParticles.destroyLoop = equal => {
    // Arrange
    const a = new Particle(`a
   d
  b
   d
  c
   d`)
    // Act
    a.forEach((subparticle: particlesTypes.particle) => {
      subparticle.destroy()
    })
  
    // Assert
    equal(a.length, 0)
  }
  
  testParticles.typeTests = equal => {
    // Arrange
    const a = new Particle("text")
    // Assert
    equal(a.getErrors().length, 0)
    equal(a.lineAtomTypes, "undefinedAtomType") // todo: make this a constant
  }
  
  testParticles.setTests = equal => {
    let base = new Particle(`foo bar`).particleAt(0)
    equal(base.getAtomsAsSet().has("bar"), true)
    equal(base.getAtomsAsSet().has("bar2"), false)
    equal(base.appendAtomIfMissing("bar").asString, `foo bar`)
    equal(base.appendAtomIfMissing("bam").getAtomsAsSet().has("bam"), true, "atom should be appended")
  }
  
  testParticles.getBiDirectionalMaps = equal => {
    const csv = Particle.fromCsv(Particle.iris)
    const maps = csv.getBiDirectionalMaps("species", "sepal_length")
    equal(maps[0]["versicolor"][0], "5.6")
    equal(maps[1]["5.6"][0], "versicolor")
  }
  
  testParticles.delimitedTests = equal => {
    let base = new Particle(`foo.csv`).particleAt(0)
    equal(base.addObjectsAsDelimited([{ name: "Joe", age: 100 }]).asString, `foo.csv\n name,age\n Joe,100`, "Add objects works")
  
    base = new Particle(`foo.csv`).particleAt(0)
    equal(base.setSubparticlesAsDelimited(`person\n name Joe\n age 100`).asString, `foo.csv\n name,age\n Joe,100`)
  
    let template = `foo.csv\n person\n  name Joe\n  age 100`
  
    base = new Particle(template).particleAt(0)
    equal(base.convertSubparticlesToDelimited().asString, `foo.csv\n name,age\n Joe,100`, "convert subparticles to delimited works")
  
    base = new Particle(template).particleAt(0)
    equal(base.convertSubparticlesToDelimited().addUniqueRowsToNestedDelimited(`name,age`, [`Frank,100`]).length, 3)
  
    base = new Particle(template).particleAt(0)
    equal(base.convertSubparticlesToDelimited().addUniqueRowsToNestedDelimited(`name,age`, [`Joe,100`]).length, 2)
  }
  
  testParticles.printLines = equal => {
    // Arrange
    let lastLogMessage = ""
    const orig = console.log
    console.log = (msg: string) => (lastLogMessage += msg + "\n")
    const a = new Particle(`text\n hello`)
    // Act/Assert
    a.printLinesFrom(0, 1)
    equal(lastLogMessage, "text\n")
  
    // Arrange
    lastLogMessage = ""
    // Act
    a.printLinesWithLineNumbersFrom(0, 2)
    equal(lastLogMessage, "0 text\n1  hello\n")
    // Cleanup
    console.log = orig
  }
  
  testParticles.with = equal => {
    // Arrange
    const dummy = new Particle(`0
   color red
   age 100
  1
   color blue`)
    // Act/Assert
    equal(dummy.with("color").length, 2)
    equal(dummy.with("age").length, 1)
    equal(dummy.with("score").length, 0)
    equal(dummy.without("color").length, 0)
    equal(dummy.without("age").length, 1)
    equal(dummy.without("score").length, 2)
  }
  
  testParticles.extendible = equal => {
    // Arrange
    const a = new ExtendibleParticle(`a
   color red
  b
   extends a`)
    // Assert
    equal(
      a._getLineage().asString,
      `a
   b`
    )
  }
  
  testParticles.toComparison = equal => {
    equal(new Particle(testStrings.webpage).toComparison(testStrings.webpage).asString.trim().length, 0, "should be equal")
  }
  
  testParticles.isBlank = equal => {
    // Arrange
    const a = new Particle("text\n\ntest \ntest2  ")
    // Assert
    equal(a.particleAt(0).isBlankLine(), false)
    equal(a.particleAt(1).isBlankLine(), true)
    equal(a.particleAt(0).isEmpty(), true)
    equal(a.particleAt(0).isEmpty(), true)
    equal(a.isEmpty(), false)
    equal(a.isBlankLine(), false)
    equal(a.getParticle("test").isBlankLine(), false)
    equal(a.getParticle("test").isEmpty(), true)
    equal(a.getParticle("test2").isBlankLine(), false)
    equal(a.getParticle("test2").isEmpty(), false)
  
    // Act/Assert
    equal(a.deleteSubparticles().length, 0)
  }
  
  testParticles.particles = equal => {
    // Arrange
    const a = new Particle("text")
    const particle = a.particleAt(0)
    const originalMtime = particle.getLineModifiedTime()
  
    // Assert
    equal(originalMtime > 0, true)
    equal(particle.isTerminal(), true)
    equal(particle.cue, "text")
    equal(particle.content, undefined)
    equal(particle.length, 0)
  
    // Act
    particle.setContent("hello world")
  
    // Assert
    equal(particle.content, "hello world")
    equal(a.asString, "text hello world")
  
    // Act
    particle.setSubparticles("color blue")
    particle.setSubparticles("color blue")
  
    // Assert
    equal(particle.isTerminal(), false)
    equal(particle.subparticlesToString(), "color blue")
    equal(a.asString, "text hello world\n color blue")
    equal(a.has("text"), true)
  
    // Act
    const mtime = particle.getLineModifiedTime()
    particle.setCue("foo")
  
    // Assert
    equal(a.asString, "foo hello world\n color blue")
    equal(particle.getLineModifiedTime() > mtime, true)
    equal(a.has("text"), false)
    equal(particle.has("color"), true)
  
    // Act
    particle.setSubparticles("")
  
    // Assert
    equal(!!particle.asString, true)
    equal(particle.has("color"), false)
  }
  
  testParticles.mTimeNotIncrementingRegressionTest = equal => {
    // Arrange
    const particle = new Particle("text").particleAt(0)
    let lastMTime = particle.getLineModifiedTime()
    const numOfTrials = 100
    // Previously we would get a flakey test about every 10k trials
    for (let i = 0; i  lastMTime, true, "mtime should have increased")
      lastMTime = newMTime
    }
  }
  
  testParticles.asyncUndoRedo = async equal => {
    // Arrange
    const particle = new Particle("hello world")
  
    // Assert
    await particle.saveVersion()
    equal(particle.getChangeHistory().length, 1)
    equal(particle.hasUnsavedChanges(), false)
  
    // Act
    particle.set("hello", "earth")
    equal(particle.hasUnsavedChanges(), true)
    await particle.saveVersion()
    // Assert
    equal(particle.getChangeHistory().length, 2)
    equal(particle.get("hello"), "earth")
    equal(particle.hasUnsavedChanges(), false)
    // Act
    await particle.undo()
    // Assert
    equal(particle.get("hello"), "world")
    equal(particle.hasUnsavedChanges(), true)
    // Act
    await particle.undo()
    // Assert
    equal(particle.get("hello"), "world")
    // Act
    await particle.redo()
    // Assert
    equal(particle.get("hello"), "earth")
    // Act
    await particle.redo()
    // Assert
    equal(particle.get("hello"), "earth")
  }
  
  testParticles.asSExpression = equal => {
    // Test basic nodes with just cue and content
    equal(new Particle("foo 1").asSExpression, "((foo 1))", "basic node conversion")
  
    // Test nodes with single child
    equal(new Particle("foo 1\n bar 2").asSExpression, "((foo 1 (bar 2)))", "node with single child")
  
    // Test nodes with multiple children
    equal(new Particle("foo\n bar 1\n baz 2").asSExpression, "((foo (bar 1) (baz 2)))", "node with multiple children")
  
    // Test deep nesting
    equal(new Particle("foo\n bar\n  baz 3").asSExpression, "((foo (bar (baz 3))))", "deeply nested nodes")
  
    // Test nodes without content
    equal(new Particle("foo\n bar").asSExpression, "((foo (bar)))", "nodes without content")
  
    // Test complex mixed case
    equal(new Particle("root 1\n first 2\n  inner 3\n  other 4\n second 5").asSExpression, "((root 1 (first 2 (inner 3) (other 4)) (second 5)))", "complex mixed nesting")
  
    // Test empty particle
    equal(new Particle("").asSExpression, "()", "empty particle")
  
    // Test node with content containing spaces
    equal(new Particle("title Hello World").asSExpression, "((title Hello World))", "content with spaces")
  
    // Test realistic example with mixed content types
    const webpage = new Particle(`html
   head
    title My Page
   body
    div
     class main
     content Hello world`)
  
    equal(webpage.asSExpression, "((html (head (title My Page)) (body (div (class main) (content Hello world)))))", "realistic webpage example")
  
    // Test a node with blank/empty children
    equal(new Particle("parent\n child1\n child2 \n child3").asSExpression, "((parent (child1) (child2 ) (child3)))", "handling empty/blank child nodes")
  
    // Test numbers and special characters in content
    equal(new Particle("math\n sum 2+2=4\n pi 3.14159").asSExpression, "((math (sum 2+2=4) (pi 3.14159)))", "handling numbers and special characters")
  }
  
  testParticles.trim = equal => {
    // Arrange/Act/Assert
    const particle = new Particle("\n\n\n")
    equal(particle.length, 4)
    equal(particle.trim().length, 0)
  
    const particle2 = new Particle(testStrings.webpage)
    equal(particle2.length, particle2.trim().length)
  }
  
  testParticles.macros = equal => {
    const program = new Particle()
    const search = "NAME"
    const replacement = "Breck"
    program.addTransformer((block: string) => block.replace(search, replacement))
    program.appendLine("hello NAME")
    equal(program.particleAt(0).content, "Breck", "Macro evaluated")
  
    program.addTransformer((block: string) =>
      block.replace(
        "Square",
        `A multiline
  string`
      )
    )
  
    program.appendLine("Square")
  
    equal(program.particleAt(0).content, "Breck", "Macro evaluated")
  }
  
  testParticles.wakeTest = async equal => {
    // Arrange
    let str = ""
    class Foo extends Particle {
      wake() {
        str += this.cue
      }
    }
    // Act
    const particle = new (Foo)()
    await particle.appendFromStream(`c
   b
    a
  d
  e
  g
   f`)
    // Assert
    equal(str, "abcdefg")
  }
  
  testParticles.fromStreamTest = async equal => {
    // Arrange
    const particle = new Particle()
    if (!particle.isNodeJs()) return
    const fs = require("fs")
    const path = require("path")
    const filepath = path.join(__dirname, "readme.scroll")
    const stream = fs.createReadStream(filepath, {
      encoding: "utf8"
    })
    await particle.appendFromStream(stream)
    equal(particle.toString(), fs.readFileSync(filepath, "utf8"), "Stream loaded correctly")
    const length = particle.length
  
    await particle.appendFromStream("abc")
    equal(particle.length, length + 1)
  }
  
  testParticles.queryMethods = equal => {
    // Arrange
    const particle = Particle.fromCsv(Particle.iris)
  
    // Act/Assert
    let result = particle.select(["sepal_width", "species"]).where("sepal_width", ">", 3.7)
    equal(result.length, 1)
    equal(result.particleAt(0).get("species"), "virginica")
  
    // Act/Assert
    equal(particle.select(["sepal_width"]).length, 10)
    equal(particle.where("sepal_width", "=", 3.7).length, 2)
    equal(particle.where("sepal_width", " any
  declare type mapFn = (value: any, index: int, array: any[]) => any
  
  enum FileFormat {
    csv = "csv",
    tsv = "tsv",
    particles = "particles"
  }
  
  const ATOM_MEMBRANE = " " // The symbol that separates atoms (words)
  const PARTICLE_MEMBRANE = "\n" // The symbol that separates particles (lines)
  const SUBPARTICLE_MEMBRANE = " " // The symbol, in combination with PARTICLE_MEMBRANE, that makes subparticles
  
  declare type removeAfterRunning = boolean
  
  declare type ParticleEventHandler = (event: AbstractParticleEvent) => removeAfterRunning
  
  abstract class AbstractParticleEvent {
    public targetParticle: Particle
    constructor(targetParticle: Particle) {
      this.targetParticle = targetParticle
    }
  }
  
  function splitBlocks(str: string, edgeSymbol: string, particleBreakSymbol: string) {
    const regex = new RegExp(`\\${particleBreakSymbol}(?!\\${edgeSymbol})`, "g")
    return str.split(regex)
  }
  
  function _getIndentCount(str: string, edgeSymbol: string) {
    let level = 0
    const edgeChar = edgeSymbol
    while (str[level] === edgeChar) {
      level++
    }
    return level
  }
  
  class ChildAddedParticleEvent extends AbstractParticleEvent {}
  class ChildRemovedParticleEvent extends AbstractParticleEvent {}
  class DescendantChangedParticleEvent extends AbstractParticleEvent {}
  class LineChangedParticleEvent extends AbstractParticleEvent {}
  
  class ParticleAtom {
    private _particle: Particle
    private _atomIndex: number
    constructor(particle: Particle, atomIndex: number) {
      this._particle = particle
      this._atomIndex = atomIndex
    }
    replace(newAtom: string) {
      this._particle.setAtom(this._atomIndex, newAtom)
    }
    get atom() {
      return this._particle.getAtom(this._atomIndex)
    }
  }
  
  const ParticleEvents = { ChildAddedParticleEvent, ChildRemovedParticleEvent, DescendantChangedParticleEvent, LineChangedParticleEvent }
  
  enum WhereOperators {
    equal = "=",
    notEqual = "!=",
    lessThan = "",
    greaterThanOrEqual = ">=",
    includes = "includes",
    doesNotInclude = "doesNotInclude",
    in = "in",
    notIn = "notIn",
    empty = "empty",
    notEmpty = "notEmpty"
  }
  
  enum ParticlesConstants {
    extends = "extends"
  }
  
  class ParserPool {
    // todo: should getErrors be under here? At least for certain types of errors?
    private _catchAllParser: particlesTypes.ParticleParser
    private _cueMap: Map
    private _regexTests: particlesTypes.regexTest[]
    constructor(catchAllParser: particlesTypes.ParticleParser, cueMap: particlesTypes.cueToParserMap = {}, regexTests: particlesTypes.regexTest[] = undefined) {
      this._catchAllParser = catchAllParser
      this._cueMap = new Map(Object.entries(cueMap))
      this._regexTests = regexTests
    }
  
    getCueOptions() {
      return Array.from(this._getCueMap().keys())
    }
  
    // todo: remove
    private _getCueMap() {
      return this._cueMap
    }
  
    // todo: remove
    _getCueMapAsObject() {
      let obj: particlesTypes.cueToParserMap = {}
      const map = this._getCueMap()
      for (let [key, val] of map.entries()) {
        obj[key] = val
      }
      return obj
    }
  
    _getMatchingParser(block: string, parentParticle: particlesTypes.particle, lineNumber: number, atomBreakSymbol = ATOM_MEMBRANE): particlesTypes.ParticleParser {
      return this._getCueMap().get(this._getCue(block, atomBreakSymbol)) || this._getParserFromRegexTests(block) || this._getCatchAllParser(parentParticle)
    }
  
    _getCatchAllParser(contextParticle: particlesTypes.particle) {
      if (this._catchAllParser) return this._catchAllParser
  
      const parent = contextParticle.parent
  
      if (parent) return parent._getParserPool()._getCatchAllParser(parent)
  
      return contextParticle.constructor
    }
  
    private _getParserFromRegexTests(block: string): particlesTypes.ParticleParser {
      if (!this._regexTests) return undefined
      const line = block.split(/\n/)[0]
      const hit = this._regexTests.find(test => test.regex.test(line))
      if (hit) return hit.parser
      return undefined
    }
  
    private _getCue(block: string, atomBreakSymbol: string) {
      const line = block.split(/\n/)[0]
      const firstBreak = line.indexOf(atomBreakSymbol)
      return line.substr(0, firstBreak > -1 ? firstBreak : undefined)
    }
  
    async appendParticleAsync(parentParticle: particlesTypes.particle, block: string): particlesTypes.particle {
      const index = parentParticle.length
      const parser: any = this._getMatchingParser(block, parentParticle, index)
      const { particleBreakSymbol } = parentParticle
      const lines = block.split(particleBreakSymbol)
      const subparticles = lines
        .slice(1)
        .map(line => line.substr(1))
        .join(particleBreakSymbol)
      const particle = new parser(undefined, lines[0], parentParticle, index)
      if (subparticles.length) await particle.appendFromStream(subparticles)
      await particle.wake()
      return particle
    }
  
    createParticle(parentParticle: particlesTypes.particle, block: string, index?: number): particlesTypes.particle {
      const rootParticle = parentParticle.root
      if (rootParticle.particleTransformers) {
        // A macro may return multiple new blocks.
        const blocks = splitBlocks(rootParticle._transformBlock(block), SUBPARTICLE_MEMBRANE, PARTICLE_MEMBRANE)
        const newParticles = blocks.map((block, newBlockIndex) => this._createParticle(parentParticle, block, index === undefined ? undefined : index + newBlockIndex))
        return newParticles[0]
      } else return this._createParticle(parentParticle, block, index)
    }
  
    _createParticle(parentParticle: particlesTypes.particle, block: string, index?: number): particlesTypes.particle {
      index = index === undefined ? parentParticle.length : index
      const parser: any = this._getMatchingParser(block, parentParticle, index)
      const { particleBreakSymbol } = parentParticle
      const lines = block.split(particleBreakSymbol)
      const subparticles = lines
        .slice(1)
        .map(line => line.substr(1))
        .join(particleBreakSymbol)
      return new parser(subparticles, lines[0], parentParticle, index)
    }
  }
  
  class Particle extends AbstractParticle {
    constructor(subparticles?: particlesTypes.subparticles, line?: string, parent?: Particle, index?: number) {
      super()
      this._parent = parent
      this._setLine(line)
      this._setSubparticles(subparticles)
      if (index !== undefined) parent._getSubparticlesArray().splice(index, 0, this)
      else if (parent) parent._getSubparticlesArray().push(this)
    }
  
    private _uid: int
    private _atoms: string[]
    private _parent: Particle | undefined
    private _subparticles: Particle[]
    private _line: string
    private _cueIndex: {
      [cue: string]: int
    }
  
    wake() {}
  
    execute() {}
  
    // If you want to link a particle to a file on the filesystem.
    setFile(file: File) {
      this.file = file
    }
  
    // Store all parsing state in the document, not the parser pool.
    particleTransformers?: particlesTypes.particleTransformer[]
  
    // todo: perhaps if needed in the future we can add more contextual params here
    _transformBlock(block: string) {
      this.particleTransformers.forEach(fn => {
        block = fn(block)
      })
      return block
    }
  
    addTransformer(fn: particlesTypes.particleTransformer) {
      if (!this.particleTransformers) this.particleTransformers = []
      this.particleTransformers.push(fn)
      return this
    }
  
    async loadRequirements(context: any) {
      // todo: remove
      await Promise.all(this.map(particle => particle.loadRequirements(context)))
    }
  
    getErrors(): particlesTypes.ParticleError[] {
      return []
    }
  
    get lineAtomTypes() {
      // todo: make this any a constant
      return "undefinedAtomType ".repeat(this.atoms.length).trim()
    }
  
    isNodeJs() {
      return typeof exports !== "undefined"
    }
  
    isBrowser() {
      return !this.isNodeJs()
    }
  
    getOlderSiblings() {
      if (this.isRoot()) return []
      return this.parent.slice(0, this.index)
    }
  
    protected _getClosestOlderSibling(): Particle | undefined {
      const olderSiblings = this.getOlderSiblings()
      return olderSiblings[olderSiblings.length - 1]
    }
  
    getYoungerSiblings() {
      if (this.isRoot()) return []
      return this.parent.slice(this.index + 1)
    }
  
    getSiblings() {
      if (this.isRoot()) return []
      return this.parent.filter(particle => particle !== this)
    }
  
    protected _getUid() {
      if (!this._uid) this._uid = Particle._makeUniqueId()
      return this._uid
    }
  
    // todo: rename getMother? grandMother et cetera?
    get parent() {
      return this._parent
    }
  
    getIndentLevel(relativeTo?: Particle) {
      return this._getIndentLevel(relativeTo)
    }
  
    get indentation() {
      const indentLevel = this._getIndentLevel() - 1
      if (indentLevel (arr: Parser[]) {
      this.forEach(subparticle => {
        arr.push(subparticle)
        subparticle._getTopDownArray(arr)
      })
    }
  
    get topDownArray(): Particle[] {
      const arr: Particle[] = []
      this._getTopDownArray(arr)
      return arr
    }
  
    *getTopDownArrayIterator(): IterableIterator {
      for (let subparticle of this.getSubparticles()) {
        yield subparticle
        yield* subparticle.getTopDownArrayIterator()
      }
    }
  
    particleAtLine(lineNumber: particlesTypes.positiveInt): Particle | undefined {
      let index = 0
      for (let particle of this.getTopDownArrayIterator()) {
        if (lineNumber === index) return particle
        index++
      }
    }
  
    get numberOfLines(): int {
      let lineCount = 0
      for (let particle of this.getTopDownArrayIterator()) {
        lineCount++
      }
      return lineCount
    }
  
    private _getMaxUnitsOnALine() {
      let max = 0
      for (let particle of this.getTopDownArrayIterator()) {
        const count = particle.atoms.length + particle.getIndentLevel()
        if (count > max) max = count
      }
      return max
    }
  
    get numberOfAtoms(): int {
      let atomCount = 0
      for (let particle of this.getTopDownArrayIterator()) {
        atomCount += particle.atoms.length
      }
      return atomCount
    }
  
    get lineNumber(): int {
      return this._getLineNumberRelativeTo()
    }
  
    protected _cachedLineNumber: int
    _getLineNumber(target: Particle = this) {
      if (this._cachedLineNumber) return this._cachedLineNumber
      let lineNumber = 1
      for (let particle of this.root.getTopDownArrayIterator()) {
        if (particle === target) return lineNumber
        lineNumber++
      }
      return lineNumber
    }
  
    isBlankLine(): boolean {
      return !this.length && !this.getLine()
    }
  
    get isBlank() {
      return this.isBlankLine()
    }
  
    hasDuplicateCues(): boolean {
      return this.length ? new Set(this.getCues()).size !== this.length : false
    }
  
    isEmpty(): boolean {
      return !this.length && !this.content
    }
  
    protected _getLineNumberRelativeTo(relativeTo?: Particle) {
      if (this.isRoot(relativeTo)) return 0
      const start = relativeTo || this.root
      return start._getLineNumber(this)
    }
  
    isRoot(relativeTo?: Particle): boolean {
      return relativeTo === this || !this.parent
    }
  
    get root() {
      return this._getRootParticle()
    }
  
    protected _getRootParticle(relativeTo?: Particle): Particle | this {
      if (this.isRoot(relativeTo)) return this
      return this.parent._getRootParticle(relativeTo)
    }
  
    toString(indentCount = 0, language = this): string {
      if (this.isRoot()) return this._subparticlesToString(indentCount, language)
      return this._toStringWithLine(indentCount, language)
    }
  
    _toStringWithLine(indentCount = 0, language = this): string {
      return language.edgeSymbol.repeat(indentCount) + this.getLine(language) + (this.length ? language.particleBreakSymbol + this._subparticlesToString(indentCount + 1, language) : "")
    }
  
    get asString() {
      return this.toString()
    }
  
    printLinesFrom(start: particlesTypes.int, quantity: particlesTypes.int) {
      return this._printLinesFrom(start, quantity, false)
    }
  
    printLinesWithLineNumbersFrom(start: particlesTypes.int, quantity: particlesTypes.int) {
      return this._printLinesFrom(start, quantity, true)
    }
  
    private _printLinesFrom(start: particlesTypes.int, quantity: particlesTypes.int, printLineNumbers: boolean) {
      // todo: use iterator for better perf?
      const end = start + quantity
      this.toString()
        .split("\n")
        .slice(start, end)
        .forEach((line, index) => {
          if (printLineNumbers) console.log(`${start + index} ${line}`)
          else console.log(line)
        })
      return this
    }
  
    getAtom(index: int): atom {
      const atoms = this._getAtoms(0)
      if (index ${edge}`
      const lineHtml = this._getLineHtml()
      const subparticlesHtml = this.length ? `${this.particleBreakSymbol}` + `${this._subparticlesToHtml(indentCount + 1)}` : ""
  
      return `${edgeHtml}${lineHtml}${subparticlesHtml}`
    }
  
    protected _getAtoms(startFrom: int) {
      if (!this._atoms) this._atoms = this._getLine().split(this.atomBreakSymbol)
      return startFrom ? this._atoms.slice(startFrom) : this._atoms
    }
  
    get atoms(): atom[] {
      return this._getAtoms(0)
    }
  
    doesExtend(parserId: particlesTypes.parserId) {
      return false
    }
  
    require(moduleName: string, filePath?: string): any {
      if (!this.isNodeJs()) return (window)[moduleName]
      return require(filePath || moduleName)
    }
  
    getAtomsFrom(startFrom: int) {
      return this._getAtoms(startFrom)
    }
  
    getFirstAncestor(): Particle {
      const parent = this.parent
      return parent.isRoot() ? this : parent.getFirstAncestor()
    }
  
    isLoaded() {
      return true
    }
  
    private _runTimePhaseErrors: { [phase: string]: any }
  
    getRunTimePhaseErrors() {
      if (!this._runTimePhaseErrors) this._runTimePhaseErrors = {}
      return this._runTimePhaseErrors
    }
  
    setRunTimePhaseError(phase: string, errorObject: any) {
      if (errorObject === undefined) delete this.getRunTimePhaseErrors()[phase]
      else this.getRunTimePhaseErrors()[phase] = errorObject
      return this
    }
  
    _getJavascriptPrototypeChainUpTo(stopAtClassName = "Particle") {
      // todo: cross browser test this
      let constructor: any = this.constructor
      const chain: string[] = []
      while (constructor.name !== stopAtClassName) {
        chain.unshift(constructor.name)
        constructor = constructor.__proto__
      }
      chain.unshift(stopAtClassName)
      return chain
    }
  
    _getProjectRootDir(): string {
      return this.isRoot() ? "" : this.root._getProjectRootDir()
    }
  
    // Concat 2 particles amd return a new particle, but replace any particles
    // in this particle that start with the same particle from the first particle with
    // that patched version. Does not recurse.
    patch(two: Particle) {
      const copy = this.clone()
      two.forEach(particle => {
        const hit = copy.getParticle(particle.getAtom(0))
        if (hit) hit.destroy()
      })
      copy.concat(two)
      return copy
    }
  
    getSparsity() {
      const particles = this.getSubparticles()
      const fields = this._getUnionNames()
      let count = 0
      this.getSubparticles().forEach(particle => {
        fields.forEach(field => {
          if (particle.has(field)) count++
        })
      })
  
      return 1 - count / (particles.length * fields.length)
    }
  
    // todo: rename. what is the proper term from set/cat theory?
    getBiDirectionalMaps(propertyNameOrFn: mapFn | string, propertyNameOrFn2: mapFn | string = particle => particle.getAtom(0)) {
      const oneToTwo: { [key: string]: string[] } = {}
      const twoToOne: { [key: string]: string[] } = {}
      const is1Str = typeof propertyNameOrFn === "string"
      const is2Str = typeof propertyNameOrFn2 === "string"
      const subparticles = this.getSubparticles()
      this.forEach((particle, index) => {
        const value1 = is1Str ? particle.get(propertyNameOrFn) : (propertyNameOrFn)(particle, index, subparticles)
        const value2 = is2Str ? particle.get(propertyNameOrFn2) : (propertyNameOrFn2)(particle, index, subparticles)
        if (value1 !== undefined) {
          if (!oneToTwo[value1]) oneToTwo[value1] = []
          oneToTwo[value1].push(value2)
        }
        if (value2 !== undefined) {
          if (!twoToOne[value2]) twoToOne[value2] = []
          twoToOne[value2].push(value1)
        }
      })
      return [oneToTwo, twoToOne]
    }
  
    private _getAtomIndexCharacterStartPosition(atomIndex: int): particlesTypes.positiveInt {
      const xiLength = this.edgeSymbol.length
      const numIndents = this._getIndentLevel() - 1
      const indentPosition = xiLength * numIndents
      if (atomIndex  0) return this
      let particle: Particle = this
      while (atomIndex  {
        line.atoms.forEach((atom, index) => line.setAtom(index, fill))
      })
      return this
    }
  
    getAllAtomBoundaryCoordinates() {
      const coordinates: particlesTypes.atomBoundary[] = []
      let lineIndex = 0
      for (let particle of this.getTopDownArrayIterator()) {
        ;(particle).getAtomBoundaryCharIndices().forEach((charIndex, atomIndex) => {
          coordinates.push({
            lineIndex: lineIndex,
            charIndex: charIndex,
            atomIndex: atomIndex
          })
        })
  
        lineIndex++
      }
      return coordinates
    }
  
    getAtomBoundaryCharIndices(): particlesTypes.positiveInt[] {
      let indentLevel = this._getIndentLevel()
      const atomBreakSymbolLength = this.atomBreakSymbol.length
      let elapsed = indentLevel
      return this.atoms.map((atom, atomIndex) => {
        const boundary = elapsed
        elapsed += atom.length + atomBreakSymbolLength
        return boundary
      })
    }
  
    getAtomIndexAtCharacterIndex(charIndex: particlesTypes.positiveInt): int {
      // todo: is this correct thinking for handling root?
      if (this.isRoot()) return 0
      const numberOfIndents = this._getIndentLevel(undefined) - 1
      // todo: probably want to rewrite this in a performant way.
      const spots = []
      while (spots.length  {
        atom.split("").forEach(letter => {
          spots.push(atomIndex)
        })
        spots.push(atomIndex)
      })
  
      return spots[charIndex]
    }
  
    // Note: This currently does not return any errors resulting from "required" or "single"
    getAllErrors(lineStartsAt = 1): particlesTypes.ParticleError[] {
      const errors: particlesTypes.ParticleError[] = []
      for (let particle of this.topDownArray) {
        particle._cachedLineNumber = lineStartsAt // todo: cleanup
        const errs: particlesTypes.ParticleError[] = particle.getErrors()
        errs.forEach(err => errors.push(err))
        // delete particle._cachedLineNumber
        lineStartsAt++
      }
      return errors
    }
  
    *getAllErrorsIterator() {
      let line = 1
      for (let particle of this.getTopDownArrayIterator()) {
        particle._cachedLineNumber = line
        const errs = particle.getErrors()
        // delete particle._cachedLineNumber
        if (errs.length) yield errs
        line++
      }
    }
  
    get cue(): atom {
      return this.atoms[0]
    }
  
    set cue(atom: atom) {
      this.setAtom(0, atom)
    }
  
    get content(): string {
      const atoms = this.getAtomsFrom(1)
      return atoms.length ? atoms.join(this.atomBreakSymbol) : undefined
    }
  
    get contentWithSubparticles(): string {
      // todo: deprecate
      const content = this.content
      return (content ? content : "") + (this.length ? this.particleBreakSymbol + this._subparticlesToString() : "")
    }
  
    getFirstParticle(): Particle {
      return this.particleAt(0)
    }
  
    getStack() {
      return this._getStack()
    }
  
    protected _getStack(relativeTo?: Particle): Particle[] {
      if (this.isRoot(relativeTo)) return []
      const parent = this.parent
      if (parent.isRoot(relativeTo)) return [this]
      else return parent._getStack(relativeTo).concat([this])
    }
  
    getStackString(): string {
      return this._getStack()
        .map((particle, index) => this.edgeSymbol.repeat(index) + particle.getLine())
        .join(this.particleBreakSymbol)
    }
  
    getLine(language?: Particle) {
      if (!this._atoms && !language) return this._getLine() // todo: how does this interact with "language" param?
      return this.atoms.join((language || this).atomBreakSymbol)
    }
  
    getColumnNames(): atom[] {
      return this._getUnionNames()
    }
  
    getOneHot(column: string) {
      const clone = this.clone()
      const cols = Array.from(new Set(clone.getColumn(column)))
      clone.forEach(particle => {
        const val = particle.get(column)
        particle.delete(column)
        cols.forEach(col => {
          particle.set(column + "_" + col, val === col ? "1" : "0")
        })
      })
      return clone
    }
  
    // todo: return array? getPathArray?
    protected _getCuePath(relativeTo?: Particle): particlesTypes.cuePath {
      if (this.isRoot(relativeTo)) return ""
      else if (this.parent.isRoot(relativeTo)) return this.cue
  
      return this.parent._getCuePath(relativeTo) + this.edgeSymbol + this.cue
    }
  
    getCuePathRelativeTo(relativeTo?: Particle): particlesTypes.cuePath {
      return this._getCuePath(relativeTo)
    }
  
    getCuePath(): particlesTypes.cuePath {
      return this._getCuePath()
    }
  
    getPathVector(): particlesTypes.pathVector {
      return this._getPathVector()
    }
  
    getPathVectorRelativeTo(relativeTo?: Particle): particlesTypes.pathVector {
      return this._getPathVector(relativeTo)
    }
  
    protected _getPathVector(relativeTo?: Particle): particlesTypes.pathVector {
      if (this.isRoot(relativeTo)) return []
      const path = this.parent._getPathVector(relativeTo)
      path.push(this.index)
      return path
    }
  
    get index(): int {
      return this.parent._indexOfParticle(this)
    }
  
    isTerminal() {
      return !this.length
    }
  
    protected _getLineHtml() {
      return this.atoms.map((atom, index) => `${Utils.stripHtml(atom)}`).join(`${this.atomBreakSymbol}`)
    }
  
    protected _getXmlContent(indentCount: particlesTypes.positiveInt) {
      if (this.content !== undefined) return this.contentWithSubparticles
      return this.length ? `${indentCount === -1 ? "" : "\n"}${this._subparticlesToXml(indentCount > -1 ? indentCount + 2 : -1)}${" ".repeat(indentCount)}` : ""
    }
  
    protected _toXml(indentCount: particlesTypes.positiveInt) {
      const indent = " ".repeat(indentCount)
      const tag = this.cue
      return `${indent}${this._getXmlContent(indentCount)}${indentCount === -1 ? "" : "\n"}`
    }
  
    protected _toObjectTuple() {
      const content = this.content
      const length = this.length
      const hasSubparticlesNoContent = content === undefined && length
      const hasContentAndHasSubparticles = content !== undefined && length
      // If the particle has a content and a subparticle return it as a string, as
      // Javascript object values can't be both a leaf and a particle.
      const tupleValue = hasSubparticlesNoContent ? this.toObject() : hasContentAndHasSubparticles ? this.contentWithSubparticles : content
      return [this.cue, tupleValue]
    }
  
    protected _indexOfParticle(needleParticle: Particle) {
      let result = -1
      this.find((particle, index) => {
        if (particle === needleParticle) {
          result = index
          return true
        }
      })
      return result
    }
  
    getMaxLineWidth() {
      let maxWidth = 0
      for (let particle of this.getTopDownArrayIterator()) {
        const lineWidth = particle.getLine().length
        if (lineWidth > maxWidth) maxWidth = lineWidth
      }
      return maxWidth
    }
  
    toParticle() {
      return new Particle(this.toString())
    }
  
    protected _rightPad(newWidth: number, padCharacter: string) {
      const line = this.getLine()
      this.setLine(line + padCharacter.repeat(newWidth - line.length))
      return this
    }
  
    rightPad(padCharacter = " ") {
      const newWidth = this.getMaxLineWidth()
      this.topDownArray.forEach(particle => particle._rightPad(newWidth, padCharacter))
      return this
    }
  
    lengthen(numberOfLines: int) {
      let linesToAdd = numberOfLines - this.numberOfLines
      while (linesToAdd > 0) {
        this.appendLine("")
        linesToAdd--
      }
      return this
    }
  
    toSideBySide(particlesOrStrings: (Particle | string)[], delimiter = " ") {
      particlesOrStrings = particlesOrStrings.map(particle => (particle instanceof Particle ? particle : new Particle(particle)))
      const clone = this.toParticle()
      const particleBreakSymbol = "\n"
      let next: any
      while ((next = particlesOrStrings.shift())) {
        clone.lengthen(next.numberOfLines)
        clone.rightPad()
        next
          .toString()
          .split(particleBreakSymbol)
          .forEach((line: string, index: number) => {
            const particle = clone.particleAtLine(index)
            particle.setLine(particle.getLine() + delimiter + line)
          })
      }
      return clone
    }
  
    toComparison(particle: Particle | string) {
      const particleBreakSymbol = "\n"
      const lines = particle.toString().split(particleBreakSymbol)
      return new Particle(
        this.toString()
          .split(particleBreakSymbol)
          .map((line, index) => (lines[index] === line ? "" : "x"))
          .join(particleBreakSymbol)
      )
    }
  
    toBraid(particlesOrStrings: (Particle | string)[]) {
      particlesOrStrings.unshift(this)
      const particleDelimiter = this.particleBreakSymbol
      return new Particle(
        Utils.interweave(particlesOrStrings.map(particle => particle.toString().split(particleDelimiter)))
          .map(line => (line === undefined ? "" : line))
          .join(particleDelimiter)
      )
    }
  
    getSlice(startIndexInclusive: int, stopIndexExclusive: int) {
      return new Particle(
        this.slice(startIndexInclusive, stopIndexExclusive)
          .map(subparticle => subparticle.toString())
          .join("\n")
      )
    }
  
    protected _hasColumns(columns: string[]) {
      const atoms = this.atoms
      return columns.every((searchTerm, index) => searchTerm === atoms[index])
    }
  
    hasAtom(index: int, atom: string): boolean {
      return this.getAtom(index) === atom
    }
  
    getParticleByColumns(...columns: string[]): Particle {
      return this.topDownArray.find(particle => particle._hasColumns(columns))
    }
  
    getParticleByColumn(index: int, name: string): Particle {
      return this.find(particle => particle.getAtom(index) === name)
    }
  
    protected _getParticlesByColumn(index: int, name: atom): Particle[] {
      return this.filter(particle => particle.getAtom(index) === name)
    }
  
    // todo: preserve subclasses!
    select(columnNames: string[] | string) {
      columnNames = Array.isArray(columnNames) ? columnNames : [columnNames]
      const result = new Particle()
      this.forEach(particle => {
        const newParticle = result.appendLine(particle.getLine())
        ;(columnNames).forEach((name: string) => {
          const valueParticle = particle.getParticle(name)
          if (valueParticle) newParticle.appendParticle(valueParticle)
        })
      })
      return result
    }
  
    selectionToString() {
      return this.getSelectedParticles()
        .map(particle => particle.toString())
        .join("\n")
    }
  
    getSelectedParticles() {
      return this.topDownArray.filter(particle => particle.isSelected())
    }
  
    clearSelection() {
      this.getSelectedParticles().forEach(particle => particle.unselectParticle())
    }
  
    // Note: this is for debugging select chains
    print(message = "") {
      if (message) console.log(message)
      console.log(this.toString())
      return this
    }
  
    // todo: preserve subclasses!
    // todo: preserve links back to parent so you could edit as normal?
    where(columnName: string, operator: WhereOperators, fixedValue?: string | number | string[] | number[]) {
      const isArray = Array.isArray(fixedValue)
      const valueType = isArray ? typeof (>fixedValue)[0] : typeof fixedValue
      let parser: Function
      if (valueType === "number") parser = parseFloat
      const fn = (particle: Particle) => {
        const atom = particle.get(columnName)
        const typedAtom = parser ? parser(atom) : atom
        if (operator === WhereOperators.equal) return fixedValue === typedAtom
        else if (operator === WhereOperators.notEqual) return fixedValue !== typedAtom
        else if (operator === WhereOperators.includes) return typedAtom !== undefined && typedAtom.includes(fixedValue)
        else if (operator === WhereOperators.doesNotInclude) return typedAtom === undefined || !typedAtom.includes(fixedValue)
        else if (operator === WhereOperators.greaterThan) return typedAtom > fixedValue
        else if (operator === WhereOperators.lessThan) return typedAtom = fixedValue
        else if (operator === WhereOperators.lessThanOrEqual) return typedAtom >fixedValue).includes(typedAtom)
        else if (operator === WhereOperators.notIn && isArray) return !(>fixedValue).includes(typedAtom)
      }
      const result = new Particle()
      this.filter(fn).forEach(particle => {
        result.appendParticle(particle)
      })
      return result
    }
  
    with(cue: string) {
      return this.filter(particle => particle.has(cue))
    }
  
    without(cue: string) {
      return this.filter(particle => !particle.has(cue))
    }
  
    first(quantity = 1) {
      return this.limit(quantity, 0)
    }
  
    last(quantity = 1) {
      return this.limit(quantity, this.length - quantity)
    }
  
    // todo: preserve subclasses!
    limit(quantity: int, offset = 0): Particle {
      const result = new Particle()
      this.getSubparticles()
        .slice(offset, quantity + offset)
        .forEach(particle => {
          result.appendParticle(particle)
        })
      return result
    }
  
    getSubparticlesFirstArray() {
      const arr: Particle[] = []
      this._getSubparticlesFirstArray(arr)
      return arr
    }
  
    protected _getSubparticlesFirstArray(arr: Particle[]) {
      this.forEach(subparticle => {
        subparticle._getSubparticlesFirstArray(arr)
        arr.push(subparticle)
      })
    }
  
    protected _getIndentLevel(relativeTo?: Particle) {
      return this._getStack(relativeTo).length
    }
  
    getParentFirstArray() {
      const levels = this._getLevels()
      const arr: Particle[] = []
      Object.values(levels).forEach(level => {
        level.forEach(item => arr.push(item))
      })
      return arr
    }
  
    protected _getLevels(): { [level: number]: Particle[] } {
      const levels: { [level: number]: Particle[] } = {}
      this.topDownArray.forEach(particle => {
        const level = particle._getIndentLevel()
        if (!levels[level]) levels[level] = []
        levels[level].push(particle)
      })
      return levels
    }
  
    protected _getSubparticlesArray() {
      if (!this._subparticles) this._subparticles = []
      return this._subparticles
    }
  
    getLines(): string[] {
      return this.map(particle => particle.getLine())
    }
  
    getSubparticles(): any[] {
      return this._getSubparticlesArray().slice(0)
    }
  
    get length(): particlesTypes.positiveInt {
      return this._getSubparticlesArray().length
    }
  
    protected _particleAt(index: int) {
      if (index  {
        newObject[subparticle.getAtom(0)] = subparticle.content
        subparticle.topDownArray.forEach((particle: Particle) => {
          const newColumnName = particle.getCuePathRelativeTo(this).replace(edgeSymbolRegex, delimiter)
          const value = particle.content
          newObject[newColumnName] = value
        })
      })
      return newObject
    }
  
    protected _toObject() {
      const obj: particlesTypes.stringMap = {}
      this.forEach(particle => {
        const tuple = particle._toObjectTuple()
        obj[tuple[0]] = tuple[1]
      })
      return obj
    }
  
    get asHtml(): particlesTypes.htmlString {
      return this._subparticlesToHtml(0)
    }
  
    protected _toHtmlCubeLine(indents = 0, lineIndex = 0, planeIndex = 0): particlesTypes.htmlString {
      const getLine = (atomIndex: number, atom = "") =>
        `${atom.replace(/`
      let atoms: string[] = []
      this.atoms.forEach((atom, index) => (atom ? atoms.push(getLine(index + indents, atom)) : ""))
      return atoms.join("")
    }
  
    get asHtmlCube(): particlesTypes.htmlString {
      return this.map((plane, planeIndex) => plane.topDownArray.map((line: any, lineIndex: number) => line._toHtmlCubeLine(line.getIndentLevel() - 2, lineIndex, planeIndex)).join("")).join("")
    }
  
    protected _getHtmlJoinByCharacter() {
      return `${this.particleBreakSymbol}`
    }
  
    protected _subparticlesToHtml(indentCount: int) {
      const joinBy = this._getHtmlJoinByCharacter()
      return this.map(particle => particle._toHtml(indentCount)).join(joinBy)
    }
  
    protected _subparticlesToString(indentCount?: int, language = this) {
      return this.map(particle => particle.toString(indentCount, language)).join(language.particleBreakSymbol)
    }
  
    subparticlesToString(indentCount = 0): string {
      return this._subparticlesToString(indentCount)
    }
  
    get murmurHash(): string {
      const str = this.toString()
      let h1 = 0xdeadbeef
      for (let i = 0; i >> 0).toString(16)
    }
  
    // todo: implement
    protected _getChildJoinCharacter() {
      return "\n"
    }
  
    format() {
      this.forEach(subparticle => subparticle.format())
      return this
    }
  
    compile(): string {
      return this.map(subparticle => subparticle.compile()).join(this._getChildJoinCharacter())
    }
  
    get asXml(): particlesTypes.xmlString {
      return this._subparticlesToXml(0)
    }
  
    toDisk(path: string) {
      if (!this.isNodeJs()) throw new Error("This method only works in Node.js")
      const format = Particle._getFileFormat(path)
      const formats = {
        particles: (particle: Particle) => particle.toString(),
        csv: (particle: Particle) => particle.asCsv,
        tsv: (particle: Particle) => particle.asTsv
      }
      this.require("fs").writeFileSync(path, (formats)[format](this), "utf8")
      return this
    }
  
    _lineToYaml(indentLevel: number, listTag = "") {
      let prefix = " ".repeat(indentLevel)
      if (listTag && indentLevel > 1) prefix = " ".repeat(indentLevel - 2) + listTag + " "
      return prefix + `${this.cue}:` + (this.content ? " " + this.content : "")
    }
  
    _isYamlList() {
      return this.hasDuplicateCues()
    }
  
    get asYaml() {
      return `%YAML 1.2
  ---\n${this._subparticlesToYaml(0).join("\n")}`
    }
  
    _subparticlesToYaml(indentLevel: number): string[] {
      if (this._isYamlList()) return this._subparticlesToYamlList(indentLevel)
      else return this._subparticlesToYamlAssociativeArray(indentLevel)
    }
  
    // if your code-to-be-yaml has a list of associative arrays of type N and you don't
    // want the type N to print
    _collapseYamlLine() {
      return false
    }
  
    _toYamlListElement(indentLevel: number) {
      const subparticles = this._subparticlesToYaml(indentLevel + 1)
      if (this._collapseYamlLine()) {
        if (indentLevel > 1) return subparticles.join("\n").replace(" ".repeat(indentLevel), " ".repeat(indentLevel - 2) + "- ")
        return subparticles.join("\n")
      } else {
        subparticles.unshift(this._lineToYaml(indentLevel, "-"))
        return subparticles.join("\n")
      }
    }
  
    _subparticlesToYamlList(indentLevel: number): string[] {
      return this.map(particle => particle._toYamlListElement(indentLevel + 2))
    }
  
    _toYamlAssociativeArrayElement(indentLevel: number) {
      const subparticles = this._subparticlesToYaml(indentLevel + 1)
      subparticles.unshift(this._lineToYaml(indentLevel))
      return subparticles.join("\n")
    }
  
    _subparticlesToYamlAssociativeArray(indentLevel: number): string[] {
      return this.map(particle => particle._toYamlAssociativeArrayElement(indentLevel))
    }
  
    get asJsonSubset(): particlesTypes.jsonSubset {
      return JSON.stringify(this.toObject(), null, " ")
    }
  
    private _toObjectForSerialization(): particlesTypes.SerializedParticle {
      return this.length
        ? {
            atoms: this.atoms,
            subparticles: this.map(subparticle => subparticle._toObjectForSerialization())
          }
        : {
            atoms: this.atoms
          }
    }
  
    get asSExpression(): string {
      return this._toSExpression()
    }
  
    protected _toSExpression(): string {
      const thisAtoms = this.atoms.join(" ")
      if (!this.length)
        // For leaf nodes, just return (cue content) or (cue) if no content
        return `(${thisAtoms})`
  
      // For nodes with children, recursively process each child
      const children = this.map(particle => particle._toSExpression()).join(" ")
      return thisAtoms ? `(${thisAtoms} ${children})` : `(${children})`
    }
  
    get asJson(): string {
      return JSON.stringify({ subparticles: this.map(subparticle => subparticle._toObjectForSerialization()) }, null, " ")
    }
  
    get asGrid() {
      const AtomBreakSymbol = this.atomBreakSymbol
      return this.toString()
        .split(this.particleBreakSymbol)
        .map(line => line.split(AtomBreakSymbol))
    }
  
    get asGridJson() {
      return JSON.stringify(this.asGrid, null, 2)
    }
  
    findParticles(cuePath: particlesTypes.cuePath | particlesTypes.cuePath[]): Particle[] {
      // todo: can easily speed this up
      const map: any = {}
      if (!Array.isArray(cuePath)) cuePath = [cuePath]
      cuePath.forEach(path => (map[path] = true))
      return this.topDownArray.filter(particle => {
        if (map[particle._getCuePath(this)]) return true
        return false
      })
    }
  
    evalTemplateString(str: particlesTypes.templateString): string {
      const that = this
      return str.replace(/{([^\}]+)}/g, (match, path) => that.get(path) || "")
    }
  
    emitLogMessage(message: string) {
      console.log(message)
    }
  
    getColumn(path: atom): string[] {
      return this.map(particle => particle.get(path))
    }
  
    getFiltered(fn: particlesTypes.filterFn) {
      const clone = this.clone()
      clone
        .filter((particle, index) => !fn(particle, index))
        .forEach(particle => {
          particle.destroy()
        })
      return clone
    }
  
    getParticle(cuePath: particlesTypes.cuePath) {
      return this._getParticleByPath(cuePath)
    }
  
    getParticles(cuePath: particlesTypes.cuePath) {
      return this.findParticles(cuePath)
    }
  
    get section() {
      // return all particles after this one to the next blank line or end of file
      const particles = []
      if (this.isLast) return particles
      let next = this.next
      while (!next.isBlank) {
        particles.push(next)
        next = next.next
        if (next.isFirst) break
      }
      return particles
    }
  
    get isLast() {
      return this.index === this.parent.length - 1
    }
  
    get isFirst() {
      return this.index === 0
    }
  
    getFrom(prefix: string) {
      const hit = this.filter(particle => particle.getLine().startsWith(prefix))[0]
      if (hit) return hit.getLine().substr((prefix + this.atomBreakSymbol).length)
    }
  
    get(cuePath: particlesTypes.cuePath) {
      const particle = this._getParticleByPath(cuePath)
      return particle === undefined ? undefined : particle.content
    }
  
    getOneOf(keys: string[]) {
      for (let i = 0; i  {
        if (!map[particle.getAtom(0)]) particle.destroy()
      })
  
      return newParticle
    }
  
    getParticlesByGlobPath(query: particlesTypes.globPath): Particle[] {
      return this._getParticlesByGlobPath(query)
    }
  
    private _getParticlesByGlobPath(globPath: particlesTypes.globPath): Particle[] {
      const edgeSymbol = this.edgeSymbol
      if (!globPath.includes(edgeSymbol)) {
        if (globPath === "*") return this.getSubparticles()
        return this.filter(particle => particle.cue === globPath)
      }
  
      const parts = globPath.split(edgeSymbol)
      const current = parts.shift()
      const rest = parts.join(edgeSymbol)
      const matchingParticles = current === "*" ? this.getSubparticles() : this.filter(subparticle => subparticle.cue === current)
  
      return [].concat.apply(
        [],
        matchingParticles.map(particle => particle._getParticlesByGlobPath(rest))
      )
    }
  
    protected _getParticleByPath(cuePath: particlesTypes.cuePath): Particle {
      const edgeSymbol = this.edgeSymbol
      if (!cuePath.includes(edgeSymbol)) {
        const index = this.indexOfLast(cuePath)
        return index === -1 ? undefined : this._particleAt(index)
      }
  
      const parts = cuePath.split(edgeSymbol)
      const current = parts.shift()
      const currentParticle = this._getSubparticlesArray()[this._getCueIndex()[current]]
      return currentParticle ? currentParticle._getParticleByPath(parts.join(edgeSymbol)) : undefined
    }
  
    get next(): Particle {
      if (this.isRoot()) return this
      const index = this.index
      const parent = this.parent
      const length = parent.length
      const next = index + 1
      return next === length ? parent._getSubparticlesArray()[0] : parent._getSubparticlesArray()[next]
    }
  
    get previous(): Particle {
      if (this.isRoot()) return this
      const index = this.index
      const parent = this.parent
      const length = parent.length
      const prev = index - 1
      return prev === -1 ? parent._getSubparticlesArray()[length - 1] : parent._getSubparticlesArray()[prev]
    }
  
    protected _getUnionNames() {
      if (!this.length) return []
  
      const obj: particlesTypes.stringMap = {}
      this.forEach((particle: Particle) => {
        if (!particle.length) return undefined
        particle.forEach(particle => {
          obj[particle.cue] = 1
        })
      })
      return Object.keys(obj)
    }
  
    getAncestorParticlesByInheritanceViaExtendsCue(key: atom): Particle[] {
      const ancestorParticles = this._getAncestorParticles(
        (particle, id) => particle._getParticlesByColumn(0, id),
        particle => particle.get(key),
        this
      )
      ancestorParticles.push(this)
      return ancestorParticles
    }
  
    // Note: as you can probably tell by the name of this method, I don't recommend using this as it will likely be replaced by something better.
    getAncestorParticlesByInheritanceViaColumnIndices(thisColumnNumber: int, extendsColumnNumber: int): Particle[] {
      const ancestorParticles = this._getAncestorParticles(
        (particle, id) => particle._getParticlesByColumn(thisColumnNumber, id),
        particle => particle.getAtom(extendsColumnNumber),
        this
      )
      ancestorParticles.push(this)
      return ancestorParticles
    }
  
    protected _getAncestorParticles(getPotentialParentParticlesByIdFn: (thisParentParticle: Particle, id: atom) => Particle[], getParentIdFn: (thisParticle: Particle) => atom, cannotContainParticle: Particle): Particle[] {
      const parentId = getParentIdFn(this)
      if (!parentId) return []
  
      const potentialParentParticles = getPotentialParentParticlesByIdFn(this.parent, parentId)
      if (!potentialParentParticles.length) throw new Error(`"${this.getLine()} tried to extend "${parentId}" but "${parentId}" not found.`)
  
      if (potentialParentParticles.length > 1) throw new Error(`Invalid inheritance paths. Multiple unique ids found for "${parentId}"`)
  
      const parentParticle = potentialParentParticles[0]
  
      // todo: detect loops
      if (parentParticle === cannotContainParticle) throw new Error(`Loop detected between '${this.getLine()}' and '${parentParticle.getLine()}'`)
  
      const ancestorParticles = parentParticle._getAncestorParticles(getPotentialParentParticlesByIdFn, getParentIdFn, cannotContainParticle)
      ancestorParticles.push(parentParticle)
      return ancestorParticles
    }
  
    pathVectorToCuePath(pathVector: particlesTypes.pathVector): atom[] {
      const path = pathVector.slice() // copy array
      const names = []
      let particle: Particle = this
      while (path.length) {
        if (!particle) return names
        names.push(particle.particleAt(path[0]).cue)
        particle = particle.particleAt(path.shift())
      }
      return names
    }
  
    toStringWithLineNumbers() {
      return this.toString()
        .split("\n")
        .map((line, index) => `${index + 1} ${line}`)
        .join("\n")
    }
  
    get asCsv(): string {
      return this.toDelimited(",")
    }
  
    protected _getTypes(header: string[]) {
      const matrix = this._getMatrix(header)
      const types = header.map(i => "int")
      matrix.forEach(row => {
        row.forEach((value, index) => {
          const type = types[index]
          if (type === "string") return 1
          if (value === undefined || value === "") return 1
          if (type === "float") {
            if (value.match(/^\-?[0-9]*\.?[0-9]*$/)) return 1
            types[index] = "string"
          }
          if (value.match(/^\-?[0-9]+$/)) return 1
          types[index] = "string"
        })
      })
      return types
    }
  
    toDataTable(header = this._getUnionNames()): particlesTypes.dataTable {
      const types = this._getTypes(header)
      const parsers: { [parseName: string]: (str: string) => any } = {
        string: str => str,
        float: parseFloat,
        int: parseInt
      }
      const atomFn: atomFn = (atomValue, rowIndex, columnIndex) => (rowIndex ? parsers[types[columnIndex]](atomValue) : atomValue)
      const arrays = this._toArrays(header, atomFn)
      arrays.rows.unshift(arrays.header)
      return arrays.rows
    }
  
    toDelimited(delimiter: particlesTypes.delimiter, header = this._getUnionNames(), escapeSpecialChars = true) {
      const regex = new RegExp(`(\\n|\\"|\\${delimiter})`)
      const atomFn: atomFn = (str, row, column) => (!str.toString().match(regex) ? str : `"` + str.replace(/\"/g, `""`) + `"`)
      return this._toDelimited(delimiter, header, escapeSpecialChars ? atomFn : str => str)
    }
  
    protected _getMatrix(columns: string[]) {
      const matrix: string[][] = []
      this.forEach(subparticle => {
        const row: string[] = []
        columns.forEach(col => {
          row.push(subparticle.get(col))
        })
        matrix.push(row)
      })
      return matrix
    }
  
    protected _toArrays(columnNames: string[], atomFn: atomFn) {
      const skipHeaderRow = 1
      const header = columnNames.map((columnName, index) => atomFn(columnName, 0, index))
      const rows = this.map((particle, rowNumber) =>
        columnNames.map((columnName, columnIndex) => {
          const subparticleParticle = particle.getParticle(columnName)
          const content = subparticleParticle ? subparticleParticle.contentWithSubparticles : ""
          return atomFn(content, rowNumber + skipHeaderRow, columnIndex)
        })
      )
      return {
        rows,
        header
      }
    }
  
    _toDelimited(delimiter: particlesTypes.delimiter, header: string[], atomFn: atomFn) {
      const data = this._toArrays(header, atomFn)
      return data.header.join(delimiter) + "\n" + data.rows.map(row => row.join(delimiter)).join("\n")
    }
  
    get asTable(): string {
      // Output a table for printing
      return this._toTable(100, false)
    }
  
    toFormattedTable(maxCharactersPerColumn: number, alignRight = false): string {
      return this._toTable(maxCharactersPerColumn, alignRight)
    }
  
    protected _toTable(maxCharactersPerColumn: number, alignRight = false) {
      const header = this._getUnionNames()
      // Set initial column widths
      const widths = header.map(col => (col.length > maxCharactersPerColumn ? maxCharactersPerColumn : col.length))
  
      // Expand column widths if needed
      this.forEach(particle => {
        if (!particle.length) return true
        header.forEach((col, index) => {
          const atomValue = particle.get(col)
          if (!atomValue) return true
          const length = atomValue.toString().length
          if (length > widths[index]) widths[index] = length > maxCharactersPerColumn ? maxCharactersPerColumn : length
        })
      })
  
      const atomFn = (atomText: string, row: particlesTypes.positiveInt, col: particlesTypes.positiveInt) => {
        const width = widths[col]
        // Strip newlines in fixedWidth output
        const atomValue = atomText.toString().replace(/\n/g, "\\n")
        const atomLength = atomValue.length
        if (atomLength > width) return atomValue.substr(0, width) + "..."
  
        const padding = " ".repeat(width - atomLength)
        return alignRight ? padding + atomValue : atomValue + padding
      }
      return this._toDelimited(" ", header, atomFn)
    }
  
    get asSsv(): string {
      return this.toDelimited(" ")
    }
  
    get asOutline(): string {
      return this._toOutline(particle => particle.getLine())
    }
  
    toMappedOutline(particleFn: particlesTypes.particleToStringFn): string {
      return this._toOutline(particleFn)
    }
  
    // Adapted from: https://github.com/notatestuser/treeify.js
    protected _toOutline(particleFn: particlesTypes.particleToStringFn) {
      const growBranch = (outlineParticle: any, last: boolean, lastStates: any[], particleFn: particlesTypes.particleToStringFn, callback: any) => {
        let lastStatesCopy = lastStates.slice(0)
        const particle: Particle = outlineParticle.particle
  
        if (lastStatesCopy.push([outlineParticle, last]) && lastStates.length > 0) {
          let line = ""
          // cued on the "was last element" states of whatever we're nested within,
          // we need to append either blankness or a branch to our line
          lastStates.forEach((lastState, idx) => {
            if (idx > 0) line += lastState[1] ? " " : "│"
          })
  
          // the prefix varies cued on whether the key contains something to show and
          // whether we're dealing with the last element in this collection
          // the extra "-" just makes things stand out more.
          line += (last ? "└" : "├") + particleFn(particle)
          callback(line)
        }
  
        if (!particle) return
  
        const length = particle.length
        let index = 0
        particle.forEach(particle => {
          let lastKey = ++index === length
  
          growBranch({ particle: particle }, lastKey, lastStatesCopy, particleFn, callback)
        })
      }
  
      let output = ""
      growBranch({ particle: this }, false, [], particleFn, (line: string) => (output += line + "\n"))
      return output
    }
  
    copyTo(particle: Particle, index: int) {
      return particle._insertBlock(this.toString(), index)
    }
  
    // Note: Splits using a positive lookahead
    // this.split("foo").join("\n") === this.toString()
    split(cue: particlesTypes.atom): Particle[] {
      // todo: cleanup
      const constructor = this._modifiedConstructor || this.constructor
      const ParticleBreakSymbol = this.particleBreakSymbol
      const AtomBreakSymbol = this.atomBreakSymbol
  
      // todo: cleanup. the escaping is wierd.
      return this.toString()
        .split(new RegExp(`\\${ParticleBreakSymbol}(?=${cue}(?:${AtomBreakSymbol}|\\${ParticleBreakSymbol}))`, "g"))
        .map(str => new constructor(str))
    }
  
    get asMarkdownTable(): string {
      return this.toMarkdownTableAdvanced(this._getUnionNames(), (val: string) => val)
    }
  
    toMarkdownTableAdvanced(columns: atom[], formatFn: particlesTypes.formatFunction): string {
      const matrix = this._getMatrix(columns)
      const empty = columns.map(col => "-")
      matrix.unshift(empty)
      matrix.unshift(columns)
      const lines = matrix.map((row, rowIndex) => {
        const formattedValues = row.map((val, colIndex) => formatFn(val, rowIndex, colIndex))
        return `|${formattedValues.join("|")}|`
      })
      return lines.join("\n")
    }
  
    get asTsv(): string {
      return this.toDelimited("\t")
    }
  
    get particleBreakSymbol(): string {
      return PARTICLE_MEMBRANE
    }
  
    get atomBreakSymbol(): string {
      return ATOM_MEMBRANE
    }
  
    get edgeSymbolRegex() {
      return new RegExp(this.edgeSymbol, "g")
    }
  
    get particleBreakSymbolRegex() {
      return new RegExp(this.particleBreakSymbol, "g")
    }
  
    get edgeSymbol(): string {
      return SUBPARTICLE_MEMBRANE
    }
  
    protected _textToContentAndSubparticlesTuple(text: string) {
      const lines = text.split(this.particleBreakSymbolRegex)
      const firstLine = lines.shift()
      const subparticles = !lines.length
        ? undefined
        : lines
            .map(line => (line.substr(0, 1) === this.edgeSymbol ? line : this.edgeSymbol + line))
            .map(line => line.substr(1))
            .join(this.particleBreakSymbol)
      return [firstLine, subparticles]
    }
  
    protected _getLine() {
      return this._line
    }
  
    protected _setLine(line = "") {
      this._line = line
      if (this._atoms) delete this._atoms
      return this
    }
  
    protected _clearSubparticles() {
      this._deleteByIndexes(Utils.getRange(0, this.length))
      delete this._subparticles
      return this
    }
  
    protected _setSubparticles(content: any, circularCheckArray?: any[]) {
      this._clearSubparticles()
      // todo: is this correct? seems like `new Particle("").length` should be 1, not 0.
      if (!content) return this
  
      // set from string
      if (typeof content === "string") {
        this._appendSubparticlesFromString(content)
        return this
      }
  
      // set from particle
      if (content instanceof Particle) {
        content.forEach(particle => this._insertBlock(particle.toString()))
        return this
      }
  
      // If we set from object, create an array of inserted objects to avoid circular loops
      if (!circularCheckArray) circularCheckArray = [content]
  
      return this._setFromObject(content, circularCheckArray)
    }
  
    protected _setFromObject(content: any, circularCheckArray: Object[]) {
      for (let cue in content) {
        if (!content.hasOwnProperty(cue)) continue
        // Branch the circularCheckArray, as we only have same branch circular arrays
        this._appendFromJavascriptObjectTuple(cue, content[cue], circularCheckArray.slice(0))
      }
  
      return this
    }
  
    // todo: refactor the below.
    protected _appendFromJavascriptObjectTuple(cue: particlesTypes.atom, content: any, circularCheckArray: Object[]) {
      const type = typeof content
      let line
      let subparticles
      if (content === null) line = cue + " " + null
      else if (content === undefined) line = cue
      else if (type === "string") {
        const tuple = this._textToContentAndSubparticlesTuple(content)
        line = cue + " " + tuple[0]
        subparticles = tuple[1]
      } else if (type === "function") line = cue + " " + content.toString()
      else if (type !== "object") line = cue + " " + content
      else if (content instanceof Date) line = cue + " " + content.getTime().toString()
      else if (content instanceof Particle) {
        line = cue
        subparticles = new Particle(content.subparticlesToString(), content.getLine())
      } else if (circularCheckArray.indexOf(content) === -1) {
        circularCheckArray.push(content)
        line = cue
        const length = content instanceof Array ? content.length : Object.keys(content).length
        if (length) subparticles = new Particle()._setSubparticles(content, circularCheckArray)
      } else {
        // iirc this is return early from circular
        return
      }
      this._insertBlock(this._makeBlock(line, subparticles))
    }
  
    protected _insertBlock(block: string, index?: number) {
      if (index !== undefined) index = index  parserPool.createParticle(this, block))
    }
  
    private async _appendBlockAsync(block) {
      // We need to keep grapping the parserPool in case it changed.
      // todo: cleanup and perf optimize
      let parserPool = this._getParserPool()
      await parserPool.appendParticleAsync(this, block)
    }
  
    private async _transformAndAppendBlockAsync(block: string): particlesTypes.particle {
      block = block.replace(/\r/g, "") // I hate \r
      const rootParticle = this.root
      if (this._beforeAppend) this._beforeAppend(block) // todo: clean this up and document it.
      if (rootParticle.particleTransformers) {
        // A macro may return multiple new blocks.
        const blocks = splitBlocks(rootParticle._transformBlock(block), SUBPARTICLE_MEMBRANE, PARTICLE_MEMBRANE)
  
        const newParticles: particlesTypes.particle[] = []
        for (const [newBlockIndex, block] of blocks.entries()) {
          const particle = await this._appendBlockAsync(block)
          newParticles.push(particle)
        }
        return newParticles[0]
      }
  
      const newParticle = await this._appendBlockAsync(block)
      return newParticle
    }
  
    async appendFromStream(input) {
      const { edgeSymbol, particleBreakSymbol } = this
  
      let buffer = ""
      const breakRegex = new RegExp(`${particleBreakSymbol}(?!${edgeSymbol})`)
  
      // Node.js Readable stream
      if (typeof process !== "undefined" && input instanceof require("stream").Readable) {
        for await (const chunk of input) {
          buffer += chunk.toString("utf8")
  
          while (true) {
            const breakIndex = buffer.search(breakRegex)
            if (breakIndex === -1) break
  
            const block = buffer.slice(0, breakIndex)
            buffer = buffer.slice(breakIndex + particleBreakSymbol.length)
  
            await this._transformAndAppendBlockAsync(block)
          }
        }
        // Process remaining buffer
        await this._transformAndAppendBlockAsync(buffer)
      }
      // Browser ReadableStream
      else if (typeof ReadableStream !== "undefined" && input instanceof ReadableStream) {
        const reader = input.getReader()
        try {
          while (true) {
            const { done, value } = await reader.read()
            if (done) break
  
            buffer += new TextDecoder().decode(value) // Convert Uint8Array to string
  
            while (true) {
              const breakIndex = buffer.search(breakRegex)
              if (breakIndex === -1) break
  
              const block = buffer.slice(0, breakIndex)
              buffer = buffer.slice(breakIndex + particleBreakSymbol.length)
  
              await this._transformAndAppendBlockAsync(block)
            }
          }
          // Process remaining buffer
          await this._transformAndAppendBlockAsync(buffer)
        } finally {
          reader.releaseLock()
        }
      }
      // Plain string input (works in both environments)
      else if (typeof input === "string") {
        buffer = input
        while (true) {
          const breakIndex = buffer.search(breakRegex)
          if (breakIndex === -1) break
  
          const block = buffer.slice(0, breakIndex)
          buffer = buffer.slice(breakIndex + particleBreakSymbol.length)
  
          await this._transformAndAppendBlockAsync(block)
        }
        await this._transformAndAppendBlockAsync(buffer)
      } else {
        throw new Error("Unsupported input type. Expected string, Node.js Readable, or ReadableStream.")
      }
    }
  
    protected _getCueIndex() {
      // StringMap {cue: index}
      // When there are multiple tails with the same cue, index stores the last content.
      // todo: change the above behavior: when a collision occurs, create an array.
      return this._cueIndex || this._makeCueIndex()
    }
  
    getContentsArray() {
      return this.map(particle => particle.content)
    }
  
    getSubparticlesByParser(parser: Function) {
      return this.filter(subparticle => subparticle instanceof parser)
    }
  
    getAncestorByParser(parser: Function): Particle | undefined {
      if (this instanceof parser) return this
      if (this.isRoot()) return undefined
      const parent = this.parent
      return parent instanceof parser ? parent : parent.getAncestorByParser(parser)
    }
  
    getParticleByParser(parser: Function) {
      return this.find(subparticle => subparticle instanceof parser)
    }
  
    // todo: switch to native classes and parsers in particles and away from javascript classes for parsing.
    // move off particle.ts
    // make the below work.
    // By default every particle has a parser. By default they all match to the first particle.
    get parser() {
      return this._parser || this.root.particleAt(0)
    }
  
    // The parserId of a particle at the moment is defined as the cue of the parser it is matched to.
    get parserId() {
      return this.parser.cue
    }
  
    indexOfLast(cue: atom): int {
      const result = this._getCueIndex()[cue]
      return result === undefined ? -1 : result
    }
  
    // todo: renmae to indexOfFirst?
    indexOf(cue: atom): int {
      if (!this.has(cue)) return -1
  
      const length = this.length
      const particles = this._getSubparticlesArray()
  
      for (let index = 0; index  particle.cue)
    }
  
    protected _makeCueIndex(startAt = 0) {
      if (!this._cueIndex || !startAt) this._cueIndex = {}
      const particles = this._getSubparticlesArray()
      const newIndex = this._cueIndex
      const length = particles.length
  
      for (let index = startAt; index  particle._toXml(indentCount)).join("")
    }
  
    clone(subparticles = this.subparticlesToString(), line = this.getLine()): Particle {
      return new (this.constructor)(subparticles, line)
    }
  
    hasCue(cue: atom): boolean {
      return this._hasCue(cue)
    }
  
    has(cuePath: particlesTypes.cuePath): boolean {
      const edgeSymbol = this.edgeSymbol
      if (!cuePath.includes(edgeSymbol)) return this.hasCue(cuePath)
  
      const parts = cuePath.split(edgeSymbol)
      const next = this.getParticle(parts.shift())
      if (!next) return false
      return next.has(parts.join(edgeSymbol))
    }
  
    hasParticle(particle: Particle | string): boolean {
      const needle = particle.toString()
      return this.getSubparticles().some(particle => particle.toString() === needle)
    }
  
    protected _hasCue(cue: string) {
      return this._getCueIndex()[cue] !== undefined
    }
  
    map(fn: mapFn) {
      return this.getSubparticles().map(fn)
    }
  
    filter(fn: particlesTypes.filterFn = item => item) {
      return this.getSubparticles().filter(fn)
    }
  
    find(fn: particlesTypes.filterFn) {
      return this.getSubparticles().find(fn)
    }
  
    findLast(fn: particlesTypes.filterFn) {
      return this.getSubparticles().reverse().find(fn)
    }
  
    every(fn: particlesTypes.everyFn) {
      let index = 0
      for (let particle of this.getTopDownArrayIterator()) {
        if (!fn(particle, index)) return false
        index++
      }
      return true
    }
  
    forEach(fn: particlesTypes.forEachFn) {
      this.getSubparticles().forEach(fn)
      return this
    }
  
    // Recurse if predicate passes
    deepVisit(predicate: (particle: any) => boolean) {
      this.forEach(particle => {
        if (predicate(particle) !== false) particle.deepVisit(predicate)
      })
    }
  
    _quickCache: particlesTypes.stringMap
    get quickCache() {
      if (!this._quickCache) this._quickCache = {}
      return this._quickCache
    }
  
    getCustomIndex(key: string) {
      if (!this.quickCache.customIndexes) this.quickCache.customIndexes = {}
      const customIndexes = this.quickCache.customIndexes
      if (customIndexes[key]) return customIndexes[key]
      const customIndex: { [cue: string]: Particle[] } = {}
      customIndexes[key] = customIndex
      this.filter(file => file.has(key)).forEach(file => {
        const value = file.get(key)
        if (!customIndex[value]) customIndex[value] = []
        customIndex[value].push(file)
      })
      return customIndex
    }
  
    clearQuickCache() {
      delete this._quickCache
    }
  
    // todo: protected?
    _clearCueIndex() {
      delete this._cueIndex
      this.clearQuickCache()
    }
  
    slice(start: int, end?: int): Particle[] {
      return this.getSubparticles().slice(start, end)
    }
  
    // todo: make 0 and 1 a param
    getInheritanceParticles() {
      const paths: particlesTypes.stringMap = {}
      const result = new Particle()
      this.forEach(particle => {
        const key = particle.getAtom(0)
        const parentKey = particle.getAtom(1)
        const parentPath = paths[parentKey]
        paths[key] = parentPath ? [parentPath, key].join(" ") : key
        result.touchParticle(paths[key])
      })
      return result
    }
  
    protected _getGrandParent(): Particle | undefined {
      return this.isRoot() || this.parent.isRoot() ? undefined : this.parent.parent
    }
  
    private static _parserPoolsCache = new Map()
  
    private _parserPool?: ParserPool
    _getParserPool() {
      if (this._parserPool) return this._parserPool
      if (!Particle._parserPoolsCache.has(this.constructor)) Particle._parserPoolsCache.set(this.constructor, this.createParserPool())
      return Particle._parserPoolsCache.get(this.constructor)
    }
  
    createParserPool(): ParserPool {
      return new ParserPool(this.constructor)
    }
  
    private static _uniqueId: int
  
    static _makeUniqueId() {
      if (this._uniqueId === undefined) this._uniqueId = 0
      this._uniqueId++
      return this._uniqueId
    }
  
    protected static _getFileFormat(path: string) {
      const format = path.split(".").pop()
      return (FileFormat)[format] ? format : FileFormat.particles
    }
  
    static ParserPool = ParserPool
  
    static iris = `sepal_length,sepal_width,petal_length,petal_width,species
  6.1,3,4.9,1.8,virginica
  5.6,2.7,4.2,1.3,versicolor
  5.6,2.8,4.9,2,virginica
  6.2,2.8,4.8,1.8,virginica
  7.7,3.8,6.7,2.2,virginica
  5.3,3.7,1.5,0.2,setosa
  6.2,3.4,5.4,2.3,virginica
  4.9,2.5,4.5,1.7,virginica
  5.1,3.5,1.4,0.2,setosa
  5,3.4,1.5,0.2,setosa`
  
    // BEGIN MUTABLE METHODS BELOw
  
    private _particleCreationTime: number = this._getProcessTimeInMilliseconds()
    private _lineModifiedTime: number
    private _subparticleArrayModifiedTime: number
  
    getLineModifiedTime(): number {
      return this._lineModifiedTime || this._particleCreationTime
    }
  
    getChildArrayModifiedTime() {
      return this._subparticleArrayModifiedTime || this._particleCreationTime
    }
  
    protected _setChildArrayMofifiedTime(value: number) {
      this._subparticleArrayModifiedTime = value
      return this
    }
  
    getLineOrSubparticlesModifiedTime(): number {
      return Math.max(
        this.getLineModifiedTime(),
        this.getChildArrayModifiedTime(),
        Math.max.apply(
          null,
          this.map(subparticle => subparticle.getLineOrSubparticlesModifiedTime())
        )
      )
    }
  
    private _virtualParentParticle: Particle
    protected _setVirtualParentParticle(particle: Particle) {
      this._virtualParentParticle = particle
      return this
    }
  
    protected _getVirtualParentParticle() {
      return this._virtualParentParticle
    }
  
    private _setVirtualAncestorParticlesByInheritanceViaColumnIndicesAndThenExpand(particles: Particle[], thisIdColumnNumber: int, extendsIdColumnNumber: int) {
      const map: { [particleId: string]: particlesTypes.inheritanceInfo } = {}
      for (let particle of particles) {
        const particleId = particle.getAtom(thisIdColumnNumber)
        if (map[particleId]) throw new Error(`Tried to define a particle with id "${particleId}" but one is already defined.`)
        map[particleId] = {
          particleId: particleId,
          particle: particle,
          parentId: particle.getAtom(extendsIdColumnNumber)
        }
      }
      // Add parent Particles
      Object.values(map).forEach(particleInfo => {
        const parentId = particleInfo.parentId
        const parentParticle = map[parentId]
        if (parentId && !parentParticle) throw new Error(`Particle "${particleInfo.particleId}" tried to extend "${parentId}" but "${parentId}" not found.`)
        if (parentId) particleInfo.particle._setVirtualParentParticle(parentParticle.particle)
      })
  
      particles.forEach(particle => particle._expandFromVirtualParentParticle())
      return this
    }
  
    private _isVirtualExpanded: boolean
    private _isExpanding: boolean // for loop detection
  
    protected _expandFromVirtualParentParticle() {
      if (this._isVirtualExpanded) return this
  
      this._isExpanding = true
  
      let parentParticle = this._getVirtualParentParticle()
      if (parentParticle) {
        if (parentParticle._isExpanding) throw new Error(`Loop detected: '${this.getLine()}' is the ancestor of one of its ancestors.`)
        parentParticle._expandFromVirtualParentParticle()
        const clone = this.clone()
        this._setSubparticles(parentParticle.subparticlesToString())
        this.extend(clone)
      }
  
      this._isExpanding = false
      this._isVirtualExpanded = true
    }
  
    // todo: solve issue related to whether extend should overwrite or append.
    _expandSubparticles(thisIdColumnNumber: int, extendsIdColumnNumber: int, subparticlesThatNeedExpanding = this.getSubparticles()) {
      return this._setVirtualAncestorParticlesByInheritanceViaColumnIndicesAndThenExpand(subparticlesThatNeedExpanding, thisIdColumnNumber, extendsIdColumnNumber)
    }
  
    // todo: add more testing.
    // todo: solve issue with where extend should overwrite or append
    // todo: should take a parsers? to decide whether to overwrite or append.
    // todo: this is slow.
    extend(particleOrStr: Particle | string | Object) {
      const particle = particleOrStr instanceof Particle ? particleOrStr : new Particle(particleOrStr)
      const usedCues = new Set()
      particle.forEach(sourceParticle => {
        const cue = sourceParticle.cue
        let targetParticle
        const isAnArrayNotMap = usedCues.has(cue)
        if (!this.has(cue)) {
          usedCues.add(cue)
          this.appendLineAndSubparticles(sourceParticle.getLine(), sourceParticle.subparticlesToString())
          return true
        }
        if (isAnArrayNotMap) targetParticle = this.appendLine(sourceParticle.getLine())
        else {
          targetParticle = this.touchParticle(cue).setContent(sourceParticle.content)
          usedCues.add(cue)
        }
        if (sourceParticle.length) targetParticle.extend(sourceParticle)
      })
      return this
    }
  
    lastParticle(): Particle {
      return this.getSubparticles()[this.length - 1]
    }
  
    expandLastFromTopMatter(): Particle {
      const clone = this.clone()
      const map = new Map()
      const lastParticle = clone.lastParticle()
      lastParticle.getOlderSiblings().forEach(particle => map.set(particle.getAtom(0), particle))
      lastParticle.topDownArray.forEach(particle => {
        const replacement = map.get(particle.getAtom(0))
        if (!replacement) return
  
        particle.replaceParticle(str => replacement.toString())
      })
      return lastParticle
    }
  
    macroExpand(macroDefinitionAtom: string, macroUsageAtom: string): Particle {
      const clone = this.clone()
      const defs = clone.findParticles(macroDefinitionAtom)
      const allUses = clone.findParticles(macroUsageAtom)
      const atomBreakSymbol = clone.atomBreakSymbol
      defs.forEach(def => {
        const macroName = def.getAtom(1)
        const uses = allUses.filter(particle => particle.hasAtom(1, macroName))
        const params = def.getAtomsFrom(2)
        const replaceFn = (str: string) => {
          const paramValues = str.split(atomBreakSymbol).slice(2)
          let newParticle = def.subparticlesToString()
          params.forEach((param, index) => {
            newParticle = newParticle.replace(new RegExp(param, "g"), paramValues[index])
          })
          return newParticle
        }
        uses.forEach(particle => {
          particle.replaceParticle(replaceFn)
        })
        def.destroy()
      })
      return clone
    }
  
    setSubparticles(subparticles: particlesTypes.subparticles) {
      return this._setSubparticles(subparticles)
    }
  
    protected _updateLineModifiedTimeAndTriggerEvent() {
      this._lineModifiedTime = this._getProcessTimeInMilliseconds()
    }
  
    insertAtom(index: int, atom: string) {
      const wi = this.atomBreakSymbol
      const atoms = this._getLine().split(wi)
      atoms.splice(index, 0, atom)
      this.setLine(atoms.join(wi))
      return this
    }
  
    deleteDuplicates() {
      const set = new Set()
      this.topDownArray.forEach(particle => {
        const str = particle.toString()
        if (set.has(str)) particle.destroy()
        else set.add(str)
      })
      return this
    }
  
    setAtom(index: int, atom: string) {
      const wi = this.atomBreakSymbol
      const atoms = this._getLine().split(wi)
      atoms[index] = atom
      this.setLine(atoms.join(wi))
      return this
    }
  
    deleteSubparticles() {
      return this._clearSubparticles()
    }
  
    setContent(content: string): Particle {
      if (content === this.content) return this
      const newArray = [this.cue]
      if (content !== undefined) {
        content = content.toString()
        if (content.match(this.particleBreakSymbol)) return this.setContentWithSubparticles(content)
        newArray.push(content)
      }
      this._setLine(newArray.join(this.atomBreakSymbol))
      this._updateLineModifiedTimeAndTriggerEvent()
      return this
    }
  
    prependSibling(line: string, subparticles: string) {
      return this.parent.insertLineAndSubparticles(line, subparticles, this.index)
    }
  
    appendSibling(line: string, subparticles: string) {
      return this.parent.insertLineAndSubparticles(line, subparticles, this.index + 1)
    }
  
    setContentWithSubparticles(text: string) {
      // todo: deprecate
      if (!text.includes(this.particleBreakSymbol)) {
        this._clearSubparticles()
        return this.setContent(text)
      }
  
      const lines = text.split(this.particleBreakSymbolRegex)
      const firstLine = lines.shift()
      this.setContent(firstLine)
  
      // tood: cleanup.
      const remainingString = lines.join(this.particleBreakSymbol)
      const subparticles = new Particle(remainingString)
      if (!remainingString) subparticles.appendLine("")
      this.setSubparticles(subparticles)
      return this
    }
  
    setCue(cue: atom) {
      return this.setAtom(0, cue)
    }
  
    setLine(line: string) {
      if (line === this.getLine()) return this
      // todo: clear parent TMTimes
      this.parent._clearCueIndex()
      this._setLine(line)
      this._updateLineModifiedTimeAndTriggerEvent()
      return this
    }
  
    duplicate() {
      return this.parent._insertBlock(this.toString(), this.index + 1)
    }
  
    trim() {
      // todo: could do this so only the trimmed rows are deleted.
      this.setSubparticles(this.subparticlesToString().trim())
      return this
    }
  
    destroy() {
      ;(this.parent as Particle)._deleteParticle(this)
    }
  
    set(cuePath: particlesTypes.cuePath, text: string) {
      return this.touchParticle(cuePath).setContentWithSubparticles(text)
    }
  
    setFromText(text: string) {
      if (this.toString() === text) return this
      const tuple = this._textToContentAndSubparticlesTuple(text)
      this.setLine(tuple[0])
      return this._setSubparticles(tuple[1])
    }
  
    setPropertyIfMissing(prop: string, value: string) {
      if (this.has(prop)) return true
      return this.touchParticle(prop).setContent(value)
    }
  
    setProperties(propMap: particlesTypes.stringMap) {
      const props = Object.keys(propMap)
      const values = Object.values(propMap)
      // todo: is there a built in particle method to do this?
      props.forEach((prop, index) => {
        const value = values[index]
        if (!value) return true
        if (this.get(prop) === value) return true
        this.touchParticle(prop).setContent(value)
      })
      return this
    }
  
    // todo: throw error if line contains a \n
    appendLine(line: string) {
      return this._insertBlock(line)
    }
  
    appendUniqueLine(line: string) {
      if (!this.hasLine(line)) return this.appendLine(line)
      return this.findLine(line)
    }
  
    appendLineAndSubparticles(line: string, subparticles: particlesTypes.subparticles) {
      return this._insertBlock(this._makeBlock(line, subparticles))
    }
  
    appendBlocks(blocks: string) {
      return this._appendSubparticlesFromString(blocks)
    }
  
    _makeBlock(line: string, subparticles: particlesTypes.subparticles) {
      if (subparticles === undefined) return line
      const particle = new Particle(subparticles, line)
      return particle._toStringWithLine()
    }
  
    getParticlesByRegex(regex: RegExp | RegExp[]) {
      const matches: Particle[] = []
      regex = regex instanceof RegExp ? [regex] : regex
      this._getParticlesByLineRegex(matches, regex)
      return matches
    }
  
    // todo: remove?
    getParticlesByLinePrefixes(columns: string[]) {
      const matches: Particle[] = []
      this._getParticlesByLineRegex(
        matches,
        columns.map(str => new RegExp("^" + str))
      )
      return matches
    }
  
    particlesThatStartWith(prefix: string) {
      return this.filter(particle => particle.getLine().startsWith(prefix))
    }
  
    protected _getParticlesByLineRegex(matches: Particle[], regs: RegExp[]) {
      const rgs = regs.slice(0)
      const reg = rgs.shift()
      const candidates = this.filter(subparticle => subparticle.getLine().match(reg))
      if (!rgs.length) return candidates.forEach(cand => matches.push(cand))
      candidates.forEach(cand => (cand)._getParticlesByLineRegex(matches, rgs))
    }
  
    concat(particle: string | Particle) {
      if (typeof particle === "string") particle = new Particle(particle)
      return particle.map(particle => this._insertBlock(particle.toString()))
    }
  
    protected _deleteByIndexes(indexesToDelete: int[]) {
      if (!indexesToDelete.length) return this
      this._clearCueIndex()
      // note: assumes indexesToDelete is in ascending order
      const deletedParticles = indexesToDelete.reverse().map(index => this._getSubparticlesArray().splice(index, 1)[0])
      this._setChildArrayMofifiedTime(this._getProcessTimeInMilliseconds())
      return this
    }
  
    protected _deleteParticle(particle: Particle) {
      const index = this._indexOfParticle(particle)
      return index > -1 ? this._deleteByIndexes([index]) : 0
    }
  
    reverse() {
      this._clearCueIndex()
      this._getSubparticlesArray().reverse()
      return this
    }
  
    shift() {
      if (!this.length) return null
      const particle = this._getSubparticlesArray().shift()
      return particle.copyTo(new (this.constructor)(), 0)
    }
  
    sort(fn: particlesTypes.sortFn) {
      this._getSubparticlesArray().sort(fn)
      this._clearCueIndex()
      return this
    }
  
    invert() {
      this.forEach(particle => particle.atoms.reverse())
      return this
    }
  
    protected _rename(oldCue: particlesTypes.atom, newCue: particlesTypes.atom) {
      const index = this.indexOf(oldCue)
  
      if (index === -1) return this
  
      const particle = this._getSubparticlesArray()[index]
  
      particle.setCue(newCue)
      this._clearCueIndex()
      return this
    }
  
    // Does not recurse.
    remap(map: particlesTypes.stringMap) {
      this.forEach(particle => {
        const cue = particle.cue
        if (map[cue] !== undefined) particle.setCue(map[cue])
      })
      return this
    }
  
    rename(oldCue: atom, newCue: atom) {
      this._rename(oldCue, newCue)
      return this
    }
  
    renameAll(oldName: atom, newName: atom) {
      this.findParticles(oldName).forEach(particle => particle.setCue(newName))
      return this
    }
  
    protected _deleteAllChildParticlesWithCue(cue: atom) {
      if (!this.has(cue)) return this
      const allParticles = this._getSubparticlesArray()
      const indexesToDelete: int[] = []
      allParticles.forEach((particle, index) => {
        if (particle.cue === cue) indexesToDelete.push(index)
      })
      return this._deleteByIndexes(indexesToDelete)
    }
  
    delete(path: particlesTypes.cuePath = "") {
      const edgeSymbol = this.edgeSymbol
      if (!path.includes(edgeSymbol)) return this._deleteAllChildParticlesWithCue(path)
  
      const parts = path.split(edgeSymbol)
      const nextCue = parts.pop()
      const targetParticle = this.getParticle(parts.join(edgeSymbol))
  
      return targetParticle ? targetParticle._deleteAllChildParticlesWithCue(nextCue) : 0
    }
  
    deleteColumn(cue = "") {
      this.forEach(particle => particle.delete(cue))
      return this
    }
  
    protected _getNonMaps(): Particle[] {
      const results = this.topDownArray.filter(particle => particle.hasDuplicateCues())
      if (this.hasDuplicateCues()) results.unshift(this)
      return results
    }
  
    replaceWith(blocks: string) {
      const split = splitBlocks(blocks, SUBPARTICLE_MEMBRANE, PARTICLE_MEMBRANE).reverse()
      const parent = this.parent
      const index = this.index
      const newParticles = split.map((block, newBlockIndex) => parent._insertBlock(block, index))
      this.destroy()
      return newParticles
    }
  
    replaceParticle(fn: (thisStr: string) => string) {
      const parent = this.parent
      const index = this.index
      const newParticles = new Particle(fn(this.toString()))
      const returnedParticles: Particle[] = []
      newParticles.forEach((subparticle, subparticleIndex) => {
        const newParticle = parent.insertLineAndSubparticles(subparticle.getLine(), subparticle.subparticlesToString(), index + subparticleIndex)
        returnedParticles.push(newParticle)
      })
      this.destroy()
      return returnedParticles
    }
  
    insertLineAndSubparticles(line: string, subparticles: particlesTypes.subparticles, index: int) {
      return this._insertBlock(this._makeBlock(line, subparticles), index)
    }
  
    insertLine(line: string, index: int) {
      return this._insertBlock(line, index)
    }
  
    insertSection(lines: string, index: int) {
      return this._insertBlock(lines, index)
    }
  
    prependLine(line: string) {
      return this.insertLine(line, 0)
    }
  
    pushContentAndSubparticles(content?: particlesTypes.line, subparticles?: particlesTypes.subparticles) {
      let index = this.length
  
      while (this.has(index.toString())) {
        index++
      }
      const line = index.toString() + (content === undefined ? "" : this.atomBreakSymbol + content)
      return this.appendLineAndSubparticles(line, subparticles)
    }
  
    deleteBlanks() {
      this.getSubparticles()
        .filter(particle => particle.isBlankLine())
        .forEach(particle => (particle).destroy())
      return this
    }
  
    // todo: add "globalReplace" method? Which runs a global regex or string replace on the Particle as a string?
  
    cueSort(cueOrder: particlesTypes.atom[]): this {
      return this._cueSort(cueOrder)
    }
  
    deleteAtomAt(atomIndex: particlesTypes.positiveInt): this {
      const atoms = this.atoms
      atoms.splice(atomIndex, 1)
      return this.setAtoms(atoms)
    }
  
    private _listeners: Map
  
    trigger(event: AbstractParticleEvent) {
      if (this._listeners && this._listeners.has(event.constructor)) {
        const listeners = this._listeners.get(event.constructor)
        const listenersToRemove: int[] = []
        for (let index = 0; index  listenersToRemove.splice(index, 1))
      }
    }
  
    triggerAncestors(event: AbstractParticleEvent) {
      if (this.isRoot()) return
      const parent = this.parent
      parent.trigger(event)
      parent.triggerAncestors(event)
    }
  
    onLineChanged(eventHandler: ParticleEventHandler) {
      return this._addEventListener(LineChangedParticleEvent, eventHandler)
    }
  
    onDescendantChanged(eventHandler: ParticleEventHandler) {
      return this._addEventListener(DescendantChangedParticleEvent, eventHandler)
    }
  
    onChildAdded(eventHandler: ParticleEventHandler) {
      return this._addEventListener(ChildAddedParticleEvent, eventHandler)
    }
  
    onChildRemoved(eventHandler: ParticleEventHandler) {
      return this._addEventListener(ChildRemovedParticleEvent, eventHandler)
    }
  
    private _addEventListener(eventClass: any, eventHandler: ParticleEventHandler) {
      if (!this._listeners) this._listeners = new Map()
      if (!this._listeners.has(eventClass)) this._listeners.set(eventClass, [])
      this._listeners.get(eventClass).push(eventHandler)
      return this
    }
  
    setAtoms(atoms: particlesTypes.atom[]): this {
      return this.setLine(atoms.join(this.atomBreakSymbol))
    }
  
    setAtomsFrom(index: particlesTypes.positiveInt, atoms: particlesTypes.atom[]): this {
      this.setAtoms(this.atoms.slice(0, index).concat(atoms))
      return this
    }
  
    appendAtom(atom: particlesTypes.atom): this {
      const atoms = this.atoms
      atoms.push(atom)
      return this.setAtoms(atoms)
    }
  
    _cueSort(cueOrder: particlesTypes.atom[], secondarySortFn?: particlesTypes.sortFn): this {
      const particleAFirst = -1
      const particleBFirst = 1
      const map: { [cue: string]: int } = {}
      cueOrder.forEach((atom, index) => {
        map[atom] = index
      })
      this.sort((particleA, particleB) => {
        const valA = map[particleA.cue]
        const valB = map[particleB.cue]
        if (valA > valB) return particleBFirst
        if (valA  {
        contextParticle = contextParticle.getParticle(cue) || contextParticle.appendLine(cue)
      })
      return contextParticle
    }
  
    protected _touchParticleByString(str: string) {
      str = str.replace(this.particleBreakSymbolRegex, "") // todo: do we want to do this sanitization?
      return this._touchParticle(str.split(this.atomBreakSymbol))
    }
  
    touchParticle(str: particlesTypes.cuePath) {
      return this._touchParticleByString(str)
    }
  
    appendParticle(particle: Particle) {
      return this.appendLineAndSubparticles(particle.getLine(), particle.subparticlesToString())
    }
  
    hasLine(line: particlesTypes.line) {
      return this.getSubparticles().some(particle => particle.getLine() === line)
    }
  
    findLine(line: particlesTypes.line) {
      return this.getSubparticles().find(particle => particle.getLine() === line)
    }
  
    getParticlesByLine(line: particlesTypes.line) {
      return this.filter(particle => particle.getLine() === line)
    }
  
    toggleLine(line: particlesTypes.line): Particle {
      const lines = this.getParticlesByLine(line)
      if (lines.length) {
        lines.map(line => line.destroy())
        return this
      }
  
      return this.appendLine(line)
    }
  
    // todo: remove?
    sortByColumns(indexOrIndices: int | int[]) {
      const indices = indexOrIndices instanceof Array ? indexOrIndices : [indexOrIndices]
  
      const length = indices.length
      this.sort((particleA, particleB) => {
        const atomsA = particleA.atoms
        const atomsB = particleB.atoms
  
        for (let index = 0; index  bv) return 1
          else if (av 
        Object.values(item)
          .join(delimiter)
          .replace(/[\n\r]/g, "")
      )
      return this.addUniqueRowsToNestedDelimited(header, rows)
    }
  
    setSubparticlesAsDelimited(particle: Particle | string, delimiter = Utils._chooseDelimiter(particle.toString())) {
      particle = particle instanceof Particle ? particle : new Particle(particle)
      return this.setSubparticles(particle.toDelimited(delimiter))
    }
  
    convertSubparticlesToDelimited(delimiter = Utils._chooseDelimiter(this.subparticlesToString())) {
      // todo: handle newlines!!!
      return this.setSubparticles(this.toDelimited(delimiter))
    }
  
    addUniqueRowsToNestedDelimited(header: string, rowsAsStrings: string[]) {
      if (!this.length) this.appendLine(header)
  
      // todo: this looks brittle
      rowsAsStrings.forEach(row => {
        if (!this.toString().includes(row)) this.appendLine(row)
      })
  
      return this
    }
  
    shiftLeft(): Particle {
      const grandParent = this._getGrandParent()
      if (!grandParent) return this
  
      const parentIndex = this.parent.index
      const newParticle = grandParent.insertLineAndSubparticles(this.getLine(), this.length ? this.subparticlesToString() : undefined, parentIndex + 1)
      this.destroy()
      return newParticle
    }
  
    pasteText(text: string) {
      const parent = this.parent
      const index = this.index
      const newParticles = new Particle(text)
      const firstParticle = newParticles.particleAt(0)
      if (firstParticle) {
        this.setLine(firstParticle.getLine())
        if (firstParticle.length) this.setSubparticles(firstParticle.subparticlesToString())
      } else {
        this.setLine("")
      }
      newParticles.forEach((subparticle, subparticleIndex) => {
        if (!subparticleIndex)
          // skip first
          return true
        parent.insertLineAndSubparticles(subparticle.getLine(), subparticle.subparticlesToString(), index + subparticleIndex)
      })
      return this
    }
  
    templateToString(obj: particlesTypes.stringMap): string {
      // todo: compile/cache for perf?
      const particle = this.clone()
      particle.topDownArray.forEach(particle => {
        const line = particle.getLine().replace(/{([^\}]+)}/g, (match, path) => {
          const replacement = obj[path]
          if (replacement === undefined) throw new Error(`In string template no match found on line "${particle.getLine()}"`)
          return replacement
        })
        particle.pasteText(line)
      })
      return particle.toString()
    }
  
    shiftRight(): Particle {
      const olderSibling = this._getClosestOlderSibling()
      if (!olderSibling) return this
  
      const newParticle = olderSibling.appendLineAndSubparticles(this.getLine(), this.length ? this.subparticlesToString() : undefined)
      this.destroy()
      return newParticle
    }
  
    shiftYoungerSibsRight(): Particle {
      const particles = this.getYoungerSiblings()
      particles.forEach(particle => particle.shiftRight())
      return this
    }
  
    sortBy(nameOrNames: particlesTypes.atom[]) {
      const names = nameOrNames instanceof Array ? nameOrNames : [nameOrNames]
  
      const length = names.length
      this.sort((particleA, particleB) => {
        if (!particleB.length && !particleA.length) return 0
        else if (!particleA.length) return -1
        else if (!particleB.length) return 1
  
        for (let index = 0; index  bv) return 1
          else if (av  {
          newParticle.appendParticle(this.serializedParticleToParticle(subparticle))
        })
      return newParticle
    }
  
    static fromJson(str: particlesTypes.serializedParticle) {
      return this.serializedParticleToParticle(JSON.parse(str))
    }
  
    static fromGridJson(str: string) {
      const lines = JSON.parse(str)
      const language = new Particle()
      const atomDelimiter = language.atomBreakSymbol
      const particleDelimiter = language.particleBreakSymbol
      return new Particle(lines.map((line: any) => line.join(atomDelimiter)).join(particleDelimiter))
    }
  
    static fromSsv(str: string) {
      return this.fromDelimited(str, " ", '"')
    }
  
    static fromTsv(str: string) {
      return this.fromDelimited(str, "\t", '"')
    }
  
    static fromDelimited(str: string, delimiter: string, quoteChar: string = '"') {
      str = str.replace(/\r/g, "") // remove windows newlines if present
      const rows = this._getEscapedRows(str, delimiter, quoteChar)
      return this._rowsToParticle(rows, delimiter, true)
    }
  
    static _getEscapedRows(str: string, delimiter: string, quoteChar: string) {
      return str.includes(quoteChar) ? this._strToRows(str, delimiter, quoteChar) : str.split("\n").map(line => line.split(delimiter))
    }
  
    static fromDelimitedNoHeaders(str: string, delimiter: string, quoteChar: string) {
      str = str.replace(/\r/g, "") // remove windows newlines if present
      const rows = this._getEscapedRows(str, delimiter, quoteChar)
      return this._rowsToParticle(rows, delimiter, false)
    }
  
    static _strToRows(str: string, delimiter: string, quoteChar: string, newLineChar = "\n") {
      const rows: string[][] = [[]]
      const newLine = "\n"
      const length = str.length
      let currentAtom = ""
      let inQuote = str.substr(0, 1) === quoteChar
      let currentPosition = inQuote ? 1 : 0
      let nextChar
      let isLastChar
      let currentRow = 0
      let char
      let isNextCharAQuote
  
      while (currentPosition  {
        particle.setSubparticles(particle.length ? this.multiply(particle, particleB) : particleB.clone())
      })
      return productParticle
    }
  
    // Given an array return a particle
    static _rowsToParticle(rows: string[][], delimiter: string, hasHeaders: boolean) {
      const numberOfColumns = rows[0].length
      const particle = new Particle()
      const names = this._getHeader(rows, hasHeaders)
  
      const rowCount = rows.length
      for (let rowIndex = hasHeaders ? 1 : 0; rowIndex  numberOfColumns) {
          row[numberOfColumns - 1] = row.slice(numberOfColumns - 1).join(delimiter)
          row = row.slice(0, numberOfColumns)
        } else if (row.length  {
          obj[names[index]] = atomValue
        })
  
        particle.pushContentAndSubparticles(undefined, obj)
      }
      return particle
    }
  
    // todo: cleanup. add types
    private static _xmlParser: any
  
    static _initializeXmlParser() {
      if (this._xmlParser) return
      const windowObj = window
  
      if (typeof windowObj.DOMParser !== "undefined") this._xmlParser = (xmlStr: string) => new windowObj.DOMParser().parseFromString(xmlStr, "text/xml")
      else if (typeof windowObj.ActiveXObject !== "undefined" && new windowObj.ActiveXObject("Microsoft.XMLDOM")) {
        this._xmlParser = (xmlStr: string) => {
          const xmlDoc = new windowObj.ActiveXObject("Microsoft.XMLDOM")
          xmlDoc.async = "false"
          xmlDoc.loadXML(xmlStr)
          return xmlDoc
        }
      } else throw new Error("No XML parser found")
    }
  
    static fromXml(str: string) {
      this._initializeXmlParser()
      const xml = this._xmlParser(str)
  
      try {
        return this._particleFromXml(xml).getParticle("subparticles")
      } catch (err) {
        return this._particleFromXml(this._parseXml2(str)).getParticle("subparticles")
      }
    }
  
    static _zipObject(keys: string[], values: any) {
      const obj: particlesTypes.stringMap = {}
      keys.forEach((key, index) => (obj[key] = values[index]))
      return obj
    }
  
    static fromShape(shapeArr: int[], rootParticle = new Particle()) {
      const part = shapeArr.shift()
      if (part !== undefined) {
        for (let index = 0; index  Particle.fromShape(shapeArr.slice(0), particle))
  
      return rootParticle
    }
  
    static fromDataTable(table: particlesTypes.dataTable) {
      const header = table.shift()
      return new Particle(table.map(row => this._zipObject(header, row)))
    }
  
    static _parseXml2(str: string) {
      const el = document.createElement("div")
      el.innerHTML = str
      return el
    }
  
    // todo: cleanup typings
    static _particleFromXml(xml: any) {
      const result = new Particle()
      const subparticles = new Particle()
  
      // Set attributes
      if (xml.attributes) {
        for (let index = 0; index  0) {
        for (let index = 0; index  0 && child.tagName) subparticles.appendLineAndSubparticles(child.tagName, this._particleFromXml(child))
          else if (child.tagName) subparticles.appendLine(child.tagName)
          else if (child.data) {
            const data = child.data.trim()
            if (data) subparticles.pushContentAndSubparticles(data)
          }
        }
      }
  
      if (subparticles.length > 0) result.touchParticle("subparticles").setSubparticles(subparticles)
  
      return result
    }
  
    static _getHeader(rows: string[][], hasHeaders: boolean) {
      const numberOfColumns = rows[0].length
      const headerRow = hasHeaders ? rows[0] : []
      const AtomBreakSymbol = " "
      const ziRegex = new RegExp(AtomBreakSymbol, "g")
  
      if (hasHeaders) {
        // Strip any AtomBreakSymbols from column names in the header row.
        // This makes the mapping not quite 1 to 1 if there are any AtomBreakSymbols in names.
        for (let index = 0; index  "107.0.0"
  
    static fromDisk(path: string): Particle {
      const format = this._getFileFormat(path)
      const content = require("fs").readFileSync(path, "utf8")
      const methods: { [kind: string]: (content: string) => Particle } = {
        particles: (content: string) => new Particle(content),
        csv: (content: string) => this.fromCsv(content),
        tsv: (content: string) => this.fromTsv(content)
      }
  
      if (!methods[format]) throw new Error(`No support for '${format}'`)
  
      return methods[format](content)
    }
  
    static fromFolder(folderPath: string, filepathPredicate = (filepath: string) => filepath !== ".DS_Store"): Particle {
      const path = require("path")
      const fs = require("fs")
      const particle = new Particle()
      const files = fs
        .readdirSync(folderPath)
        .map((filename: string) => path.join(folderPath, filename))
        .filter((filepath: string) => !fs.statSync(filepath).isDirectory() && filepathPredicate(filepath))
        .forEach((filePath: string) => particle.appendLineAndSubparticles(filePath, fs.readFileSync(filePath, "utf8")))
      return particle
    }
  }
  
  abstract class AbstractExtendibleParticle extends Particle {
    _getFromExtended(cuePath: particlesTypes.cuePath) {
      const hit = this._getParticleFromExtended(cuePath)
      return hit ? hit.get(cuePath) : undefined
    }
  
    _getLineage() {
      const newParticle = new Particle()
      this.forEach(particle => {
        const path = particle._getAncestorsArray().map((particle: AbstractExtendibleParticle) => particle.id)
        path.reverse()
        newParticle.touchParticle(path.join(SUBPARTICLE_MEMBRANE))
      })
      return newParticle
    }
  
    // todo: be more specific with the param
    _getSubparticlesByParserInExtended(parser: Function): Particle[] {
      return Utils.flatten(this._getAncestorsArray().map(particle => particle.getSubparticlesByParser(parser)))
    }
  
    _getExtendedParent() {
      return this._getAncestorsArray()[1]
    }
  
    _hasFromExtended(cuePath: particlesTypes.cuePath) {
      return !!this._getParticleFromExtended(cuePath)
    }
  
    _getParticleFromExtended(cuePath: particlesTypes.cuePath) {
      return this._getAncestorsArray().find(particle => particle.has(cuePath))
    }
  
    _getConcatBlockStringFromExtended(cuePath: particlesTypes.cuePath) {
      return this._getAncestorsArray()
        .filter(particle => particle.has(cuePath))
        .map(particle => particle.getParticle(cuePath).subparticlesToString())
        .reverse()
        .join("\n")
    }
  
    _doesExtend(parserId: particlesTypes.parserId) {
      return this._getAncestorSet().has(parserId)
    }
  
    _getAncestorSet() {
      if (!this._cache_ancestorSet) this._cache_ancestorSet = new Set(this._getAncestorsArray().map(def => def.id))
      return this._cache_ancestorSet
    }
  
    abstract get id(): string
  
    private _cache_ancestorSet: Set
    private _cache_ancestorsArray: AbstractExtendibleParticle[]
  
    // Note: the order is: [this, parent, grandParent, ...]
    _getAncestorsArray(cannotContainParticles?: AbstractExtendibleParticle[]) {
      this._initAncestorsArrayCache(cannotContainParticles)
      return this._cache_ancestorsArray
    }
  
    private get idThatThisExtends() {
      return this.get(ParticlesConstants.extends)
    }
  
    abstract get idToParticleMap(): { [id: string]: AbstractExtendibleParticle }
  
    protected _initAncestorsArrayCache(cannotContainParticles?: AbstractExtendibleParticle[]): void {
      if (this._cache_ancestorsArray) return undefined
      if (cannotContainParticles && cannotContainParticles.includes(this)) throw new Error(`Loop detected: '${this.getLine()}' is the ancestor of one of its ancestors.`)
      cannotContainParticles = cannotContainParticles || [this]
      let ancestors: AbstractExtendibleParticle[] = [this]
      const extendedId = this.idThatThisExtends
      if (extendedId) {
        const parentParticle = this.idToParticleMap[extendedId]
        if (!parentParticle) throw new Error(`${extendedId} not found`)
  
        ancestors = ancestors.concat(parentParticle._getAncestorsArray(cannotContainParticles))
      }
      this._cache_ancestorsArray = ancestors
    }
  }
  
  class ExtendibleParticle extends AbstractExtendibleParticle {
    private _particleMapCache: { [id: string]: AbstractExtendibleParticle }
    get idToParticleMap() {
      if (!this.isRoot()) return (this.root).idToParticleMap
      if (!this._particleMapCache) {
        this._particleMapCache = {}
        this.forEach(subparticle => {
          this._particleMapCache[subparticle.id] = subparticle
        })
      }
      return this._particleMapCache
    }
  
    get id() {
      return this.getAtom(0)
    }
  }
  
  export { Particle, ExtendibleParticle, AbstractExtendibleParticle, ParticleEvents, ParticleAtom }
  
 readme.scroll
  title Particle
  
  This folder contains the base Particle library.
  
  This code is used in both the browser lib and node.js lib.
  
  ? What are the differences between browser lib and node lib?
  The Node lib contains a dozen or so extra static methods. The implementations otherwise are almost identical with some slight overloads for the different environments.

stamp
 Parsers.compiled.test.ts
  #!/usr/bin/env ts-node
  
  import { particlesTypes } from "../products/particlesTypes"
  const path = require("path")
  const { TestRacer } = require("../products/TestRacer.js")
  const { Disk } = require("../products/Disk.node.js")
  const { Particle } = require("../products/Particle.js")
  const { HandParsersProgram, UnknownParsersProgram } = require("../products/Parsers.js")
  const { ParsersCompiler } = require("../products/ParsersCompiler.js")
  
  const testParticles: particlesTypes.testParticles = {}
  
  // todo: turn prettier off for test running? seems like it might increase test time from 2s to 5s...
  // todo: setup: make vms dir. cleanup? delete parsers file when done?
  
  const outputDir = path.join(__dirname, "..", "ignore", "vms")
  const langsDir = path.join(__dirname, "..", "langs")
  
  Disk.mkdir(outputDir)
  
  const makeProgram = (parsersCode: string, code: string) => {
    const parsersProgram = new HandParsersProgram(parsersCode)
    const rootParser = parsersProgram.compileAndReturnRootParser()
    return new rootParser(code)
  }
  
  testParticles.parsers = equal => {
    // Arrange
    const parsersParsersPath = path.join(langsDir, "parsers", "parsers.parsers")
    try {
      const tempFilePath = ParsersCompiler.compileParsersForNodeJs(parsersParsersPath, outputDir, false)
  
      // Act
      const parsers = require(tempFilePath)
  
      // Assert
      equal(!!new parsers(), true, "it compiled")
    } catch (err) {
      console.error(err)
    } finally {
    }
  }
  
  testParticles.compileAll = equal => {
    // Arrange/Act
    const langs = "hakon swarm dug stump project jibberish config poop jibjab fire stamp zin newlang chuck"
    langs.split(" ").map(name => {
      try {
        // Act
        const parsersPath = path.join(langsDir, name, `${name}.parsers`)
        const parsersCode = Particle.fromDisk(parsersPath)
        const tempFilePath = ParsersCompiler.compileParsersForNodeJs(parsersPath, outputDir, false)
        const rootClass = require(tempFilePath)
  
        // Assert
        equal(true, true, `Expected to compile and include "${name}" without error.`)
  
        // Act
        // todo: should we have an example particle for all langs?
        const exampleProgram = parsersCode.getParticle("parsers example")
        if (exampleProgram) {
          const testProgram = new rootClass(exampleProgram.subparticlesToString())
          // todo: should we then execute it? compile it?
  
          // Assert
          equal(testProgram.getAllErrors().length, 0, `no errors in test ${name} program`)
        }
  
        // Act/ Assert
        equal(new rootClass(Disk.read(path.join(langsDir, name, `sample.${name}`))).getAllErrors().length, 0, `no errors in ${name} sample program`)
      } catch (err) {
        console.log(err)
        equal(true, false, "Hit an error")
      }
    })
  }
  
  testParticles.jibberish = equal => {
    // Arrange
    try {
      const tempFilePath = ParsersCompiler.compileParsersForNodeJs(path.join(langsDir, `jibberish/jibberish.parsers`), outputDir, false)
  
      // Act
      const jibberish = require(tempFilePath)
  
      // Assert
      equal(!!new jibberish(), true, "it compiled")
  
      // Arrange
      const program = new jibberish(`particleWithConsts`)
  
      // Act/Assert
      equal(program.particleAt(0).score1, 28, "constants work")
    } catch (err) {
      console.error(err)
    } finally {
    }
  }
  
  testParticles.numbers = equal => {
    // Arrange
    const numbersParsersPath = path.join(langsDir, `numbers/numbers.parsers`)
    const numbersParsersCode = Disk.read(numbersParsersPath)
    const makeNumbersRunTimeProgram = (code: string) => makeProgram(numbersParsersCode, code)
    try {
      const tempFilePath = ParsersCompiler.compileParsersForNodeJs(numbersParsersPath, outputDir, false)
  
      // Act
      const numbers = require(tempFilePath)
  
      // Assert
      equal(!!new numbers(), true, "it compiled")
  
      // Arrange/Act
      const code = `+ 2 3
  * 2 3 10`
      const program = new numbers(code)
      const firstParticle = program.particleAt(0)
      const runtimeProgram = makeNumbersRunTimeProgram(code)
  
      // Assert
      equal(firstParticle.numbersAtom.length, 2, "atom getters work")
      equal(firstParticle.numbersAtom[0], 2, "typings work")
      equal(program.execute().join(" "), "5 60", "execute works")
      equal(program.getAllErrors().length, 0, "no errors found")
      if (program.getAllErrors().length) console.log(program.getAllErrors())
  
      equal(firstParticle.definition.lineHints, "+: operatorAtom numbersAtom...", "line hints work")
      equal(program.toAtomTypeParticles(), runtimeProgram.toAtomTypeParticles(), "atom types worked")
  
      // Arrange/Act/Assert
      equal(new numbers(`+ 2 a`).getAllErrors().length, 1, "should be 1 error")
    } catch (err) {
      console.error(err)
    } finally {
    }
  }
  
  testParticles.predictParsersFile = equal => {
    // Arrange
    const input = Disk.read(path.join(__dirname, "UnknownParsers.sample.scroll"))
  
    // Act
    const parsersFile = new UnknownParsersProgram(input).inferParsersFileForACueLanguage("foobar")
  
    // Assert
    equal(parsersFile, Disk.read(path.join(__dirname, "UnknownParsers.expected.parsers")), "predicted parsers correct")
  }
  
  testParticles.emojis = equal => {
    const source = `⌨🕸🌐
   📈
    🏦😎
   📉
    💩`
  
    // Act
    const parsersFile = new UnknownParsersProgram(source).inferParsersFileForACueLanguage("emojiLang")
    // Assert
    equal(parsersFile, Disk.read(path.join(__dirname, "UnknownParsers.expectedEmoji.parsers")), "predicted emoji parsers correct")
  }
  
  const langs = Disk.dir(langsDir)
  langs.forEach((name: string) => {
    const folder = path.join(langsDir, `${name}`)
    if (!Disk.isDir(folder)) return
    testParticles[`${name}InferPrefixParsers`] = equal => {
      // Arrange
      const samplePath = path.join(langsDir, name, `sample.${name}`)
      const sampleCode = Particle.fromDisk(samplePath).toString()
  
      // todo: cleanup
      if (Disk.read(path.join(langsDir, name, `${name}.parsers`)).includes("nonPrefixParsers")) return equal(true, true, `skipped ${name} beause not prefix parsers`)
  
      // Act
      const inferredPrefixParsersCode = new UnknownParsersProgram(sampleCode).inferParsersFileForACueLanguage("foobar")
      const inferredPrefixParsersProgram = new HandParsersProgram(inferredPrefixParsersCode)
      const rootParser = inferredPrefixParsersProgram.compileAndReturnRootParser()
      const programParsedWithInferredParsers = new rootParser(sampleCode)
  
      // Assert
      equal(inferredPrefixParsersProgram.getAllErrors().length, 0, `no errors in inferred parsers program for language ${name}`)
      equal(programParsedWithInferredParsers.getAllErrors().length, 0, `no errors in program from inferred parsers for ${name}`)
    }
  })
  
  /*NODE_JS_ONLY*/ if (!module.parent) TestRacer.testSingleFile(__filename, testParticles)
  
  export { testParticles }
  
 Parsers.test.ts
  #!/usr/bin/env ts-node
  
  // todo: make isomorphic
  
  import { particlesTypes } from "../products/particlesTypes"
  
  const { Disk } = require("../products/Disk.node.js")
  const { TestRacer } = require("../products/TestRacer.js")
  const { HandParsersProgram } = require("../products/Parsers.js")
  const path = require("path")
  
  const jibberishRootDir = path.join(__dirname, "..", "langs", "jibberish")
  const numbersPath = path.join(__dirname, "..", "langs", "numbers", "numbers.parsers")
  const numbersParsers = Disk.read(numbersPath)
  const arrowPath = path.join(__dirname, "..", "langs", "arrow", "arrow.parsers")
  const arrowParsers = Disk.read(arrowPath)
  const hakonPath = path.join(__dirname, "..", "langs", "hakon", "hakon.parsers")
  const hakonParsers = Disk.read(hakonPath)
  const parsersParsersPath = path.join(__dirname, "..", "langs", "parsers", "parsers.parsers")
  const parsersParsers = Disk.read(parsersParsersPath)
  const jibberishParsersPath = path.join(jibberishRootDir, "jibberish.parsers")
  const jibberishParsersCode = Disk.read(jibberishParsersPath)
  const poopParsersPath = path.join(__dirname, "..", "langs", "poop", "poop.parsers")
  
  const testParticles: particlesTypes.testParticles = {}
  
  testParticles.emptyProgram = equal => {
    // Arrange/Act/Assert
    const program = new HandParsersProgram()
    const errs = program.getAllErrors()
  
    // Assert
    if (errs.length) console.log(errs.map((err: any) => err.message))
    equal(errs.length, 0, "should be no errors")
  }
  
  testParticles.parsersLangBasics = equal => {
    // Arrange/Act
    const parsersProgram = new HandParsersProgram(jibberishParsersCode)
    const errs = parsersProgram.getAllErrors()
  
    // Assert
    if (errs.length) console.log(errs.map((err: any) => err.message))
    equal(errs.length, 0, "should be no errors")
  }
  
  const makeParsersProgram = (code: string) => makeProgram(parsersParsers, code)
  
  const makeJibberishProgram = (code: string) => {
    const parsersCode = Disk.read(jibberishParsersPath)
    return makeProgram(parsersCode, code)
  }
  
  const makePoopProgram = (code: string) => {
    const parsersCode = Disk.read(poopParsersPath)
    return makeProgram(parsersCode, code)
  }
  
  const makeIrisProgram = (code: string) => makeProgram(Disk.read(path.normalize(__dirname + "/../langs/iris/iris.parsers")), code)
  
  const makeNumbersProgram = (code: string) => makeProgram(numbersParsers, code)
  
  const makeProgram = (parsersCode: string, code: string) => {
    const parsersProgram = new HandParsersProgram(parsersCode)
    const rootParser = parsersProgram.compileAndReturnRootParser()
    return new rootParser(code)
  }
  
  testParticles.jibberish = equal => {
    // Arrange
    const sampleJibberishCode = Disk.read(path.join(jibberishRootDir, "sample.jibberish"))
  
    // Act
    const program = makeJibberishProgram(sampleJibberishCode)
  
    // Assert
    equal(program.constructor.name, "jibberishParser", "correct program class")
    const errs = program.getAllErrors()
    equal(errs.length, 0, `should be 0 errors`)
    if (errs.length) console.log(errs.map((err: any) => err.message))
  
    const parserDef = program.handParsersProgram.parserLineage.getParticle("abstractTopLevelParser particleWithConstsParser particleExpandsConstsParser")
  
    equal(parserDef.toString(), "particleExpandsConstsParser", "parser lineage works")
  
    // Act
    const fooParticle = program.getParticle("foo")
    const constParticle = program.getParticle("particleWithConsts")
    const particleExpandsConsts = program.getParticle("particleExpandsConsts")
  
    // Assert
    equal(fooParticle.parserId, "fooParser")
    equal(constParticle.parserId, "particleWithConstsParser")
    equal(constParticle.definition.ancestorParserIdsArray.join(" "), "abstractTopLevelParser particleWithConstsParser")
    equal(constParticle.definition.greeting, "hello world", "constants are also present on parsers definition particles")
  
    // Assert
    equal(constParticle.greeting, "hello world", "constant strings should work")
    equal(constParticle.score1, 28, "constant insts should work")
    equal(constParticle.score2, 3.01, "constant floats should work")
    equal(constParticle.win, true, "constant booleans should work")
    const obj = constParticle.definition.constantsObject
    equal(obj.score1, 28, "constants int works")
    equal(obj.score2, 3.01, "constants floats works")
    equal(obj.win, true, "constants bool works")
    equal(obj.greeting, "hello world", "constants string works")
    equal(
      obj.longText,
      `hello
  world`,
      "constants multiline string works"
    )
    const obj2 = particleExpandsConsts.definition.constantsObject
    equal(obj2.greeting, "hola", "expanding constants works and last wins")
    equal(obj2.win, true, "expanding constants works")
  
    // Act
    const addition = program.getParticle("+")
  
    // Assert
    equal(addition.constructor.name, "plusParser", "correct constructor name")
  
    // Act/Assert
    equal(program.getParticle("someCode echo").constructor.name, "lineOfCodeParser", "line of code class")
  
    // Act
    const programWithParserBugs = makeJibberishProgram(`missing 1 2
  missing2 true`)
  
    // Assert
    equal(programWithParserBugs.invalidParsers.length, 2)
  
    // Grandchild inheritance
    // Arrange
    const def = (program.getParticle("html.h1")).definition
  
    // Act/Assert
    equal(
      def
        ._getAncestorsArray()
        .map((def: any) => def.parserIdFromDefinition)
        .join(" "),
      "h1Parser abstractHtmlParser abstractTopLevelParser"
    )
  }
  
  const langs = Disk.dir(path.normalize(__dirname + `/../langs/`))
  langs.forEach((lang: string) => {
    const folder = path.normalize(`${__dirname}/../langs/${lang}`)
    if (!Disk.isDir(folder)) return
    testParticles[`${lang}SimTest`] = equal => {
      const parsersCode = Disk.read(path.normalize(`${folder}/${lang}.parsers`))
      const parsersProgram = new HandParsersProgram(parsersCode)
      const rootParser = parsersProgram.compileAndReturnRootParser()
  
      // Act
      const simulatedProgram = parsersProgram.rootParserDefinition.synthesizeParticle().join("\n")
  
      // Assert
      const errors = new rootParser(simulatedProgram).getAllErrors()
      //if (errors.length) console.log(simulatedProgram, errors)
      equal(errors.length, 0, `should be no errors in simulated ${lang} program`)
    }
  })
  
  testParticles.iris = equal => {
    // Arrange
    const programWithBugs = makeIrisProgram(`6.1 3 4.9  virginica`)
  
    // Act/Assert
    equal(programWithBugs.toAtomTypeParticles(), `sepalLengthAtom sepalWidthAtom petalLengthAtom petalWidthAtom speciesAtom`)
  }
  
  testParticles.jibberishErrors = equal => {
    // Arrange
    const programWithBugs = makeJibberishProgram(`+ foo bar`)
  
    // Act/Assert
    equal(programWithBugs.getAllErrors().length, 2, "2 errors")
  
    // Act
    let count = 0
    for (let err of programWithBugs.getAllErrorsIterator()) {
      // 2 errors in 1 line
      equal(err.length, 2)
    }
  
    // Act/Asssert
    equal(programWithBugs.invalidParsers.length, 0)
  }
  
  testParticles.toTypeScriptInterface = equal => {
    // Arrange
    const parsersProgram = new HandParsersProgram(arrowParsers).compileAndReturnRootParser()
    // Act // Assert
    equal(
      new parsersProgram().definition.toTypeScriptInterface(),
      `// A credit card charge
  interface chargeParser {
   amount: any
   cardNumber: any
   currency: any
   description: any
   token?: any
  }
  
  interface arrowParser {
   Comment?: any
   charge?: chargeParser
  }`
    )
  }
  
  testParticles.makeError = equal => {
    // Arrange/Act/Assert
    const program = makeJibberishProgram("")
    const message = "My custom error"
    const error = program.makeError(message)
  
    // Assert
    equal(error.message, message, "should be no errors")
    equal(error.lineNumber, 1)
  }
  
  testParticles.atomTypeParticles = equal => {
    // Act
    const someJibberishProgram = makeJibberishProgram(`foo
  + 2 3 2`)
  
    const a = (someJibberishProgram.particleAt(1)).definition
  
    equal(someJibberishProgram.usesParser("fooParser"), true)
    equal(someJibberishProgram.usesParser("abstractTopLevelParser"), true)
    equal(someJibberishProgram.usesParser("foobar"), false)
  
    // Assert
    equal(
      someJibberishProgram.toAtomTypeParticles(),
      `topLevelPropertyAtom
  opSymbolAtom integerAtom integerAtom integerAtom`,
      "atom types should match"
    )
    equal(someJibberishProgram.findAllAtomsWithAtomType("integerAtom").length, 3)
  
    // Act
    const parsers = someJibberishProgram.asAtomTypeParticlesWithParserIds
    const particlesWithParsers = someJibberishProgram.asParticlesWithParsers
  
    // Assert
    equal(
      parsers,
      `fooParser topLevelPropertyAtom
  plusParser opSymbolAtom integerAtom integerAtom integerAtom`,
      "parsers atom types should match"
    )
    equal(
      particlesWithParsers,
      `fooParser foo
  plusParser + 2 3 2`,
      "particlesWithParsers atom types should match"
    )
  }
  
  testParticles.preludeTypes = equal => {
    // Act/Assert
    equal(makeNumbersProgram(`+ 2`).particleAt(0).getLineAtomPreludeTypes(), `anyAtom floatAtom`)
  }
  
  testParticles.exponentialNotation = equal => {
    // Act/Assert
    equal(makeNumbersProgram(`+ 2e3`).particleAt(0).getErrors().length, 0)
  }
  
  testParticles.usesParser = equal => {
    // Act/Assert
    equal(makeNumbersProgram(`+ 2\n - 2`).usesParser("substractParser"), true)
  }
  
  testParticles.format = equal => {
    // Arrange
    const normalCode = `someLangParser
   root
  abstractTopLevelParser
  abstractHtmlParser
   extends abstractTopLevelParser
  h1Parser
   cue html.h1
   extends abstractHtmlParser
  abstractColorPropertiesParser
   extends abstractTopLevelParser
  constrastParser
   extends abstractColorPropertiesParser
  hueParser
   extends abstractColorPropertiesParser
  saturationParser
   extends abstractColorPropertiesParser`
    const parsersProgram = makeParsersProgram(normalCode)
    const formatted = parsersProgram.format().toString()
    equal(formatted, normalCode, "code is already in formatted form")
  }
  
  testParticles.formatDo = equal => {
    // Arrange
    const unsortedCode = `someLangParser
   root
   inScope abstractTopLevelParser
  abstractTopLevelParser
  h1Parser
   cue html.h1
   extends abstractHtmlParser
  abstractHtmlParser
   extends abstractTopLevelParser
  integerAtom`
    const sortedCode = `integerAtom
  someLangParser
   root
   inScope abstractTopLevelParser
  abstractTopLevelParser
  abstractHtmlParser
   extends abstractTopLevelParser
  h1Parser
   cue html.h1
   extends abstractHtmlParser`
    // Act/Assert
    equal(makeParsersProgram(unsortedCode).format().toString(), sortedCode, "code was fixed")
  }
  
  testParticles.cokeRegression = equal => {
    // Arrange
    const lang = `cokeParser
   root
   inScope cokesParser
  integerAtom
   paint constant.numeric.integer
  anyAtom
  cokesParser
   atoms anyAtom
   catchAllAtomType integerAtom`
    const code = `
  cokes 22 11`
  
    // Act
    const program = makeProgram(lang, code)
  
    // Assert
    const errs = program.getAllErrors()
    equal(errs.length, 0)
    if (errs.length) console.log(errs.map((err: any) => err.message).join("\n"))
    equal(typeof program.toPaintParticles(), "string")
  }
  
  testParticles.paints = equal => {
    // Arrange
    const someJibberishProgram = makeJibberishProgram(`foo
  + 2 3 2`)
  
    // Act
    const scopes = someJibberishProgram.toPaintParticles()
  
    // Assert
    equal(
      scopes,
      `constant.language
  keyword.operator.arithmetic constant.numeric constant.numeric constant.numeric`
    )
  
    // Arrange/Act/Assert
    equal(makeJibberishProgram(`fault`).toPaintParticles(), `invalid`)
    equal(makeJibberishProgram(`fault fault`).toPaintParticles(), `invalid invalid`)
    equal(makeNumbersProgram(`+ 2`).toPaintParticles(), `keyword.operator.arithmetic constant.numeric`)
  
    // Arrange
    const program = makeJibberishProgram(`lightbulbState on
   someerror`)
  
    // Act/Assert
    equal(
      program.toPaintParticles(),
      `constant.language source
   invalid`
    )
    equal(program.getAllErrors().length, 1)
  }
  
  testParticles.autocomplete = equal => {
    // Arrange
    let program = makeNumbersProgram(`+ 2 3
  com
  `)
  
    // Act/Assert
    equal(program.getAutocompleteResultsAt(1, 0).matches.length, 1, "should be 1 match")
    equal(program.getAutocompleteResultsAt(1, 2).matches.length, 1, "should complete comment")
    equal(program.getAutocompleteResultsAt(1, 3).matches.length, 1, "should complete comment")
    const acResults = program.getAutocompleteResultsAt(2, 0).matches
    equal(acResults.length, 7, "all particles")
    equal(program.getAutocompleteResultsAt(0, 2).matches.length, 0, "should be none")
  
    equal(program.getAutocompleteResultsAt(0, 2).matches.length, 0)
    // todo: test for descriptions in addition to returned atoms
  
    // Arrange/Act/Assert
    equal(makeNumbersProgram(``).getAutocompleteResultsAt(0, 0).matches.length, 7, "should be 7 results at root level")
  
    // Arrange
    program = makeNumbersProgram(`+ 2 3
  * 2 3 10`)
  
    // Act/Assert
    equal(program.execute().join(" "), "5 60")
  }
  
  testParticles.extraAtom = equal => {
    // Arrange
    const program = makeParsersProgram(`foobarParser
   root foo2`)
  
    // Act/Assert
    equal(program.getAllErrors().length, 1)
    equal(
      program.toAtomTypeParticles(),
      `parserIdAtom
   cueAtom extraAtomAtom`
    )
  }
  
  testParticles.autocompleteAdditionalAtoms = equal => {
    // Arrange
    const program = makeParsersProgram(`fooAtom
   paint comme`)
  
    // Act/Assert
    equal(program.getAutocompleteResultsAt(1, 11).matches.length, 5)
  }
  
  testParticles.autocompleteAdvanced = equal => {
    // Arrange
    const program = makeParsersProgram(`latinParser
   root
   catchAllParser anyParser
   inScope faveNumberParser
  integerAtom
  anyParser
  faveNumberParser
   atoms in`)
  
    // Act/Assert
    equal(program.getAutocompleteResultsAt(7, 9).matches.length, 2)
  
    equal(program.toSideBySide([program.toDefinitionLineNumberParticles()]).numberOfLines, 8)
  }
  
  // todo: fix autocomplete for omnifix languages
  // testParticles._autocompleteUnicode = equal => {
  //   // Arrange/Act/Assert
  //   equal(makePoopProgram(``).getAutocompleteResultsAt(0, 0).matches.length, 5)
  // }
  
  testParticles.autocompleteCustom = equal => {
    // Arrange/Act/Assert
    equal(makeJibberishProgram(`xColumnName `).getAutocompleteResultsAt(0, 12).matches.length, 3)
    equal(makeJibberishProgram(`xColumnName eight`).getAutocompleteResultsAt(0, 12).matches.length, 2)
    equal(makeJibberishProgram(`xColumnName gender`).getAllErrors().length, 0)
    equal(makeJibberishProgram(`xColumnName genders`).getAllErrors().length, 1, "should have 1 error. genders doesnt fit.")
  }
  
  testParticles.blobParsers = equal => {
    // Arrange/Act
    const anyProgram = makeJibberishProgram(`text foobar
   This is a blob particle.
   this is some text.
   hello world
   
   1+1`)
  
    // Assert
    equal(anyProgram.getAllErrors().length, 0)
  
    // Act
    for (let err of anyProgram.getAllErrorsIterator()) {
      // Should be no errors
      equal(true, false)
    }
  
    // Regression test. The below should not throw
    equal(anyProgram.topDownArray.map((particle: any) => particle.parserId).length > 0, true, "passed blob regression")
  }
  
  // todo: reenable once we have the requirement of at least 1 root particle
  // testParticles.requiredParsers = equal => {
  //   // Arrange/Act
  //   const path = parsersParsersPath
  //   const anyProgram = makeProgram(
  //     readFileSync(path, "utf8"),
  //     `atomType atom
  // parser baseParser`,
  //     path
  //   )
  
  //   // Assert
  //   const errs = anyProgram.getAllErrors()
  //   equal(errs.length, 1)
  // }
  
  testParticles.minimumParsers = equal => {
    // Arrange/Act
    const rootParser = new HandParsersProgram(
      `anyLangParser
   root
   catchAllParser anyParser
  anyParser
   catchAllAtomType anyAtom
  anyAtom`
    ).compileAndReturnRootParser()
    const program = new rootParser()
    const handParsersProgram = program.handParsersProgram
  
    // Assert
    let errors = handParsersProgram.getAllErrors()
    equal(errors.length, 0)
    errors = program.getAllErrors()
    equal(errors.length, 0)
  
    // Arrange/Act/Assert
    const constructor = new HandParsersProgram().compileAndReturnRootParser()
    const errs = new constructor("foobar").getAllErrors()
    equal(errs.length, 0)
  }
  
  testParticles.rootCatchAllParser = equal => {
    // Arrange
    const abcLang = new HandParsersProgram(`abcParser
   root`).compileAndReturnRootParser()
  
    // Act/Assert
    const program = new abcLang("foobar")
    equal(program.getAllErrors().length, 0)
    equal(program.toAtomTypeParticles(), "extraAtomAtom", "one atom")
  
    // Arrange
    const abcLangWithErrors = new HandParsersProgram(`abcParser
   root
   catchAllParser errorParser
  errorParser
   baseParser errorParser`).compileAndReturnRootParser()
  
    // Act/Assert
    equal(new abcLangWithErrors("foobar").getAllErrors().length, 1)
  }
  
  testParticles.blankParserId = equal => {
    // Arrange
    const abcLang = new HandParsersProgram(`parser `).compileAndReturnRootParser()
  
    // Act/Assert
    equal(new abcLang("foobar").getAllErrors().length, 0)
  }
  
  testParticles.parsersWithLoop = equal => {
    // Arrange/Act/Assert
    try {
      const rootParser = new HandParsersProgram(
        `langWithLoopParser
   root
   catchAllParser particleAParser
  particleAParser
   extends particleCParser
   catchAllAtomType anyAtom
  particleBParser
   extends particleAParser
  particleCParser
   extends particleBParser
  anyAtom`
      ).compileAndReturnRootParser()
  
      new rootParser("particleA")
      equal(false, true, "Should have thrown error")
    } catch (err) {
      equal(err.toString().includes("Loop"), true, `Expected correct error thrown when parsers. Got: ${err.toString()}`)
    }
  }
  
  testParticles.informationContent = equal => {
    // Test bit atom
    const bitProgram = makeJibberishProgram("lightbulbState on")
    const bitParticle = bitProgram.particleAt(0)
    const atom = bitParticle.parsedAtoms[1]
    equal(atom.bitsRequired, 1, "bit atom should have 1 bit of information")
    equal(bitParticle.parsedAtoms[0].bitsRequired, 0, "cue word should have 0 bits of information. particle is fixed.")
    equal(bitParticle.bitsRequired, 1, "bit particle should have 1 bit of information")
  }
  
  testParticles.duplicateParsers = equal => {
    // Arrange/Act
    const anyProgram = makeJibberishProgram(`type foo
  type bar`)
  
    // Assert
    equal(anyProgram.getAllErrors().length, 2)
  }
  
  testParticles.extendsScope = equal => {
    // Arange
    const rootParser = new HandParsersProgram(`cueAtom
  newlangParser
   root
   catchAllParser catchAllErrorParser
   inScope rootParser
  rootParser
  videoParser
   extends rootParser
   atoms cueAtom
   cueFromId
   widthParser
    cueFromId
    atoms cueAtom
  quickVideoParser
   cue qv
   extends videoParser
  catchAllErrorParser
   baseParser errorParser`).compileAndReturnRootParser()
    const program = `video
   width
  qv
   width`
  
    //  console.log(new rootParser(program).definition.toBrowserJavascript())
  
    // Act
    equal(new rootParser(program).getAllErrors().length, 0)
  }
  
  testParticles.abstractParsers = equal => {
    // Arrange/Act
    const anyProgram = makeJibberishProgram(`someAbstractClass
  extendsAbstract 2`)
  
    // Assert
    equal(anyProgram.getAllErrors().length, 1)
  }
  
  testParticles.updateParserIds = equal => {
    // Arrange/Act
    const anyProgram = makeParsersProgram(`someLangParser
   root
  foobarAtom
   regex test`)
  
    // Assert
    anyProgram.findAllParticlesWithParser("parsersRegexParser").forEach((particle: any) => {
      particle.setAtom(0, "regexString")
    })
    equal(
      anyProgram.toString(),
      `someLangParser
   root
  foobarAtom
   regexString test`
    )
  }
  
  testParticles.toNodeJsJavascript = equal => {
    // Arrange
    let program = new HandParsersProgram(parsersParsers)
    // Act
    let compiledParser = program.toNodeJsJavascript()
    // Assert
    equal(typeof compiledParser, "string")
  }
  
  testParticles.invalidParsersRegression = equal => {
    // Arrange
    let program = new HandParsersProgram(`oldStyle something
   root`)
    // Act
    let compiledParser = program.toNodeJsJavascript()
    // Assert
    equal(typeof compiledParser, "string")
  }
  
  testParticles.addRunTimeParser = equal => {
    const parsers = `// Atom Parsers
  nameAtom
   description A person's name
   paint string
  cueAtom
   paint keyword
  
  // Line Parsers
  newlangParser
   root
   description A basic root parser.
   catchAllParser catchAllErrorParser
   inScope helloParser
  helloParser
   int luckyNumber 7
   catchAllAtomType nameAtom
   atoms cueAtom
   cue hello
  catchAllErrorParser
   baseParser errorParser`
  
    // Arrange
    const parsersProgram = new HandParsersProgram(parsers)
    const rootParser = parsersProgram.compileAndReturnRootParser()
  
    // Act/Assert
    const basicProgram = new rootParser(`hello Mom`)
    equal(basicProgram.particleAt(0).luckyNumber, 7, "Basics work")
  
    const byeParser = `byeParser
   int luckyNumber 42
   atoms cueAtom
   extends helloParser
   cue bye`
  
    // Act
    // Now we need to add a Parser.
    basicProgram.registerParsers(byeParser)
    basicProgram.appendLine("bye")
  
    // Assert
    equal(basicProgram.particleAt(1).luckyNumber, 42, "registerParsers work")
  
    const adiosParser = `adiosParser
   int luckyNumber 15
   atoms cueAtom
   extends helloParser
   cueFromId`
  
    // Act
    basicProgram.registerParsers(adiosParser)
    basicProgram.appendLine("adios")
    basicProgram.appendLine("bye")
  
    // Assert
    equal(basicProgram.particleAt(2).luckyNumber, 15, "adding multiple parsers works")
    equal(basicProgram.particleAt(3).luckyNumber, 42, "earlier additions work")
  }
  
  const jibberishParsersProgram = new HandParsersProgram(jibberishParsersCode)
  Object.assign(testParticles, jibberishParsersProgram.examplesToTestBlocks())
  
  // Arrange/Act
  const badParsersProgram = new HandParsersProgram(
    `badParser
   root
   inScope addParser
  addParser
   cue +
   catchAllAtomType integerAtom
   atoms cueAtom
   example This is a bad example.
    + 1 B
  cueAtom
  integerAtom`
  )
  Object.assign(testParticles, badParsersProgram.examplesToTestBlocks(undefined, `InvalidAtom at line 9 atom 2. "B" does not fit in atomType "integerAtom".`))
  
  /*NODE_JS_ONLY*/ if (!module.parent) TestRacer.testSingleFile(__filename, testParticles)
  
  export { testParticles }
  
 Parsers.ts
  const { Utils } = require("../products/Utils.js")
  const { Particle, ParticleAtom, ExtendibleParticle, AbstractExtendibleParticle } = require("../products/Particle.js")
  
  import { particlesTypes } from "../products/particlesTypes"
  
  interface AbstractRuntimeProgramConstructorInterface {
    new (code?: string): ParserBackedParticle
  }
  
  declare type parserInfo = { cueMap: { [cue: string]: parserDefinitionParser }; regexTests: particlesTypes.regexTestDef[] }
  
  // Compiled language parsers will include these files:
  const GlobalNamespaceAdditions: particlesTypes.stringMap = {
    Utils: "Utils.js",
    Particle: "Particle.js",
    HandParsersProgram: "Parsers.js",
    ParserBackedParticle: "Parsers.js"
  }
  
  enum ParsersConstantsCompiler {
    stringTemplate = "stringTemplate", // replacement instructions
    indentCharacter = "indentCharacter",
    catchAllAtomDelimiter = "catchAllAtomDelimiter",
    openSubparticles = "openSubparticles",
    joinSubparticlesWith = "joinSubparticlesWith",
    closeSubparticles = "closeSubparticles"
  }
  
  enum ParsersConstantsMisc {
    doNotSynthesize = "doNotSynthesize"
  }
  
  enum PreludeAtomTypeIds {
    anyAtom = "anyAtom",
    cueAtom = "cueAtom",
    extraAtomAtom = "extraAtomAtom",
    floatAtom = "floatAtom",
    numberAtom = "numberAtom",
    bitAtom = "bitAtom",
    booleanAtom = "booleanAtom",
    integerAtom = "integerAtom"
  }
  
  enum ParsersConstantsConstantTypes {
    boolean = "boolean",
    string = "string",
    int = "int",
    float = "float"
  }
  
  enum ParsersAtomParser {
    prefix = "prefix",
    postfix = "postfix",
    omnifix = "omnifix"
  }
  
  enum ParsersConstants {
    // particle types
    comment = "//",
    parser = "parser",
    atomType = "atomType",
  
    parsersFileExtension = "parsers",
  
    abstractParserPrefix = "abstract",
    parserSuffix = "Parser",
    atomTypeSuffix = "Atom",
  
    // error check time
    regex = "regex", // temporary?
    reservedAtoms = "reservedAtoms", // temporary?
    enumFromAtomTypes = "enumFromAtomTypes", // temporary?
    enum = "enum", // temporary?
    examples = "examples",
    min = "min",
    max = "max",
  
    // baseParsers
    baseParser = "baseParser",
    blobParser = "blobParser",
    errorParser = "errorParser",
  
    // parse time
    extends = "extends",
    root = "root",
    cue = "cue",
    cueFromId = "cueFromId",
    pattern = "pattern",
    inScope = "inScope",
    atoms = "atoms",
    listDelimiter = "listDelimiter",
    contentKey = "contentKey",
    subparticlesKey = "subparticlesKey",
    uniqueCue = "uniqueCue",
    catchAllAtomType = "catchAllAtomType",
    atomParser = "atomParser",
    catchAllParser = "catchAllParser",
    constants = "constants",
    required = "required", // Require this parser to be present in a particle or program
    single = "single", // Have at most 1 of these
    uniqueLine = "uniqueLine", // Can't have duplicate lines.
    tags = "tags",
  
    // default catchAll parser
    BlobParser = "BlobParser",
    DefaultRootParser = "DefaultRootParser",
  
    // code
    javascript = "javascript",
  
    // compile time
    compilerParser = "compiler",
  
    // develop time
    description = "description",
    example = "example",
    popularity = "popularity", // todo: remove. switch to conditional frequencies. potentially do that outside this core lang.
    paint = "paint"
  }
  
  class TypedAtom extends ParticleAtom {
    private _type: string
    constructor(particle: Particle, atomIndex: number, type: string) {
      super(particle, atomIndex)
      this._type = type
    }
    get type() {
      return this._type
    }
    toString() {
      return this.atom + ":" + this.type
    }
  }
  
  const _parserPoolCache = {}
  // todo: can we merge these methods into base Particle and ditch this class?
  abstract class ParserBackedParticle extends Particle {
    private _definition: AbstractParserDefinitionParser | HandParsersProgram | parserDefinitionParser
  
    // Returns a pointer to the Particle containing the parser definition. In the future this will
    // be in the same file. Right now we still have the split between Parser definitions and program code.
    get definition(): AbstractParserDefinitionParser | HandParsersProgram | parserDefinitionParser {
      if (this._definition) return this._definition
  
      this._definition = this.isRoot() ? this.handParsersProgram : this.parent.definition.getParserDefinitionByParserId(this.constructor.name)
      return this._definition
    }
  
    registerParsers(parserCode: string, id?: string) {
      // Todo: hacky as shit for now. Thats fine.
      // What we do here is if a parser comes in we recreate the entire root parser.
      // What we actually want to do is just minimally update the parser pool.
      // We can do that later, but it is sort of time to look at moving the Parsers
      // concept directly into Particles, perhaps even with a bit of a rewrite, and
      // remove a lot of the classes in this file.
      const root = this.root
      const currentParserCode = (root._modifiedConstructor || root.constructor)._parserSourceCode
      const newParserCode = currentParserCode + "\n" + parserCode
      const parsersProgram = new HandParsersProgram(newParserCode)
      const rootParser = parsersProgram.compileAndReturnRootParser()
      root.topDownArray.forEach(part => part.definition) // Hacky. We need to bind all previous particles to their earlier definitions, which now may change.
      root._definition = parsersProgram
      root._modifiedConstructor = rootParser
      root._parserPool = new rootParser()._getParserPool()
      // Clear parser cache.
      delete root._parserIdIndex
      if (id) _parserPoolCache[id] = root
    }
  
    switchParserPool(parserPoolId: string) {
      const sourceParticle = _parserPoolCache[parserPoolId]
      const root = this.root
      root.topDownArray.forEach(part => part.definition) // Hacky. We need to bind all previous particles to their earlier definitions, which now may change.
      root._definition = sourceParticle._definition
      root._modifiedConstructor = sourceParticle._modifiedConstructor
      root._parserPool = sourceParticle._parserPool
      // Clear parser cache.
      delete root._parserIdIndex
    }
  
    get rootParsersParticles() {
      return this.definition.root
    }
  
    getAutocompleteResults(partialAtom: string, atomIndex: particlesTypes.positiveInt) {
      return atomIndex === 0 ? this._getAutocompleteResultsForCue(partialAtom) : this._getAutocompleteResultsForAtom(partialAtom, atomIndex)
    }
  
    makeError(message: string) {
      return new ParserDefinedError(this, message)
    }
  
    usesParser(parserId: string) {
      return !!this.parserIdIndex[parserId]
    }
  
    private _parserIdIndex: {
      [parserId: string]: ParserBackedParticle[]
    }
    get parserIdIndex() {
      if (this._parserIdIndex) return this._parserIdIndex
      const index = {}
      this._parserIdIndex = index
      for (let particle of this.getTopDownArrayIterator()) {
        Array.from(particle.definition._getAncestorSet()).forEach(id => {
          if (!index[id]) index[id] = []
          index[id].push(particle)
        })
      }
      return index
    }
  
    private _particleIndex: {
      [parserId: string]: ParserBackedParticle[]
    }
  
    protected get particleIndex() {
      // StringMap {cue: index}
      // When there are multiple tails with the same cue, index stores the last content.
      // todo: change the above behavior: when a collision occurs, create an array.
      return this._particleIndex || this._makeParticleIndex()
    }
  
    _clearCueIndex() {
      delete this._particleIndex
      return super._clearCueIndex()
    }
  
    protected _makeCueIndex(startAt = 0) {
      if (this._particleIndex) this._makeParticleIndex(startAt)
      return super._makeCueIndex(startAt)
    }
  
    protected _makeParticleIndex(startAt = 0) {
      if (!this._particleIndex || !startAt) this._particleIndex = {}
      const particles = this._getSubparticlesArray() as ParserBackedParticle[]
      const newIndex = this._particleIndex
      const length = particles.length
  
      for (let index = startAt; index  {
          if (!newIndex[id]) newIndex[id] = []
          newIndex[id].push(particle)
        })
      }
  
      return newIndex
    }
  
    /**
     * Returns the total information bits required to represent this particle and all its subparticles.
     * This is calculated as the sum of:
     * 1. Information bits of all atoms in this particle
     * 2. Information bits of all subparticles (recursive)
     */
    get bitsRequired(): number {
      // Get information bits for all atoms in this particle
      const atomBits = this.parsedAtoms.map(atom => atom.bitsRequired).reduce((sum, bits) => sum + bits, 0)
  
      // Recursively get information bits from all subparticles
      const subparticleBits = this.map(child => (child).bitsRequired).reduce((sum, bits) => sum + bits, 0)
  
      return atomBits + subparticleBits
    }
  
    getSubparticleInstancesOfParserId(parserId: particlesTypes.parserId): ParserBackedParticle[] {
      return this.particleIndex[parserId] || []
    }
  
    doesExtend(parserId: particlesTypes.parserId) {
      return this.definition._doesExtend(parserId)
    }
  
    _getErrorParserErrors() {
      return [this.cue ? new UnknownParserError(this) : new BlankLineError(this)]
    }
  
    _getBlobParserCatchAllParser() {
      return BlobParser
    }
  
    private _getAutocompleteResultsForCue(partialAtom: string) {
      const cueMap = this.definition.cueMapWithDefinitions
      let cues: string[] = Object.keys(cueMap)
  
      if (partialAtom) cues = cues.filter(cue => cue.includes(partialAtom))
  
      return cues
        .map(cue => {
          const def = cueMap[cue]
          if (def.suggestInAutocomplete === false) return false
          const description = def.description
          return {
            text: cue,
            displayText: cue + (description ? " " + description : "")
          }
        })
        .filter(i => i)
    }
  
    private _getAutocompleteResultsForAtom(partialAtom: string, atomIndex: particlesTypes.positiveInt) {
      // todo: root should be [] correct?
      const atom = this.parsedAtoms[atomIndex]
      return atom ? atom.getAutoCompleteAtoms(partialAtom) : []
    }
  
    // note: this is overwritten by the root particle of a runtime parsers program.
    // some of the magic that makes this all work. but maybe there's a better way.
    get handParsersProgram(): HandParsersProgram {
      if (this.isRoot()) throw new Error(`Root particle without getHandParsersProgram defined.`)
      return (this.root).handParsersProgram
    }
  
    getRunTimeEnumOptions(atom: AbstractParsersBackedAtom): string[] {
      return undefined
    }
  
    getRunTimeEnumOptionsForValidation(atom: AbstractParsersBackedAtom): string[] {
      return this.getRunTimeEnumOptions(atom)
    }
  
    private _sortParticlesByInScopeOrder() {
      const parserOrder = this.definition._getMyInScopeParserIds()
      if (!parserOrder.length) return this
      const orderMap: particlesTypes.stringMap = {}
      parserOrder.forEach((atom, index) => (orderMap[atom] = index))
      this.sort(Utils.makeSortByFn((runtimeParticle: ParserBackedParticle) => orderMap[runtimeParticle.parserId]))
      return this
    }
  
    protected get requiredParticleErrors() {
      const errors: particlesTypes.ParticleError[] = []
      Object.values(this.definition.cueMapWithDefinitions).forEach(def => {
        if (def.isRequired() && !this.particleIndex[def.id]) errors.push(new MissingRequiredParserError(this, def.id))
      })
      return errors
    }
  
    get programAsAtoms() {
      // todo: what is this?
      return this.topDownArray.map((particle: ParserBackedParticle) => {
        const atoms = particle.parsedAtoms
        let indents = particle.getIndentLevel() - 1
        while (indents) {
          atoms.unshift(undefined)
          indents--
        }
        return atoms
      })
    }
  
    get programWidth() {
      return Math.max(...this.programAsAtoms.map(line => line.length))
    }
  
    get allTypedAtoms() {
      const atoms: TypedAtom[] = []
      this.topDownArray.forEach((particle: ParserBackedParticle) => particle.atomTypes.forEach((atom, index) => atoms.push(new TypedAtom(particle, index, atom.atomTypeId))))
      return atoms
    }
  
    findAllAtomsWithAtomType(atomTypeId: particlesTypes.atomTypeId) {
      return this.allTypedAtoms.filter(typedAtom => typedAtom.type === atomTypeId)
    }
  
    findAllParticlesWithParser(parserId: particlesTypes.parserId) {
      return this.topDownArray.filter((particle: ParserBackedParticle) => particle.parserId === parserId)
    }
  
    toAtomTypeParticles() {
      return this.topDownArray.map(subparticle => subparticle.indentation + subparticle.lineAtomTypes).join("\n")
    }
  
    getParseTable(maxColumnWidth = 40) {
      const particle = new Particle(this.toAtomTypeParticles())
      return new Particle(
        particle.topDownArray.map((particle, lineNumber) => {
          const sourceParticle = this.particleAtLine(lineNumber)
          const errs = sourceParticle.getErrors()
          const errorCount = errs.length
          const obj: any = {
            lineNumber: lineNumber,
            source: sourceParticle.indentation + sourceParticle.getLine(),
            parser: sourceParticle.constructor.name,
            atomTypes: particle.content,
            errorCount: errorCount
          }
          if (errorCount) obj.errorMessages = errs.map(err => err.message).join(";")
          return obj
        })
      ).toFormattedTable(maxColumnWidth)
    }
  
    // Helper method for selecting potential parsers needed to update parsers file.
    get invalidParsers() {
      return Array.from(
        new Set(
          this.getAllErrors()
            .filter(err => err instanceof UnknownParserError)
            .map(err => err.getParticle().cue)
        )
      )
    }
  
    private _getAllAutoCompleteAtoms() {
      return this.getAllAtomBoundaryCoordinates().map(coordinate => {
        const results = this.getAutocompleteResultsAt(coordinate.lineIndex, coordinate.charIndex)
        return {
          lineIndex: coordinate.lineIndex,
          charIndex: coordinate.charIndex,
          atomIndex: coordinate.atomIndex,
          atom: results.atom,
          suggestions: results.matches
        }
      })
    }
  
    toAutoCompleteCube(fillChar = "") {
      const particles: any[] = [this.clone()]
      const filled = this.clone().fill(fillChar)
      this._getAllAutoCompleteAtoms().forEach(hole => {
        hole.suggestions.forEach((suggestion, index) => {
          if (!particles[index + 1]) particles[index + 1] = filled.clone()
          particles[index + 1].particleAtLine(hole.lineIndex).setAtom(hole.atomIndex, suggestion.text)
        })
      })
      return new Particle(particles)
    }
  
    toAutoCompleteTable() {
      return new Particle(
        this._getAllAutoCompleteAtoms().map(result => {
          result.suggestions = result.suggestions.map((particle: any) => particle.text).join(" ")
          return result
        })
      ).asTable
    }
  
    getAutocompleteResultsAt(lineIndex: particlesTypes.positiveInt, charIndex: particlesTypes.positiveInt) {
      const lineParticle = this.particleAtLine(lineIndex) || this
      const particleInScope = lineParticle.getParticleInScopeAtCharIndex(charIndex)
  
      // todo: add more tests
      // todo: second param this.subparticlesToString()
      // todo: change to getAutocomplete definitions
  
      const atomIndex = lineParticle.getAtomIndexAtCharacterIndex(charIndex)
      const atomProperties = lineParticle.getAtomProperties(atomIndex)
      return {
        startCharIndex: atomProperties.startCharIndex,
        endCharIndex: atomProperties.endCharIndex,
        atom: atomProperties.atom,
        matches: particleInScope.getAutocompleteResults(atomProperties.atom, atomIndex)
      }
    }
  
    private _sortWithParentParsersUpTop() {
      const lineage = new HandParsersProgram(this.toString()).parserLineage
      const rank: particlesTypes.stringMap = {}
      lineage.topDownArray.forEach((particle, index) => {
        rank[particle.getAtom(0)] = index
      })
      const particleAFirst = -1
      const particleBFirst = 1
      this.sort((particleA, particleB) => {
        const particleARank = rank[particleA.getAtom(0)]
        const particleBRank = rank[particleB.getAtom(0)]
        return particleARank  subparticle.format())
      return this
    }
  
    getParserUsage(filepath = "") {
      // returns a report on what parsers from its language the program uses
      const usage = new Particle()
      const handParsersProgram = this.handParsersProgram
      handParsersProgram.validConcreteAndAbstractParserDefinitions.forEach((def: AbstractParserDefinitionParser) => {
        const requiredAtomTypeIds = def.atomParser.getRequiredAtomTypeIds()
        usage.appendLine([def.parserIdFromDefinition, "line-id", "parser", requiredAtomTypeIds.join(" ")].join(" "))
      })
      this.topDownArray.forEach((particle: ParserBackedParticle, lineNumber: number) => {
        const stats = usage.getParticle(particle.parserId)
        stats.appendLine([filepath + "-" + lineNumber, particle.atoms.join(" ")].join(" "))
      })
      return usage
    }
  
    toPaintParticles() {
      return this.topDownArray.map((subparticle: ParserBackedParticle) => subparticle.indentation + subparticle.getLinePaints()).join("\n")
    }
  
    toDefinitionLineNumberParticles() {
      return this.topDownArray.map((subparticle: ParserBackedParticle) => subparticle.definition.lineNumber + " " + subparticle.indentation + subparticle.atomDefinitionLineNumbers.join(" ")).join("\n")
    }
  
    get asAtomTypeParticlesWithParserIds() {
      return this.topDownArray.map((subparticle: ParserBackedParticle) => subparticle.constructor.name + this.atomBreakSymbol + subparticle.indentation + subparticle.lineAtomTypes).join("\n")
    }
  
    toPreludeAtomTypeParticlesWithParserIds() {
      return this.topDownArray.map((subparticle: ParserBackedParticle) => subparticle.constructor.name + this.atomBreakSymbol + subparticle.indentation + subparticle.getLineAtomPreludeTypes()).join("\n")
    }
  
    get asParticlesWithParsers() {
      return this.topDownArray.map((subparticle: ParserBackedParticle) => subparticle.constructor.name + this.atomBreakSymbol + subparticle.indentation + subparticle.getLine()).join("\n")
    }
  
    getAtomPaintAtPosition(lineIndex: number, atomIndex: number): particlesTypes.paint | undefined {
      this._initAtomTypeCache()
      const typeParticle = this._cache_paintParticles.topDownArray[lineIndex - 1]
      return typeParticle ? typeParticle.getAtom(atomIndex - 1) : undefined
    }
  
    private _cache_programAtomTypeStringMTime: number
    private _cache_paintParticles: Particle
    private _cache_typeParticles: Particle
  
    protected _initAtomTypeCache(): void {
      const particleMTime = this.getLineOrSubparticlesModifiedTime()
      if (this._cache_programAtomTypeStringMTime === particleMTime) return undefined
  
      this._cache_typeParticles = new Particle(this.toAtomTypeParticles())
      this._cache_paintParticles = new Particle(this.toPaintParticles())
      this._cache_programAtomTypeStringMTime = particleMTime
    }
  
    createParserPool() {
      return this.isRoot() ? new Particle.ParserPool(BlobParser) : new Particle.ParserPool(this.parent._getParserPool()._getCatchAllParser(this.parent), {})
    }
  
    get parserId(): particlesTypes.parserId {
      return this.definition.cue
    }
  
    get atomTypes() {
      return this.parsedAtoms.filter(atom => atom.getAtom() !== undefined)
    }
  
    private get atomErrors() {
      const { parsedAtoms } = this // todo: speedup. takes ~3s on pldb.
  
      // todo: speedup getErrorIfAny. takes ~3s on pldb.
      return parsedAtoms.map(check => check.getErrorIfAny()).filter(identity => identity)
    }
  
    private get singleParserUsedTwiceErrors() {
      const errors: particlesTypes.ParticleError[] = []
      const parent = this.parent as ParserBackedParticle
      const hits = parent.getSubparticleInstancesOfParserId(this.definition.id)
  
      if (hits.length > 1)
        hits.forEach((particle, index) => {
          if (particle === this) errors.push(new ParserUsedMultipleTimesError(particle))
        })
      return errors
    }
  
    private get uniqueLineAppearsTwiceErrors() {
      const errors: particlesTypes.ParticleError[] = []
      const parent = this.parent as ParserBackedParticle
      const hits = parent.getSubparticleInstancesOfParserId(this.definition.id)
  
      if (hits.length > 1) {
        const set = new Set()
        hits.forEach((particle, index) => {
          const line = particle.getLine()
          if (set.has(line)) errors.push(new ParserUsedMultipleTimesError(particle))
          set.add(line)
        })
      }
      return errors
    }
  
    get scopeErrors() {
      let errors: particlesTypes.ParticleError[] = []
      const def = this.definition
      if (def.isSingle) errors = errors.concat(this.singleParserUsedTwiceErrors) // todo: speedup. takes ~1s on pldb.
      if (def.isUniqueLine) errors = errors.concat(this.uniqueLineAppearsTwiceErrors) // todo: speedup. takes ~1s on pldb.
  
      const { requiredParticleErrors } = this // todo: speedup. takes ~1.5s on pldb.
      if (requiredParticleErrors.length) errors = errors.concat(requiredParticleErrors)
      return errors
    }
  
    getErrors() {
      return this.atomErrors.concat(this.scopeErrors)
    }
  
    get parsedAtoms(): AbstractParsersBackedAtom[] {
      return this.definition.atomParser.getAtomArray(this)
    }
  
    // todo: just make a fn that computes proper spacing and then is given a particle to print
    get lineAtomTypes() {
      return this.parsedAtoms.map(slot => slot.atomTypeId).join(" ")
    }
  
    getLineAtomPreludeTypes() {
      return this.parsedAtoms
        .map(slot => {
          const def = slot.atomTypeDefinition
          //todo: cleanup
          return def ? def.preludeKindId : PreludeAtomTypeIds.anyAtom
        })
        .join(" ")
    }
  
    getLinePaints(defaultScope = "source") {
      return this.parsedAtoms.map(slot => slot.paint || defaultScope).join(" ")
    }
  
    get atomDefinitionLineNumbers() {
      return this.parsedAtoms.map(atom => atom.definitionLineNumber)
    }
  
    protected _getCompiledIndentation() {
      const indentCharacter = this.definition._getCompilerObject()[ParsersConstantsCompiler.indentCharacter]
      const indent = this.indentation
      return indentCharacter !== undefined ? indentCharacter.repeat(indent.length) : indent
    }
  
    private _getFields() {
      // fields are like atoms
      const fields: any = {}
      this.forEach(particle => {
        const def = particle.definition
        if (def.isRequired() || def.isSingle) fields[particle.getAtom(0)] = particle.content
      })
      return fields
    }
  
    protected _getCompiledLine() {
      const compiler = this.definition._getCompilerObject()
      const catchAllAtomDelimiter = compiler[ParsersConstantsCompiler.catchAllAtomDelimiter]
      const str = compiler[ParsersConstantsCompiler.stringTemplate]
      return str !== undefined ? Utils.formatStr(str, catchAllAtomDelimiter, Object.assign(this._getFields(), this.atomsMap)) : this.getLine()
    }
  
    protected get listDelimiter() {
      return this.definition._getFromExtended(ParsersConstants.listDelimiter)
    }
  
    protected get contentKey() {
      return this.definition._getFromExtended(ParsersConstants.contentKey)
    }
  
    protected get subparticlesKey() {
      return this.definition._getFromExtended(ParsersConstants.subparticlesKey)
    }
  
    protected get subparticlesAreTextBlob() {
      return this.definition._isBlobParser()
    }
  
    protected get isArrayElement() {
      return this.definition._hasFromExtended(ParsersConstants.uniqueCue) ? false : !this.definition.isSingle
    }
  
    get list() {
      return this.listDelimiter ? this.content.split(this.listDelimiter) : super.list
    }
  
    get typedContent() {
      // todo: probably a better way to do this, perhaps by defining a atomDelimiter at the particle level
      // todo: this currently parse anything other than string types
      if (this.listDelimiter) return this.content.split(this.listDelimiter)
  
      const atoms = this.parsedAtoms
      if (atoms.length === 2) return atoms[1].parsed
      return this.content
    }
  
    get typedTuple() {
      const key = this.cue
      if (this.subparticlesAreTextBlob) return [key, this.subparticlesToString()]
  
      const { typedContent, contentKey, subparticlesKey } = this
  
      if (contentKey || subparticlesKey) {
        let obj: any = {}
        if (subparticlesKey) obj[subparticlesKey] = this.subparticlesToString()
        else obj = this.typedMap
  
        if (contentKey) {
          obj[contentKey] = typedContent
        }
        return [key, obj]
      }
  
      const hasSubparticles = this.length > 0
  
      const hasSubparticlesNoContent = typedContent === undefined && hasSubparticles
      const shouldReturnValueAsObject = hasSubparticlesNoContent
      if (shouldReturnValueAsObject) return [key, this.typedMap]
  
      const hasSubparticlesAndContent = typedContent !== undefined && hasSubparticles
      const shouldReturnValueAsContentPlusSubparticles = hasSubparticlesAndContent
  
      // If the particle has a content and a subparticle return it as a string, as
      // Javascript object values can't be both a leaf and a particle.
      if (shouldReturnValueAsContentPlusSubparticles) return [key, this.contentWithSubparticles]
  
      return [key, typedContent]
    }
  
    get _shouldSerialize() {
      const should = (this).shouldSerialize
      return should === undefined ? true : should
    }
  
    get typedMap() {
      const obj: particlesTypes.stringMap = {}
      this.forEach((particle: ParserBackedParticle) => {
        if (!particle._shouldSerialize) return true
  
        const tuple = particle.typedTuple
        if (!particle.isArrayElement) obj[tuple[0]] = tuple[1]
        else {
          if (!obj[tuple[0]]) obj[tuple[0]] = []
          obj[tuple[0]].push(tuple[1])
        }
      })
      return obj
    }
  
    fromTypedMap() {}
  
    compile() {
      if (this.isRoot()) return super.compile()
      const def = this.definition
      const indent = this._getCompiledIndentation()
      const compiledLine = this._getCompiledLine()
  
      if (def.isTerminalParser()) return indent + compiledLine
  
      const compiler = def._getCompilerObject()
      const openSubparticlesString = compiler[ParsersConstantsCompiler.openSubparticles] || ""
      const closeSubparticlesString = compiler[ParsersConstantsCompiler.closeSubparticles] || ""
      const subparticleJoinCharacter = compiler[ParsersConstantsCompiler.joinSubparticlesWith] || "\n"
  
      const compiledSubparticles = this.map(subparticle => subparticle.compile()).join(subparticleJoinCharacter)
  
      return `${indent + compiledLine}${openSubparticlesString}
  ${compiledSubparticles}
  ${indent}${closeSubparticlesString}`
    }
  
    // todo: remove
    get atomsMap() {
      const atomsMap: particlesTypes.stringMap = {}
      this.parsedAtoms.forEach(atom => {
        const atomTypeId = atom.atomTypeId
        if (!atom.isCatchAll()) atomsMap[atomTypeId] = atom.parsed
        else {
          if (!atomsMap[atomTypeId]) atomsMap[atomTypeId] = []
          atomsMap[atomTypeId].push(atom.parsed)
        }
      })
      return atomsMap
    }
  }
  
  class BlobParser extends ParserBackedParticle {
    createParserPool() {
      return new Particle.ParserPool(BlobParser, {})
    }
  
    getErrors(): particlesTypes.ParticleError[] {
      return []
    }
  }
  
  // todo: can we remove this? hard to extend.
  class UnknownParserParticle extends ParserBackedParticle {
    createParserPool() {
      return new Particle.ParserPool(UnknownParserParticle, {})
    }
  
    getErrors(): particlesTypes.ParticleError[] {
      return [new UnknownParserError(this)]
    }
  }
  
  /*
  A atom contains a atom but also the type information for that atom.
  */
  abstract class AbstractParsersBackedAtom {
    constructor(particle: ParserBackedParticle, index: particlesTypes.int, typeDef: atomTypeDefinitionParser, atomTypeId: string, isCatchAll: boolean, parserDefinitionParser: AbstractParserDefinitionParser) {
      this._typeDef = typeDef
      this._particle = particle
      this._isCatchAll = isCatchAll
      this._index = index
      this._atomTypeId = atomTypeId
      this._parserDefinitionParser = parserDefinitionParser
    }
  
    get optionCount() {
      return this._typeDef.optionCount
    }
    get bitsRequired() {
      return Math.log2(this.optionCount)
    }
  
    getAtom() {
      return this._particle.getAtom(this._index)
    }
  
    get definitionLineNumber() {
      return this._typeDef.lineNumber
    }
  
    private _particle: ParserBackedParticle
    protected _index: particlesTypes.int
    private _typeDef: atomTypeDefinitionParser
    private _isCatchAll: boolean
    private _atomTypeId: string
    protected _parserDefinitionParser: AbstractParserDefinitionParser
  
    get atomTypeId() {
      return this._atomTypeId
    }
  
    static parserFunctionName = ""
  
    getParticle() {
      return this._particle
    }
  
    get atomIndex() {
      return this._index
    }
  
    isCatchAll() {
      return this._isCatchAll
    }
  
    get min() {
      return this.atomTypeDefinition.get(ParsersConstants.min) || "0"
    }
  
    get max() {
      return this.atomTypeDefinition.get(ParsersConstants.max) || "100"
    }
  
    get placeholder() {
      return this.atomTypeDefinition.get(ParsersConstants.examples) || ""
    }
  
    abstract get parsed(): T
  
    get paint(): string | undefined {
      const definition = this.atomTypeDefinition
      if (definition) return definition.paint // todo: why the undefined?
    }
  
    getAutoCompleteAtoms(partialAtom: string = "") {
      const atomDef = this.atomTypeDefinition
      let atoms = atomDef ? atomDef._getAutocompleteAtomOptions(this.getParticle().root) : []
  
      const runTimeOptions = this.getParticle().getRunTimeEnumOptions(this)
      if (runTimeOptions) atoms = runTimeOptions.concat(atoms)
  
      if (partialAtom) atoms = atoms.filter(atom => atom.includes(partialAtom))
      return atoms.map(atom => {
        return {
          text: atom,
          displayText: atom
        }
      })
    }
  
    synthesizeAtom(seed = Date.now()): string {
      // todo: cleanup
      const atomDef = this.atomTypeDefinition
      const enumOptions = atomDef._getFromExtended(ParsersConstants.enum)
      if (enumOptions) return Utils.getRandomString(1, enumOptions.split(" "))
  
      return this._synthesizeAtom(seed)
    }
  
    abstract _synthesizeAtom(seed?: number): string
  
    get atomTypeDefinition() {
      return this._typeDef
    }
  
    protected _getErrorContext() {
      return this.getParticle().getLine().split(" ")[0] // todo: AtomBreakSymbol
    }
  
    protected abstract _isValid(): boolean
  
    isValid(): boolean {
      const runTimeOptions = this.getParticle().getRunTimeEnumOptionsForValidation(this)
      const atom = this.getAtom()
      if (runTimeOptions) return runTimeOptions.includes(atom)
      return this.atomTypeDefinition.isValid(atom, this.getParticle().root) && this._isValid()
    }
  
    getErrorIfAny(): particlesTypes.ParticleError {
      const atom = this.getAtom()
      if (atom !== undefined && this.isValid()) return undefined
  
      // todo: refactor invalidatomError. We want better error messages.
      return atom === undefined || atom === "" ? new MissingAtomError(this) : new InvalidAtomError(this)
    }
  }
  
  class ParsersBitAtom extends AbstractParsersBackedAtom {
    _isValid() {
      const atom = this.getAtom()
      return atom === "0" || atom === "1"
    }
  
    get optionCount() {
      return 2
    }
  
    static defaultPaint = "constant.numeric"
  
    _synthesizeAtom() {
      return Utils.getRandomString(1, "01".split(""))
    }
  
    get regexString() {
      return "[01]"
    }
  
    get parsed() {
      const atom = this.getAtom()
      return !!parseInt(atom)
    }
  }
  
  abstract class ParsersNumberAtom extends AbstractParsersBackedAtom {}
  
  class ParsersIntegerAtom extends ParsersNumberAtom {
    _isValid() {
      const atom = this.getAtom()
      const num = parseInt(atom)
      if (isNaN(num)) return false
      return num.toString() === atom
    }
  
    get optionCount() {
      const minVal = parseInt(this.min) || -Infinity
      const maxVal = parseInt(this.max) || Infinity
      return maxVal - minVal + 1
    }
  
    static defaultPaint = "constant.numeric.integer"
  
    _synthesizeAtom(seed: number) {
      return Utils.randomUniformInt(parseInt(this.min), parseInt(this.max), seed).toString()
    }
  
    get regexString() {
      return "-?[0-9]+"
    }
  
    get parsed() {
      const atom = this.getAtom()
      return parseInt(atom)
    }
  
    static parserFunctionName = "parseInt"
  }
  
  class ParsersFloatAtom extends ParsersNumberAtom {
    _isValid() {
      const atom = this.getAtom()
      const num = parseFloat(atom)
      return !isNaN(num) && /^-?\d*(\.\d+)?([eE][+-]?\d+)?$/.test(atom)
    }
  
    get optionCount() {
      // For floats, we'll estimate based on typical float32 precision
      // ~7 decimal digits of precision
      const minVal = parseInt(this.min) || -Infinity
      const maxVal = parseInt(this.max) || Infinity
      return (maxVal - minVal) * Math.pow(10, 7)
    }
  
    static defaultPaint = "constant.numeric.float"
  
    _synthesizeAtom(seed: number) {
      return Utils.randomUniformFloat(parseFloat(this.min), parseFloat(this.max), seed).toString()
    }
  
    get regexString() {
      return "-?d*(.d+)?"
    }
  
    get parsed() {
      const atom = this.getAtom()
      return parseFloat(atom)
    }
  
    static parserFunctionName = "parseFloat"
  }
  
  // ErrorAtomType => parsers asks for a '' atom type here but the parsers does not specify a '' atom type. (todo: bring in didyoumean?)
  
  class ParsersBooleanAtom extends AbstractParsersBackedAtom {
    private _trues = new Set(["1", "true", "t", "yes"])
    private _falses = new Set(["0", "false", "f", "no"])
  
    _isValid() {
      const atom = this.getAtom()
      const str = atom.toLowerCase()
      return this._trues.has(str) || this._falses.has(str)
    }
  
    get optionCount() {
      return 2
    }
  
    static defaultPaint = "constant.language"
  
    _synthesizeAtom() {
      return Utils.getRandomString(1, ["1", "true", "t", "yes", "0", "false", "f", "no"])
    }
  
    private _getOptions() {
      return Array.from(this._trues).concat(Array.from(this._falses))
    }
  
    get regexString() {
      return "(?:" + this._getOptions().join("|") + ")"
    }
  
    get parsed() {
      const atom = this.getAtom()
      return this._trues.has(atom.toLowerCase())
    }
  }
  
  class ParsersAnyAtom extends AbstractParsersBackedAtom {
    _isValid() {
      return true
    }
  
    _synthesizeAtom() {
      const examples = this.atomTypeDefinition._getFromExtended(ParsersConstants.examples)
      if (examples) return Utils.getRandomString(1, examples.split(" "))
      return this._parserDefinitionParser.parserIdFromDefinition + "-" + this.constructor.name
    }
  
    get regexString() {
      return "[^ ]+"
    }
  
    get parsed() {
      return this.getAtom()
    }
  }
  
  class ParsersCueAtom extends ParsersAnyAtom {
    static defaultPaint = "keyword"
  
    _synthesizeAtom() {
      return this._parserDefinitionParser.cueIfAny
    }
  
    get optionCount() {
      return 1
    }
  }
  
  class ParsersExtraAtomAtomTypeAtom extends AbstractParsersBackedAtom {
    _isValid() {
      return false
    }
  
    synthesizeAtom() {
      throw new Error(`Trying to synthesize a ParsersExtraAtomAtomTypeAtom`)
      return this._synthesizeAtom()
    }
  
    _synthesizeAtom() {
      return "extraAtom" // should never occur?
    }
  
    get parsed() {
      return this.getAtom()
    }
  
    getErrorIfAny(): particlesTypes.ParticleError {
      return new ExtraAtomError(this)
    }
  }
  
  class ParsersUnknownAtomTypeAtom extends AbstractParsersBackedAtom {
    _isValid() {
      return false
    }
  
    synthesizeAtom() {
      throw new Error(`Trying to synthesize an ParsersUnknownAtomTypeAtom`)
      return this._synthesizeAtom()
    }
  
    _synthesizeAtom() {
      return "extraAtom" // should never occur?
    }
  
    get parsed() {
      return this.getAtom()
    }
  
    getErrorIfAny(): particlesTypes.ParticleError {
      return new UnknownAtomTypeError(this)
    }
  }
  
  abstract class AbstractParticleError implements particlesTypes.ParticleError {
    constructor(particle: ParserBackedParticle) {
      this._particle = particle
    }
    private _particle: ParserBackedParticle // todo: would it ever be a Particle?
  
    getLineIndex(): particlesTypes.positiveInt {
      return this.lineNumber - 1
    }
  
    get lineNumber(): particlesTypes.positiveInt {
      return this.getParticle()._getLineNumber() // todo: handle sourcemaps
    }
  
    isCursorOnAtom(lineIndex: particlesTypes.positiveInt, characterIndex: particlesTypes.positiveInt) {
      return lineIndex === this.getLineIndex() && this._doesCharacterIndexFallOnAtom(characterIndex)
    }
  
    private _doesCharacterIndexFallOnAtom(characterIndex: particlesTypes.positiveInt) {
      return this.atomIndex === this.getParticle().getAtomIndexAtCharacterIndex(characterIndex)
    }
  
    // convenience method. may be removed.
    isBlankLineError() {
      return false
    }
  
    // convenience method. may be removed.
    isMissingAtomError() {
      return false
    }
  
    getIndent() {
      return this.getParticle().indentation
    }
  
    getCodeMirrorLineWidgetElement(onApplySuggestionCallBack = () => {}) {
      const suggestion = this.suggestionMessage
      if (this.isMissingAtomError()) return this._getCodeMirrorLineWidgetElementAtomTypeHints()
      if (suggestion) return this._getCodeMirrorLineWidgetElementWithSuggestion(onApplySuggestionCallBack, suggestion)
      return this._getCodeMirrorLineWidgetElementWithoutSuggestion()
    }
  
    get parserId(): string {
      return (this.getParticle()).parserId
    }
  
    private _getCodeMirrorLineWidgetElementAtomTypeHints() {
      const el = document.createElement("div")
      el.appendChild(document.createTextNode(this.getIndent() + (this.getParticle()).definition.lineHints))
      el.className = "LintAtomTypeHints"
      return el
    }
  
    private _getCodeMirrorLineWidgetElementWithoutSuggestion() {
      const el = document.createElement("div")
      el.appendChild(document.createTextNode(this.getIndent() + this.message))
      el.className = "LintError"
      return el
    }
  
    private _getCodeMirrorLineWidgetElementWithSuggestion(onApplySuggestionCallBack: Function, suggestion: string) {
      const el = document.createElement("div")
      el.appendChild(document.createTextNode(this.getIndent() + `${this.errorTypeName}. Suggestion: ${suggestion}`))
      el.className = "LintErrorWithSuggestion"
      el.onclick = () => {
        this.applySuggestion()
        onApplySuggestionCallBack()
      }
      return el
    }
  
    getLine() {
      return this.getParticle().getLine()
    }
  
    getExtension() {
      return this.getParticle().handParsersProgram.extensionName
    }
  
    getParticle() {
      return this._particle
    }
  
    get errorTypeName() {
      return this.constructor.name.replace("Error", "")
    }
  
    get atomIndex() {
      return 0
    }
  
    toObject() {
      return {
        type: this.errorTypeName,
        line: this.lineNumber,
        atom: this.atomIndex,
        suggestion: this.suggestionMessage,
        path: this.getParticle().getCuePath(),
        message: this.message
      }
    }
  
    hasSuggestion() {
      return this.suggestionMessage !== ""
    }
  
    get suggestionMessage() {
      return ""
    }
  
    toString() {
      return this.message
    }
  
    applySuggestion() {}
  
    get message(): string {
      return `${this.errorTypeName} at line ${this.lineNumber} atom ${this.atomIndex}.`
    }
  }
  
  abstract class AbstractAtomError extends AbstractParticleError {
    constructor(atom: AbstractParsersBackedAtom) {
      super(atom.getParticle())
      this._atom = atom
    }
  
    get atom() {
      return this._atom
    }
  
    get atomIndex() {
      return this._atom.atomIndex
    }
  
    protected get atomSuggestion() {
      return Utils.didYouMean(
        this.atom.getAtom(),
        this.atom.getAutoCompleteAtoms().map(option => option.text)
      )
    }
  
    private _atom: AbstractParsersBackedAtom
  }
  
  class UnknownParserError extends AbstractParticleError {
    get message(): string {
      const particle = this.getParticle()
      const parentParticle = particle.parent
      const options = parentParticle._getParserPool().getCueOptions()
      return super.message + ` Invalid parser "${particle.cue}". Valid parsers are: ${Utils._listToEnglishText(options, 7)}.`
    }
  
    protected get atomSuggestion() {
      const particle = this.getParticle()
      const parentParticle = particle.parent
      return Utils.didYouMean(
        particle.cue,
        (parentParticle).getAutocompleteResults("", 0).map(option => option.text)
      )
    }
  
    get suggestionMessage() {
      const suggestion = this.atomSuggestion
      const particle = this.getParticle()
  
      if (suggestion) return `Change "${particle.cue}" to "${suggestion}"`
  
      return ""
    }
  
    applySuggestion() {
      const suggestion = this.atomSuggestion
      if (suggestion) this.getParticle().setAtom(this.atomIndex, suggestion)
      return this
    }
  }
  
  class ParserDefinedError extends AbstractParticleError {
    constructor(particle: ParserBackedParticle, message: string) {
      super()
      this._particle = particle
      this._message = message
    }
    private _message: string
    get message() {
      return this._message
    }
  }
  
  class BlankLineError extends UnknownParserError {
    get message(): string {
      return super.message + ` Line: "${this.getParticle().getLine()}". Blank lines are errors.`
    }
  
    // convenience method
    isBlankLineError() {
      return true
    }
  
    get suggestionMessage() {
      return `Delete line ${this.lineNumber}`
    }
  
    applySuggestion() {
      this.getParticle().destroy()
      return this
    }
  }
  
  class MissingRequiredParserError extends AbstractParticleError {
    constructor(particle: ParserBackedParticle, missingParserId: particlesTypes.cue) {
      super(particle)
      this._missingParserId = missingParserId
    }
  
    private _missingParserId: particlesTypes.parserId
  
    get message(): string {
      return super.message + ` A "${this._missingParserId}" is required.`
    }
  }
  
  class ParserUsedMultipleTimesError extends AbstractParticleError {
    get message(): string {
      return super.message + ` Multiple "${this.getParticle().cue}" found.`
    }
  
    get suggestionMessage() {
      return `Delete line ${this.lineNumber}`
    }
  
    applySuggestion() {
      return this.getParticle().destroy()
    }
  }
  
  class LineAppearsMultipleTimesError extends AbstractParticleError {
    get message(): string {
      return super.message + ` "${this.getParticle().getLine()}" appears multiple times.`
    }
  
    get suggestionMessage() {
      return `Delete line ${this.lineNumber}`
    }
  
    applySuggestion() {
      return this.getParticle().destroy()
    }
  }
  
  class UnknownAtomTypeError extends AbstractAtomError {
    get message(): string {
      return super.message + ` No atomType "${this.atom.atomTypeId}" found. Language parsers for "${this.getExtension()}" may need to be fixed.`
    }
  }
  
  class InvalidAtomError extends AbstractAtomError {
    get message(): string {
      return super.message + ` "${this.atom.getAtom()}" does not fit in atomType "${this.atom.atomTypeId}".`
    }
  
    get suggestionMessage() {
      const suggestion = this.atomSuggestion
  
      if (suggestion) return `Change "${this.atom.getAtom()}" to "${suggestion}"`
  
      return ""
    }
  
    applySuggestion() {
      const suggestion = this.atomSuggestion
      if (suggestion) this.getParticle().setAtom(this.atomIndex, suggestion)
      return this
    }
  }
  
  class ExtraAtomError extends AbstractAtomError {
    get message(): string {
      return super.message + ` Extra atom "${this.atom.getAtom()}" in ${this.parserId}.`
    }
  
    get suggestionMessage() {
      return `Delete atom "${this.atom.getAtom()}" at atom ${this.atomIndex}`
    }
  
    applySuggestion() {
      return this.getParticle().deleteAtomAt(this.atomIndex)
    }
  }
  
  class MissingAtomError extends AbstractAtomError {
    // todo: autocomplete suggestion
  
    get message(): string {
      return super.message + ` Missing atom for atom "${this.atom.atomTypeId}".`
    }
  
    isMissingAtomError() {
      return true
    }
  }
  
  // todo: add standard types, enum types, from disk types
  
  abstract class AbstractParsersAtomTestParser extends Particle {
    abstract isValid(str: string, programRootParticle?: ParserBackedParticle): boolean
  }
  
  class ParsersRegexTestParser extends AbstractParsersAtomTestParser {
    private _regex: RegExp
  
    isValid(str: string) {
      if (!this._regex) this._regex = new RegExp("^" + this.content + "$")
      return !!str.match(this._regex)
    }
  }
  
  class ParsersReservedAtomsTestParser extends AbstractParsersAtomTestParser {
    private _set: Set
  
    isValid(str: string) {
      if (!this._set) this._set = new Set(this.content.split(" "))
      return !this._set.has(str)
    }
  }
  
  // todo: remove in favor of custom atom type constructors
  class EnumFromAtomTypesTestParser extends AbstractParsersAtomTestParser {
    _getEnumFromAtomTypes(programRootParticle: ParserBackedParticle): particlesTypes.stringMap {
      const atomTypeIds = this.getAtomsFrom(1)
      const enumGroup = atomTypeIds.join(" ")
      // note: hack where we store it on the program. otherwise has global effects.
      if (!(programRootParticle)._enumMaps) (programRootParticle)._enumMaps = {}
      if ((programRootParticle)._enumMaps[enumGroup]) return (programRootParticle)._enumMaps[enumGroup]
  
      const atomIndex = 1
      const map: particlesTypes.stringMap = {}
      const atomTypeMap: particlesTypes.stringMap = {}
      atomTypeIds.forEach(typeId => (atomTypeMap[typeId] = true))
      programRootParticle.allTypedAtoms
        .filter((typedAtom: TypedAtom) => atomTypeMap[typedAtom.type])
        .forEach(typedAtom => {
          map[typedAtom.atom] = true
        })
      ;(programRootParticle)._enumMaps[enumGroup] = map
      return map
    }
  
    // todo: remove
    isValid(str: string, programRootParticle: ParserBackedParticle) {
      return this._getEnumFromAtomTypes(programRootParticle)[str] === true
    }
  }
  
  class ParsersEnumTestParticle extends AbstractParsersAtomTestParser {
    private _map: particlesTypes.stringMap
  
    isValid(str: string) {
      // enum c c++ java
      return !!this.getOptions()[str]
    }
  
    getOptions() {
      if (!this._map) this._map = Utils.arrayToMap(this.getAtomsFrom(1))
      return this._map
    }
  }
  
  class atomTypeDefinitionParser extends AbstractExtendibleParticle {
    createParserPool() {
      const types: particlesTypes.stringMap = {}
      types[ParsersConstants.regex] = ParsersRegexTestParser
      types[ParsersConstants.reservedAtoms] = ParsersReservedAtomsTestParser
      types[ParsersConstants.enumFromAtomTypes] = EnumFromAtomTypesTestParser
      types[ParsersConstants.enum] = ParsersEnumTestParticle
      types[ParsersConstants.paint] = Particle
      types[ParsersConstants.comment] = Particle
      types[ParsersConstants.examples] = Particle
      types[ParsersConstants.min] = Particle
      types[ParsersConstants.max] = Particle
      types[ParsersConstants.description] = Particle
      types[ParsersConstants.extends] = Particle
      return new Particle.ParserPool(undefined, types)
    }
  
    get id() {
      return this.getAtom(0)
    }
  
    get idToParticleMap() {
      return (this.parent).atomTypeDefinitions
    }
  
    getGetter(atomIndex: number) {
      const atomToNativeJavascriptTypeParser = this.getAtomConstructor().parserFunctionName
      return `get ${this.atomTypeId}() {
        return ${atomToNativeJavascriptTypeParser ? atomToNativeJavascriptTypeParser + `(this.getAtom(${atomIndex}))` : `this.getAtom(${atomIndex})`}
      }`
    }
  
    getCatchAllGetter(atomIndex: number) {
      const atomToNativeJavascriptTypeParser = this.getAtomConstructor().parserFunctionName
      return `get ${this.atomTypeId}() {
        return ${atomToNativeJavascriptTypeParser ? `this.getAtomsFrom(${atomIndex}).map(val => ${atomToNativeJavascriptTypeParser}(val))` : `this.getAtomsFrom(${atomIndex})`}
      }`
    }
  
    // `this.getAtomsFrom(${requireds.length + 1})`
  
    // todo: cleanup typings. todo: remove this hidden logic. have a "baseType" property?
    getAtomConstructor(): typeof AbstractParsersBackedAtom {
      return this.preludeKind || ParsersAnyAtom
    }
  
    get preludeKind() {
      return PreludeKinds[this.getAtom(0)] || PreludeKinds[this._getExtendedAtomTypeId()]
    }
  
    get preludeKindId() {
      if (PreludeKinds[this.getAtom(0)]) return this.getAtom(0)
      else if (PreludeKinds[this._getExtendedAtomTypeId()]) return this._getExtendedAtomTypeId()
      return PreludeAtomTypeIds.anyAtom
    }
  
    private _getExtendedAtomTypeId() {
      const arr = this._getAncestorsArray()
      return arr[arr.length - 1].id
    }
  
    get paint(): string | undefined {
      const hs = this._getFromExtended(ParsersConstants.paint)
      if (hs) return hs
      const preludeKind = this.preludeKind
      if (preludeKind) return preludeKind.defaultPaint
    }
  
    _getEnumOptions() {
      const enumParticle = this._getParticleFromExtended(ParsersConstants.enum)
      if (!enumParticle) return undefined
  
      // we sort by longest first to capture longest match first. todo: add test
      const options = Object.keys((enumParticle.getParticle(ParsersConstants.enum)).getOptions())
      options.sort((a, b) => b.length - a.length)
  
      return options
    }
  
    get optionCount() {
      const enumOptions = this._getEnumOptions()
      if (enumOptions) return enumOptions.length
      return Infinity
    }
  
    private _getEnumFromAtomTypeOptions(program: ParserBackedParticle) {
      const particle = this._getParticleFromExtended(ParsersConstants.enumFromAtomTypes)
      return particle ? Object.keys((particle.getParticle(ParsersConstants.enumFromAtomTypes))._getEnumFromAtomTypes(program)) : undefined
    }
  
    _getAutocompleteAtomOptions(program: ParserBackedParticle): string[] {
      return this._getEnumOptions() || this._getEnumFromAtomTypeOptions(program) || []
    }
  
    get regexString() {
      // todo: enum
      const enumOptions = this._getEnumOptions()
      return this._getFromExtended(ParsersConstants.regex) || (enumOptions ? "(?:" + enumOptions.join("|") + ")" : "[^ ]*")
    }
  
    private _getAllTests() {
      return this._getSubparticlesByParserInExtended(AbstractParsersAtomTestParser)
    }
  
    isValid(str: string, programRootParticle: ParserBackedParticle) {
      return this._getAllTests().every(particle => (particle).isValid(str, programRootParticle))
    }
  
    get atomTypeId(): particlesTypes.atomTypeId {
      return this.getAtom(0)
    }
  
    public static types: any
  }
  
  abstract class AbstractAtomParser {
    constructor(definition: AbstractParserDefinitionParser) {
      this._definition = definition
    }
  
    get catchAllAtomTypeId(): particlesTypes.atomTypeId | undefined {
      return this._definition._getFromExtended(ParsersConstants.catchAllAtomType)
    }
  
    // todo: improve layout (use bold?)
    get lineHints(): string {
      const catchAllAtomTypeId = this.catchAllAtomTypeId
      const parserId = this._definition.cueIfAny || this._definition.id // todo: cleanup
      return `${parserId}: ${this.getRequiredAtomTypeIds().join(" ")}${catchAllAtomTypeId ? ` ${catchAllAtomTypeId}...` : ""}`
    }
  
    protected _definition: AbstractParserDefinitionParser
  
    private _requiredAtomTypeIds: string[]
    getRequiredAtomTypeIds(): particlesTypes.atomTypeId[] {
      if (!this._requiredAtomTypeIds) {
        const parameters = this._definition._getFromExtended(ParsersConstants.atoms)
        this._requiredAtomTypeIds = parameters ? parameters.split(" ") : []
      }
      return this._requiredAtomTypeIds
    }
  
    protected _getAtomTypeId(atomIndex: particlesTypes.int, requiredAtomTypeIds: string[], totalAtomCount: particlesTypes.int) {
      return requiredAtomTypeIds[atomIndex]
    }
  
    protected _isCatchAllAtom(atomIndex: particlesTypes.int, numberOfRequiredAtoms: particlesTypes.int, totalAtomCount: particlesTypes.int) {
      return atomIndex >= numberOfRequiredAtoms
    }
  
    getAtomArray(particle: ParserBackedParticle = undefined): AbstractParsersBackedAtom[] {
      const atomCount = particle ? particle.atoms.length : 0
      const def = this._definition
      const parsersProgram = def.languageDefinitionProgram
      const requiredAtomTypeIds = this.getRequiredAtomTypeIds()
      const numberOfRequiredAtoms = requiredAtomTypeIds.length
  
      const actualAtomCountOrRequiredAtomCount = Math.max(atomCount, numberOfRequiredAtoms)
      const atoms: AbstractParsersBackedAtom[] = []
  
      // A for loop instead of map because "numberOfAtomsToFill" can be longer than atoms.length
      for (let atomIndex = 0; atomIndex atomConstructor
        atoms[atomIndex] = new anyAtomConstructor(particle, atomIndex, atomTypeDefinition, atomTypeId, isCatchAll, def)
      }
      return atoms
    }
  }
  
  class PrefixAtomParser extends AbstractAtomParser {}
  
  class PostfixAtomParser extends AbstractAtomParser {
    protected _isCatchAllAtom(atomIndex: particlesTypes.int, numberOfRequiredAtoms: particlesTypes.int, totalAtomCount: particlesTypes.int) {
      return atomIndex [] {
      const atomsArr: AbstractParsersBackedAtom[] = []
      const def = this._definition
      const program = (particle ? particle.root : undefined)
      const parsersProgram = def.languageDefinitionProgram
      const atoms = particle ? particle.atoms : []
      const requiredAtomTypeDefs = this.getRequiredAtomTypeIds().map(atomTypeId => parsersProgram.getAtomTypeDefinitionById(atomTypeId))
      const catchAllAtomTypeId = this.catchAllAtomTypeId
      const catchAllAtomTypeDef = catchAllAtomTypeId && parsersProgram.getAtomTypeDefinitionById(catchAllAtomTypeId)
  
      atoms.forEach((atom, atomIndex) => {
        let atomConstructor: any
        for (let index = 0; index  {
        let atomConstructor: any = atomTypeDef.getAtomConstructor()
        atomsArr.push(new atomConstructor(particle, atomCount + index, atomTypeDef, atomTypeDef.id, false, def))
      })
  
      return atomsArr
    }
  }
  
  class ParsersExampleParser extends Particle {}
  
  class ParsersCompilerParser extends Particle {
    createParserPool() {
      const types = [
        ParsersConstantsCompiler.stringTemplate,
        ParsersConstantsCompiler.indentCharacter,
        ParsersConstantsCompiler.catchAllAtomDelimiter,
        ParsersConstantsCompiler.joinSubparticlesWith,
        ParsersConstantsCompiler.openSubparticles,
        ParsersConstantsCompiler.closeSubparticles
      ]
      const map: particlesTypes.cueToParserMap = {}
      types.forEach(type => {
        map[type] = Particle
      })
      return new Particle.ParserPool(undefined, map)
    }
  }
  
  abstract class AbstractParserConstantParser extends Particle {
    constructor(subparticles?: particlesTypes.subparticles, line?: string, parent?: Particle) {
      super(subparticles, line, parent)
      parent[this.identifier] = this.constantValue
    }
  
    getGetter() {
      return `get ${this.identifier}() { return ${this.constantValueAsJsText} }`
    }
  
    get identifier() {
      return this.getAtom(1)
    }
  
    get constantValueAsJsText() {
      const atoms = this.getAtomsFrom(2)
      return atoms.length > 1 ? `[${atoms.join(",")}]` : atoms[0]
    }
  
    get constantValue() {
      return JSON.parse(this.constantValueAsJsText)
    }
  }
  
  class ParsersParserConstantInt extends AbstractParserConstantParser {}
  class ParsersParserConstantString extends AbstractParserConstantParser {
    get constantValueAsJsText() {
      return "`" + Utils.escapeBackTicks(this.constantValue) + "`"
    }
  
    get constantValue() {
      return this.length ? this.subparticlesToString() : this.getAtomsFrom(2).join(" ")
    }
  }
  class ParsersParserConstantFloat extends AbstractParserConstantParser {}
  class ParsersParserConstantBoolean extends AbstractParserConstantParser {}
  
  abstract class AbstractParserDefinitionParser extends AbstractExtendibleParticle {
    createParserPool() {
      // todo: some of these should just be on nonRootParticles
      const types = [
        ParsersConstants.popularity,
        ParsersConstants.inScope,
        ParsersConstants.atoms,
        ParsersConstants.extends,
        ParsersConstants.description,
        ParsersConstants.catchAllParser,
        ParsersConstants.catchAllAtomType,
        ParsersConstants.atomParser,
        ParsersConstants.tags,
        ParsersConstants.cue,
        ParsersConstants.cueFromId,
        ParsersConstants.listDelimiter,
        ParsersConstants.contentKey,
        ParsersConstants.subparticlesKey,
        ParsersConstants.uniqueCue,
        ParsersConstants.uniqueLine,
        ParsersConstants.pattern,
        ParsersConstants.baseParser,
        ParsersConstants.required,
        ParsersConstants.root,
        ParsersConstants.javascript,
        ParsersConstants.javascript,
        ParsersConstants.single,
        ParsersConstants.comment
      ]
  
      const map: particlesTypes.cueToParserMap = {}
      types.forEach(type => {
        map[type] = Particle
      })
      map[ParsersConstantsConstantTypes.boolean] = ParsersParserConstantBoolean
      map[ParsersConstantsConstantTypes.int] = ParsersParserConstantInt
      map[ParsersConstantsConstantTypes.string] = ParsersParserConstantString
      map[ParsersConstantsConstantTypes.float] = ParsersParserConstantFloat
      map[ParsersConstants.compilerParser] = ParsersCompilerParser
      map[ParsersConstants.example] = ParsersExampleParser
      return new Particle.ParserPool(undefined, map, [{ regex: HandParsersProgram.parserFullRegex, parser: parserDefinitionParser }])
    }
  
    toTypeScriptInterface(used = new Set()) {
      let subparticlesInterfaces: string[] = []
      let properties: string[] = []
      const inScope = this.cueMapWithDefinitions
      const thisId = this.id
  
      used.add(thisId)
      Object.keys(inScope).forEach(key => {
        const def = inScope[key]
        const map = def.cueMapWithDefinitions
        const id = def.id
        const optionalTag = def.isRequired() ? "" : "?"
        const escapedKey = key.match(/\?/) ? `"${key}"` : key
        const description = def.description
        if (Object.keys(map).length && !used.has(id)) {
          subparticlesInterfaces.push(def.toTypeScriptInterface(used))
          properties.push(` ${escapedKey}${optionalTag}: ${id}`)
        } else properties.push(` ${escapedKey}${optionalTag}: any${description ? " // " + description : ""}`)
      })
  
      properties.sort()
      const description = this.description
  
      const myInterface = ""
      return `${subparticlesInterfaces.join("\n")}
  ${description ? "// " + description : ""}
  interface ${thisId} {
  ${properties.join("\n")}
  }`.trim()
    }
  
    get id() {
      return this.getAtom(0)
    }
  
    get idWithoutSuffix() {
      return this.id.replace(HandParsersProgram.parserSuffixRegex, "")
    }
  
    get constantsObject() {
      const obj = this._getUniqueConstantParticles()
      Object.keys(obj).forEach(key => (obj[key] = obj[key].constantValue))
      return obj
    }
  
    _getUniqueConstantParticles(extended = true) {
      const obj: { [key: string]: AbstractParserConstantParser } = {}
      const items = extended ? this._getSubparticlesByParserInExtended(AbstractParserConstantParser) : this.getSubparticlesByParser(AbstractParserConstantParser)
      items.reverse() // Last definition wins.
      items.forEach((particle: AbstractParserConstantParser) => (obj[particle.identifier] = particle))
      return obj
    }
  
    get examples(): ParsersExampleParser[] {
      return this._getSubparticlesByParserInExtended(ParsersExampleParser)
    }
  
    get parserIdFromDefinition(): particlesTypes.parserId {
      return this.cue
    }
  
    // todo: remove? just reused parserId
    get generatedClassName() {
      return this.parserIdFromDefinition
    }
  
    _hasValidParserId() {
      return !!this.generatedClassName
    }
  
    _isAbstract() {
      return this.id.startsWith(ParsersConstants.abstractParserPrefix)
    }
  
    get cueIfAny(): string {
      return this.get(ParsersConstants.cue) || (this._hasFromExtended(ParsersConstants.cueFromId) ? this.idWithoutSuffix : undefined)
    }
  
    get regexMatch() {
      return this.get(ParsersConstants.pattern)
    }
  
    get cueEnumOptions() {
      const cueDef = this._getMyAtomTypeDefs()[0]
      return cueDef ? cueDef._getEnumOptions() : undefined
    }
  
    get languageDefinitionProgram(): HandParsersProgram {
      return this.root
    }
  
    protected get customJavascriptMethods(): particlesTypes.javascriptCode {
      const hasJsCode = this.has(ParsersConstants.javascript)
      return hasJsCode ? this.getParticle(ParsersConstants.javascript).subparticlesToString() : ""
    }
  
    private _cache_cueToParticleDefMap: { [cue: string]: parserDefinitionParser }
  
    get cueMapWithDefinitions() {
      if (!this._cache_cueToParticleDefMap) this._cache_cueToParticleDefMap = this._createParserInfo(this._getInScopeParserIds()).cueMap
      return this._cache_cueToParticleDefMap
    }
  
    // todo: remove
    get runTimeCuesInScope(): particlesTypes.parserId[] {
      return this._getParserPool().getCueOptions()
    }
  
    private _getMyAtomTypeDefs() {
      const requiredAtoms = this.get(ParsersConstants.atoms)
      if (!requiredAtoms) return []
      const parsersProgram = this.languageDefinitionProgram
      return requiredAtoms.split(" ").map(atomTypeId => {
        const atomTypeDef = parsersProgram.getAtomTypeDefinitionById(atomTypeId)
        if (!atomTypeDef) throw new Error(`No atomType "${atomTypeId}" found`)
        return atomTypeDef
      })
    }
  
    // todo: what happens when you have a atom getter and constant with same name?
    private get atomGettersAndParserConstants() {
      // todo: add atomType parsings
      const parsersProgram = this.languageDefinitionProgram
      const getters = this._getMyAtomTypeDefs().map((atomTypeDef, index) => atomTypeDef.getGetter(index))
  
      const catchAllAtomTypeId = this.get(ParsersConstants.catchAllAtomType)
      if (catchAllAtomTypeId) getters.push(parsersProgram.getAtomTypeDefinitionById(catchAllAtomTypeId).getCatchAllGetter(getters.length))
  
      // Constants
      Object.values(this._getUniqueConstantParticles(false)).forEach(particle => getters.push(particle.getGetter()))
  
      return getters.join("\n")
    }
  
    protected _createParserInfo(parserIdsInScope: particlesTypes.parserId[]): parserInfo {
      const result: parserInfo = {
        cueMap: {},
        regexTests: []
      }
  
      if (!parserIdsInScope.length) return result
  
      const allProgramParserDefinitionsMap = this.programParserDefinitionCache
      Object.keys(allProgramParserDefinitionsMap)
        .filter(parserId => {
          const def = allProgramParserDefinitionsMap[parserId]
          return def.isOrExtendsAParserInScope(parserIdsInScope) && !def._isAbstract()
        })
        .forEach(parserId => {
          const def = allProgramParserDefinitionsMap[parserId]
          const regex = def.regexMatch
          const cue = def.cueIfAny
          const enumOptions = def.cueEnumOptions
          if (regex) result.regexTests.push({ regex: regex, parser: def.parserIdFromDefinition })
          else if (cue) result.cueMap[cue] = def
          else if (enumOptions) {
            enumOptions.forEach(option => (result.cueMap[option] = def))
          }
        })
      return result
    }
  
    get topParserDefinitions(): parserDefinitionParser[] {
      const arr = Object.values(this.cueMapWithDefinitions)
      arr.sort(Utils.makeSortByFn((definition: parserDefinitionParser) => definition.popularity))
      arr.reverse()
      return arr
    }
  
    _getMyInScopeParserIds(target: AbstractParserDefinitionParser = this): particlesTypes.parserId[] {
      const parsersParticle = target.getParticle(ParsersConstants.inScope)
      const scopedDefinitionIds = target.myScopedParserDefinitions.map(def => def.id)
      return parsersParticle ? parsersParticle.getAtomsFrom(1).concat(scopedDefinitionIds) : scopedDefinitionIds
    }
  
    protected _getInScopeParserIds(): particlesTypes.parserId[] {
      // todo: allow multiple of these if we allow mixins?
      const ids = this._getMyInScopeParserIds()
      const parentDef = this._getExtendedParent()
      return parentDef ? ids.concat((parentDef)._getInScopeParserIds()) : ids
    }
  
    get isSingle() {
      const hit = this._getParticleFromExtended(ParsersConstants.single)
      return hit && hit.get(ParsersConstants.single) !== "false"
    }
  
    get isUniqueLine() {
      const hit = this._getParticleFromExtended(ParsersConstants.uniqueLine)
      return hit && hit.get(ParsersConstants.uniqueLine) !== "false"
    }
  
    isRequired(): boolean {
      return this._hasFromExtended(ParsersConstants.required)
    }
  
    getParserDefinitionByParserId(parserId: particlesTypes.parserId): AbstractParserDefinitionParser {
      // todo: return catch all?
      const def = this.programParserDefinitionCache[parserId]
      if (def) return def
      this.languageDefinitionProgram._addDefaultCatchAllBlobParser() // todo: cleanup. Why did I do this? Needs to be removed or documented.
      const particleDef = this.languageDefinitionProgram.programParserDefinitionCache[parserId]
      if (!particleDef) throw new Error(`No definition found for parser id "${parserId}". Particle: \n---\n${this.asString}\n---`)
      return particleDef
    }
  
    isDefined(parserId: string) {
      return !!this.programParserDefinitionCache[parserId]
    }
  
    get idToParticleMap() {
      return this.programParserDefinitionCache
    }
  
    private _cache_isRoot: boolean
  
    private _amIRoot(): boolean {
      if (this._cache_isRoot === undefined) this._cache_isRoot = this._languageRootParticle === this
      return this._cache_isRoot
    }
  
    private get _languageRootParticle() {
      return (this.root).rootParserDefinition
    }
  
    private _isErrorParser() {
      return this.get(ParsersConstants.baseParser) === ParsersConstants.errorParser
    }
  
    _isBlobParser() {
      // Do not check extended classes. Only do once.
      return this._getFromExtended(ParsersConstants.baseParser) === ParsersConstants.blobParser
    }
  
    private get errorMethodToJavascript(): particlesTypes.javascriptCode {
      if (this._isBlobParser()) return "getErrors() { return [] }" // Skips parsing subparticles for perf gains.
      if (this._isErrorParser()) return "getErrors() { return this._getErrorParserErrors() }"
      return ""
    }
  
    private get parserAsJavascript(): particlesTypes.javascriptCode {
      if (this._isBlobParser())
        // todo: do we need this?
        return "createParserPool() { return new Particle.ParserPool(this._getBlobParserCatchAllParser())}"
      const parserInfo = this._createParserInfo(this._getMyInScopeParserIds())
      const myCueMap = parserInfo.cueMap
      const regexRules = parserInfo.regexTests
  
      // todo: use constants in first atom maps?
      // todo: cache the super extending?
      const cues = Object.keys(myCueMap)
      const hasCues = cues.length
      const catchAllParser = this.catchAllParserToJavascript
      if (!hasCues && !catchAllParser && !regexRules.length) return ""
  
      const cuesStr = hasCues ? `Object.assign(Object.assign({}, super.createParserPool()._getCueMapAsObject()), {` + cues.map(cue => `"${cue}" : ${myCueMap[cue].parserIdFromDefinition}`).join(",\n") + "})" : "undefined"
  
      const regexStr = regexRules.length
        ? `[${regexRules
            .map(rule => {
              return `{regex: /${rule.regex}/, parser: ${rule.parser}}`
            })
            .join(",")}]`
        : "undefined"
  
      const catchAllStr = catchAllParser ? catchAllParser : this._amIRoot() ? `this._getBlobParserCatchAllParser()` : "undefined"
  
      const scopedParserJavascript = this.myScopedParserDefinitions.map(def => def.asJavascriptClass).join("\n\n")
  
      return `createParserPool() {${scopedParserJavascript}
    return new Particle.ParserPool(${catchAllStr}, ${cuesStr}, ${regexStr})
    }`
    }
  
    private get myScopedParserDefinitions() {
      return this.getSubparticlesByParser(parserDefinitionParser)
    }
  
    private get catchAllParserToJavascript(): particlesTypes.javascriptCode {
      if (this._isBlobParser()) return "this._getBlobParserCatchAllParser()"
      const parserId = this.get(ParsersConstants.catchAllParser)
      if (!parserId) return ""
      const particleDef = this.getParserDefinitionByParserId(parserId)
      return particleDef.generatedClassName
    }
  
    get asJavascriptClass(): particlesTypes.javascriptCode {
      const components = [this.parserAsJavascript, this.errorMethodToJavascript, this.atomGettersAndParserConstants, this.customJavascriptMethods].filter(identity => identity)
      const thisClassName = this.generatedClassName
  
      if (this._amIRoot()) {
        components.push(`static _parserSourceCode = \`${Utils.escapeBackTicks(this.parent.toString().replace(/\\/g, "\\\\"))}\`
          static cachedHandParsersProgramRoot = new HandParsersProgram(this._parserSourceCode)
          get handParsersProgram() {
            return this.constructor.cachedHandParsersProgramRoot
        }`)
  
        components.push(`static rootParser = ${thisClassName}`)
      }
  
      return `class ${thisClassName} extends ${this._getExtendsClassName()} {
        ${components.join("\n")}
      }`
    }
  
    private _getExtendsClassName() {
      const extendedDef = this._getExtendedParent()
      return extendedDef ? extendedDef.generatedClassName : "ParserBackedParticle"
    }
  
    _getCompilerObject(): particlesTypes.stringMap {
      let obj: { [key: string]: string } = {}
      const items = this._getSubparticlesByParserInExtended(ParsersCompilerParser)
      items.reverse() // Last definition wins.
      items.forEach((particle: ParsersCompilerParser) => {
        obj = Object.assign(obj, particle.toObject()) // todo: what about multiline strings?
      })
      return obj
    }
  
    // todo: improve layout (use bold?)
    get lineHints() {
      return this.atomParser.lineHints
    }
  
    isOrExtendsAParserInScope(cuesInScope: string[]): boolean {
      const chain = this._getParserInheritanceSet()
      return cuesInScope.some(cue => chain.has(cue))
    }
  
    isTerminalParser() {
      return !this._getFromExtended(ParsersConstants.inScope) && !this._getFromExtended(ParsersConstants.catchAllParser)
    }
  
    private _cache_parserInheritanceSet: Set
    private _cache_ancestorParserIdsArray: particlesTypes.parserId[]
  
    _getParserInheritanceSet() {
      if (!this._cache_parserInheritanceSet) this._cache_parserInheritanceSet = new Set(this.ancestorParserIdsArray)
      return this._cache_parserInheritanceSet
    }
  
    get ancestorParserIdsArray(): particlesTypes.parserId[] {
      if (!this._cache_ancestorParserIdsArray) {
        this._cache_ancestorParserIdsArray = this._getAncestorsArray().map(def => (def).parserIdFromDefinition)
        this._cache_ancestorParserIdsArray.reverse()
      }
      return this._cache_ancestorParserIdsArray
    }
  
    _isLooping = false
    protected _cache_parserDefinitionParsers: { [parserId: string]: parserDefinitionParser }
    get programParserDefinitionCache() {
      if (!this._cache_parserDefinitionParsers) {
        if (this._isLooping) throw new Error(`Loop detected in ${this.id}`)
        this._isLooping = true
        this._cache_parserDefinitionParsers =
          this.isRoot() || this.hasParserDefinitions
            ? this.makeProgramParserDefinitionCache()
            : this.parent.programParserDefinitionCache[this.get(ParsersConstants.extends)]?.programParserDefinitionCache || this.parent.programParserDefinitionCache
        this._isLooping = false
      }
      return this._cache_parserDefinitionParsers
    }
  
    get hasParserDefinitions() {
      return !!this.getSubparticlesByParser(parserDefinitionParser).length
    }
  
    makeProgramParserDefinitionCache() {
      const scopedParsers = this.getSubparticlesByParser(parserDefinitionParser)
      const cache = Object.assign({}, this.parent.programParserDefinitionCache) // todo. We don't really need this. we should just lookup the parent if no local hits.
      scopedParsers.forEach(parserDefinitionParser => (cache[(parserDefinitionParser).parserIdFromDefinition] = parserDefinitionParser))
      return cache
    }
  
    get description(): string {
      return this._getFromExtended(ParsersConstants.description) || ""
    }
  
    get popularity() {
      const val = this._getFromExtended(ParsersConstants.popularity)
      return val ? parseFloat(val) : 0
    }
  
    private _getExtendedParserId(): particlesTypes.parserId {
      const ancestorIds = this.ancestorParserIdsArray
      if (ancestorIds.length > 1) return ancestorIds[ancestorIds.length - 2]
    }
  
    private _generateSimulatedLine(seed: number): string {
      // todo: generate simulated data from catch all
      const cue = this.cueIfAny
      return this.atomParser
        .getAtomArray()
        .map((atom, index) => (!index && cue ? cue : atom.synthesizeAtom(seed)))
        .join(" ")
    }
  
    private _shouldSynthesize(def: AbstractParserDefinitionParser, parserChain: string[]) {
      if (def._isErrorParser() || def._isAbstract()) return false
      if (parserChain.includes(def.id)) return false
      const tags = def.get(ParsersConstants.tags)
      if (tags && tags.includes(ParsersConstantsMisc.doNotSynthesize)) return false
      return true
    }
  
    // Get all definitions in this current scope down, even ones that are scoped inside other definitions.
    get inScopeAndDescendantDefinitions() {
      return this.languageDefinitionProgram._collectAllDefinitions(Object.values(this.programParserDefinitionCache), [])
    }
  
    private _collectAllDefinitions(defs: parserDefinitionParser[], collection: parserDefinitionParser[] = []) {
      defs.forEach((def: parserDefinitionParser) => {
        collection.push(def)
        def._collectAllDefinitions(def.getSubparticlesByParser(parserDefinitionParser), collection)
      })
      return collection
    }
  
    get cuePath() {
      const parentPath = this.parent.cuePath
      return (parentPath ? parentPath + " " : "") + this.cueIfAny
    }
  
    get cuePathAsColumnName() {
      return this.cuePath.replace(/ /g, "_")
    }
  
    // Get every definition that extends from this one, even ones that are scoped inside other definitions.
    get concreteDescendantDefinitions() {
      const { inScopeAndDescendantDefinitions, id } = this
      return Object.values(inScopeAndDescendantDefinitions).filter(def => def._doesExtend(id) && !def._isAbstract())
    }
  
    get concreteInScopeDescendantDefinitions() {
      // Note: non-recursive.
      const defs = this.programParserDefinitionCache
      const id = this.id
      return Object.values(defs).filter(def => def._doesExtend(id) && !def._isAbstract())
    }
  
    private _getConcreteNonErrorInScopeParticleDefinitions(parserIds: string[]) {
      const defs: AbstractParserDefinitionParser[] = []
      parserIds.forEach(parserId => {
        const def = this.getParserDefinitionByParserId(parserId)
        if (def._isErrorParser()) return
        else if (def._isAbstract()) def.concreteInScopeDescendantDefinitions.forEach(def => defs.push(def))
        else defs.push(def)
      })
      return defs
    }
  
    // todo: refactor
    synthesizeParticle(particleCount = 1, indentCount = -1, parsersAlreadySynthesized: string[] = [], seed = Date.now()) {
      let inScopeParserIds = this._getInScopeParserIds()
      const catchAllParserId = this._getFromExtended(ParsersConstants.catchAllParser)
      if (catchAllParserId) inScopeParserIds.push(catchAllParserId)
      const thisId = this.id
      if (!parsersAlreadySynthesized.includes(thisId)) parsersAlreadySynthesized.push(thisId)
      const lines = []
      while (particleCount) {
        const line = this._generateSimulatedLine(seed)
        if (line) lines.push(" ".repeat(indentCount >= 0 ? indentCount : 0) + line)
  
        this._getConcreteNonErrorInScopeParticleDefinitions(inScopeParserIds.filter(parserId => !parsersAlreadySynthesized.includes(parserId)))
          .filter(def => this._shouldSynthesize(def, parsersAlreadySynthesized))
          .forEach(def => {
            const chain = parsersAlreadySynthesized // .slice(0)
            chain.push(def.id)
            def.synthesizeParticle(1, indentCount + 1, chain, seed).forEach(line => lines.push(line))
          })
        particleCount--
      }
      return lines
    }
  
    private _atomParser: AbstractAtomParser
  
    get atomParser() {
      if (!this._atomParser) {
        const atomParsingStrategy = this._getFromExtended(ParsersConstants.atomParser)
        if (atomParsingStrategy === ParsersAtomParser.postfix) this._atomParser = new PostfixAtomParser(this)
        else if (atomParsingStrategy === ParsersAtomParser.omnifix) this._atomParser = new OmnifixAtomParser(this)
        else this._atomParser = new PrefixAtomParser(this)
      }
      return this._atomParser
    }
  }
  
  // todo: remove?
  class parserDefinitionParser extends AbstractParserDefinitionParser {}
  
  // HandParsersProgram is a constructor that takes a parsers file, and builds a new
  // constructor for new language that takes files in that language to execute, compile, etc.
  class HandParsersProgram extends AbstractParserDefinitionParser {
    createParserPool() {
      const map: particlesTypes.stringMap = {}
      map[ParsersConstants.comment] = Particle
      return new Particle.ParserPool(UnknownParserParticle, map, [
        { regex: HandParsersProgram.blankLineRegex, parser: Particle },
        { regex: HandParsersProgram.parserFullRegex, parser: parserDefinitionParser },
        { regex: HandParsersProgram.atomTypeFullRegex, parser: atomTypeDefinitionParser }
      ])
    }
  
    static makeParserId = (str: string) => Utils._replaceNonAlphaNumericCharactersWithCharCodes(str).replace(HandParsersProgram.parserSuffixRegex, "") + ParsersConstants.parserSuffix
    static makeAtomTypeId = (str: string) => Utils._replaceNonAlphaNumericCharactersWithCharCodes(str).replace(HandParsersProgram.atomTypeSuffixRegex, "") + ParsersConstants.atomTypeSuffix
  
    static parserSuffixRegex = new RegExp(ParsersConstants.parserSuffix + "$")
    static parserFullRegex = new RegExp("^[a-zA-Z0-9_]+" + ParsersConstants.parserSuffix + "$")
    static blankLineRegex = new RegExp("^$")
  
    static atomTypeSuffixRegex = new RegExp(ParsersConstants.atomTypeSuffix + "$")
    static atomTypeFullRegex = new RegExp("^[a-zA-Z0-9_]+" + ParsersConstants.atomTypeSuffix + "$")
  
    private _cache_rootParser: any
    // rootParser
    // Note: this is some so far unavoidable tricky code. We need to eval the transpiled JS, in a NodeJS or browser environment.
    _compileAndReturnRootParser(): Function {
      if (this._cache_rootParser) return this._cache_rootParser
  
      if (!this.isNodeJs()) {
        this._cache_rootParser = Utils.appendCodeAndReturnValueOnWindow(this.toBrowserJavascript(), this.rootParserId).rootParser
        return this._cache_rootParser
      }
  
      const path = require("path")
      const code = this.toNodeJsJavascript(__dirname)
      try {
        const rootParticle = this._requireInVmNodeJsRootParser(code)
        this._cache_rootParser = rootParticle.rootParser
        if (!this._cache_rootParser) throw new Error(`Failed to rootParser`)
      } catch (err) {
        // todo: figure out best error pattern here for debugging
        console.log(err)
        // console.log(`Error in code: `)
        // console.log(new Particle(code).toStringWithLineNumbers())
      }
      return this._cache_rootParser
    }
  
    get cuePath() {
      return ""
    }
  
    // todo: hacky, remove
    private _dirName: string
    _setDirName(name: string) {
      this._dirName = name
      return this
    }
  
    private _requireInVmNodeJsRootParser(code: particlesTypes.javascriptCode): any {
      const vm = require("vm")
      const path = require("path")
      // todo: cleanup up
      try {
        Object.keys(GlobalNamespaceAdditions).forEach(key => {
          ;(global)[key] = require("./" + GlobalNamespaceAdditions[key])
        })
        ;(global).require = require
        ;(global).__dirname = this._dirName
        ;(global).module = {}
        return vm.runInThisContext(code)
      } catch (err) {
        // todo: figure out best error pattern here for debugging
        console.log(`Error in compiled parsers code for language "${this.parsersName}"`)
        // console.log(new Particle(code).toStringWithLineNumbers())
        console.log(err)
        throw err
      }
    }
  
    examplesToTestBlocks(rootParser = this.compileAndReturnRootParser(), expectedErrorMessage = "") {
      const testBlocks: { [id: string]: Function } = {}
      this.validConcreteAndAbstractParserDefinitions.forEach(def =>
        def.examples.forEach(example => {
          const id = def.id + example.content
          testBlocks[id] = (equal: Function) => {
            const exampleProgram = new rootParser(example.subparticlesToString())
            const errors = exampleProgram.getAllErrors(example._getLineNumber() + 1)
            equal(errors.join("\n"), expectedErrorMessage, `Expected no errors in ${id}`)
          }
        })
      )
      return testBlocks
    }
  
    toReadMe() {
      const languageName = this.extensionName
      const rootParticleDef = this.rootParserDefinition
      const atomTypes = this.atomTypeDefinitions
      const parserLineage = this.parserLineage
      const exampleParticle = rootParticleDef.examples[0]
      return `${languageName} stats
  
  ${languageName} has ${parserLineage.topDownArray.length} parsers.
  ${languageName} has ${Object.keys(atomTypes).length} atom types.
  The source code for ${languageName} is ${this.topDownArray.length} lines long.
  
  `
    }
  
    private _cache_atomTypes: {
      [name: string]: atomTypeDefinitionParser
    }
  
    get atomTypeDefinitions() {
      if (this._cache_atomTypes) return this._cache_atomTypes
      const types: { [typeName: string]: atomTypeDefinitionParser } = {}
      // todo: add built in atom types?
      this.getSubparticlesByParser(atomTypeDefinitionParser).forEach(type => (types[(type).atomTypeId] = type))
      this._cache_atomTypes = types
      return types
    }
  
    getAtomTypeDefinitionById(atomTypeId: particlesTypes.atomTypeId) {
      // todo: return unknownAtomTypeDefinition? or is that handled somewhere else?
      return this.atomTypeDefinitions[atomTypeId]
    }
  
    get parserLineage() {
      const newParticle = new Particle()
      Object.values(this.validConcreteAndAbstractParserDefinitions).forEach(particle => newParticle.touchParticle(particle.ancestorParserIdsArray.join(" ")))
      return newParticle
    }
  
    get languageDefinitionProgram() {
      return this
    }
  
    get validConcreteAndAbstractParserDefinitions() {
      return this.getSubparticlesByParser(parserDefinitionParser).filter((particle: parserDefinitionParser) => particle._hasValidParserId())
    }
  
    private _cache_rootParserParticle: parserDefinitionParser
  
    private get lastRootParserDefinitionParticle() {
      return this.findLast(def => def instanceof AbstractParserDefinitionParser && def.has(ParsersConstants.root) && def._hasValidParserId())
    }
  
    private _initRootParserDefinitionParticle() {
      if (this._cache_rootParserParticle) return
      if (!this._cache_rootParserParticle) this._cache_rootParserParticle = this.lastRootParserDefinitionParticle
      // By default, have a very permissive basic root particle.
      // todo: whats the best design pattern to use for this sort of thing?
      if (!this._cache_rootParserParticle) {
        this._cache_rootParserParticle = this.concat(`${ParsersConstants.DefaultRootParser}
   ${ParsersConstants.root}
   ${ParsersConstants.catchAllParser} ${ParsersConstants.BlobParser}`)[0]
        this._addDefaultCatchAllBlobParser()
      }
    }
  
    get rootParserDefinition() {
      this._initRootParserDefinitionParticle()
      return this._cache_rootParserParticle
    }
  
    // todo: whats the best design pattern to use for this sort of thing?
    // todo: remove this, or at least document wtf is going on
    _addedCatchAll: any
    _addDefaultCatchAllBlobParser() {
      if (this._addedCatchAll) return
      this._addedCatchAll = true
      delete this._cache_parserDefinitionParsers
      this.concat(`${ParsersConstants.BlobParser}
   ${ParsersConstants.baseParser} ${ParsersConstants.blobParser}`)
    }
  
    get extensionName() {
      return this.parsersName
    }
  
    get id() {
      return this.rootParserId
    }
  
    get rootParserId() {
      return this.rootParserDefinition.parserIdFromDefinition
    }
  
    get parsersName(): string | undefined {
      return this.rootParserId.replace(HandParsersProgram.parserSuffixRegex, "")
    }
  
    _getMyInScopeParserIds() {
      return super._getMyInScopeParserIds(this.rootParserDefinition)
    }
  
    protected _getInScopeParserIds(): particlesTypes.parserId[] {
      const parsersParticle = this.rootParserDefinition.getParticle(ParsersConstants.inScope)
      return parsersParticle ? parsersParticle.getAtomsFrom(1) : []
    }
  
    makeProgramParserDefinitionCache() {
      const cache = {}
      this.getSubparticlesByParser(parserDefinitionParser).forEach(parserDefinitionParser => (cache[(parserDefinitionParser).parserIdFromDefinition] = parserDefinitionParser))
      return cache
    }
  
    // todo: add explanation
    private _cached_rootParser: AbstractRuntimeProgramConstructorInterface
    compileAndReturnRootParser() {
      if (!this._cached_rootParser) {
        const rootDef = this.rootParserDefinition
        this._cached_rootParser = rootDef.languageDefinitionProgram._compileAndReturnRootParser()
      }
      return this._cached_rootParser
    }
  
    toNodeJsJavascript(scrollsdkProductsPath: particlesTypes.requirePath = "scrollsdk/products"): particlesTypes.javascriptCode {
      return this._rootParticleDefToJavascriptClass(scrollsdkProductsPath, true).trim()
    }
  
    toBrowserJavascript(): particlesTypes.javascriptCode {
      return this._rootParticleDefToJavascriptClass("", false).trim()
    }
  
    private _rootParticleDefToJavascriptClass(scrollsdkProductsPath: particlesTypes.requirePath, forNodeJs = true): particlesTypes.javascriptCode {
      const defs = this.validConcreteAndAbstractParserDefinitions
      // todo: throw if there is no root particle defined
      const parserClasses = defs.map(def => def.asJavascriptClass).join("\n\n")
      const rootDef = this.rootParserDefinition
      const rootName = rootDef.generatedClassName
  
      if (!rootName) throw new Error(`Root Particle Type Has No Name`)
  
      let exportScript = ""
      if (forNodeJs)
        exportScript = `module.exports = ${rootName};
  ${rootName}`
      else exportScript = `window.${rootName} = ${rootName}`
  
      let nodeJsImports = ``
      if (forNodeJs) {
        const path = require("path")
        nodeJsImports = Object.keys(GlobalNamespaceAdditions)
          .map(key => {
            const thePath = scrollsdkProductsPath + "/" + GlobalNamespaceAdditions[key]
            return `const { ${key} } = require("${thePath.replace(/\\/g, "\\\\")}")` // escape windows backslashes
          })
          .join("\n")
      }
  
      // todo: we can expose the previous "constants" export, if needed, via the parsers, which we preserve.
      return `{
  ${nodeJsImports}
  ${parserClasses}
  
  ${exportScript}
  }
  `
    }
  }
  
  const PreludeKinds: particlesTypes.stringMap = {}
  PreludeKinds[PreludeAtomTypeIds.anyAtom] = ParsersAnyAtom
  PreludeKinds[PreludeAtomTypeIds.cueAtom] = ParsersCueAtom
  PreludeKinds[PreludeAtomTypeIds.floatAtom] = ParsersFloatAtom
  PreludeKinds[PreludeAtomTypeIds.numberAtom] = ParsersFloatAtom
  PreludeKinds[PreludeAtomTypeIds.bitAtom] = ParsersBitAtom
  PreludeKinds[PreludeAtomTypeIds.booleanAtom] = ParsersBooleanAtom
  PreludeKinds[PreludeAtomTypeIds.integerAtom] = ParsersIntegerAtom
  
  class UnknownParsersProgram extends Particle {
    private _inferRootParticleForAPrefixLanguage(parsersName: string): Particle {
      parsersName = HandParsersProgram.makeParserId(parsersName)
      const rootParticle = new Particle(`${parsersName}
   ${ParsersConstants.root}`)
  
      // note: right now we assume 1 global atomTypeMap and parserMap per parsers. But we may have scopes in the future?
      const rootParticleNames = this.getCues()
        .filter(identity => identity)
        .map(atom => HandParsersProgram.makeParserId(atom))
      rootParticle
        .particleAt(0)
        .touchParticle(ParsersConstants.inScope)
        .setAtomsFrom(1, Array.from(new Set(rootParticleNames)))
  
      return rootParticle
    }
  
    private static _subparticleSuffix = "Subparticle"
  
    private _renameIntegerCues(clone: UnknownParsersProgram) {
      // todo: why are we doing this?
      for (let particle of clone.getTopDownArrayIterator()) {
        const cueIsAnInteger = !!particle.cue.match(/^\d+$/)
        const parentCue = particle.parent.cue
        if (cueIsAnInteger && parentCue) particle.setCue(HandParsersProgram.makeParserId(parentCue + UnknownParsersProgram._subparticleSuffix))
      }
    }
  
    private _getCueMaps(clone: UnknownParsersProgram) {
      const cuesToChildCues: { [cue: string]: particlesTypes.stringMap } = {}
      const cuesToParticleInstances: { [cue: string]: Particle[] } = {}
      for (let particle of clone.getTopDownArrayIterator()) {
        const cue = particle.cue
        if (!cuesToChildCues[cue]) cuesToChildCues[cue] = {}
        if (!cuesToParticleInstances[cue]) cuesToParticleInstances[cue] = []
        cuesToParticleInstances[cue].push(particle)
        particle.forEach((subparticle: Particle) => (cuesToChildCues[cue][subparticle.cue] = true))
      }
      return { cuesToChildCues, cuesToParticleInstances }
    }
  
    private _inferParserDef(cue: string, globalAtomTypeMap: Map, subparticleCues: string[], instances: Particle[]) {
      const edgeSymbol = this.edgeSymbol
      const parserId = HandParsersProgram.makeParserId(cue)
      const particleDefParticle = new Particle(parserId).particleAt(0)
      const subparticleParserIds = subparticleCues.map(atom => HandParsersProgram.makeParserId(atom))
      if (subparticleParserIds.length) particleDefParticle.touchParticle(ParsersConstants.inScope).setAtomsFrom(1, subparticleParserIds)
  
      const atomsForAllInstances = instances
        .map(line => line.content)
        .filter(identity => identity)
        .map(line => line.split(edgeSymbol))
      const instanceAtomCounts = new Set(atomsForAllInstances.map(atoms => atoms.length))
      const maxAtomsOnLine = Math.max(...Array.from(instanceAtomCounts))
      const minAtomsOnLine = Math.min(...Array.from(instanceAtomCounts))
      let catchAllAtomType: string
      let atomTypeIds = []
      for (let atomIndex = 0; atomIndex  atoms[atomIndex])
        )
        if (!globalAtomTypeMap.has(atomType.atomTypeId)) globalAtomTypeMap.set(atomType.atomTypeId, atomType.atomTypeDefinition)
  
        atomTypeIds.push(atomType.atomTypeId)
      }
      if (maxAtomsOnLine > minAtomsOnLine) {
        //columns = columns.slice(0, min)
        catchAllAtomType = atomTypeIds.pop()
        while (atomTypeIds[atomTypeIds.length - 1] === catchAllAtomType) {
          atomTypeIds.pop()
        }
      }
  
      const needsCueProperty = !cue.endsWith(UnknownParsersProgram._subparticleSuffix + ParsersConstants.parserSuffix) // todo: cleanup
      if (needsCueProperty) particleDefParticle.set(ParsersConstants.cue, cue)
  
      if (catchAllAtomType) particleDefParticle.set(ParsersConstants.catchAllAtomType, catchAllAtomType)
  
      const atomLine = atomTypeIds.slice()
      atomLine.unshift(PreludeAtomTypeIds.cueAtom)
      if (atomLine.length > 0) particleDefParticle.set(ParsersConstants.atoms, atomLine.join(edgeSymbol))
  
      //if (!catchAllAtomType && atomTypeIds.length === 1) particleDefParticle.set(ParsersConstants.atoms, atomTypeIds[0])
  
      // Todo: add conditional frequencies
      return particleDefParticle.parent.toString()
    }
  
    inferParsersFileForACueLanguage(parsersName: string): string {
      const clone = this.clone()
      this._renameIntegerCues(clone)
  
      const { cuesToChildCues, cuesToParticleInstances } = this._getCueMaps(clone)
  
      const globalAtomTypeMap = new Map()
      globalAtomTypeMap.set(PreludeAtomTypeIds.cueAtom, undefined)
      const parserDefs = Object.keys(cuesToChildCues)
        .filter(identity => identity)
        .map(cue => this._inferParserDef(cue, globalAtomTypeMap, Object.keys(cuesToChildCues[cue]), cuesToParticleInstances[cue]))
  
      const atomTypeDefs: string[] = []
      globalAtomTypeMap.forEach((def, id) => atomTypeDefs.push(def ? def : id))
      const particleBreakSymbol = this.particleBreakSymbol
  
      return this._formatCode([this._inferRootParticleForAPrefixLanguage(parsersName).toString(), atomTypeDefs.join(particleBreakSymbol), parserDefs.join(particleBreakSymbol)].filter(identity => identity).join("\n"))
    }
  
    private _formatCode(code: string) {
      // todo: make this run in browser too
      if (!this.isNodeJs()) return code
  
      const parsersProgram = new HandParsersProgram(Particle.fromDisk(__dirname + "/../langs/parsers/parsers.parsers"))
      const rootParser = parsersProgram.compileAndReturnRootParser()
      const program = new rootParser(code)
      return program.format().toString()
    }
  
    private _getBestAtomType(cue: string, instanceCount: particlesTypes.int, maxAtomsOnLine: particlesTypes.int, allValues: any[]): { atomTypeId: string; atomTypeDefinition?: string } {
      const asSet = new Set(allValues)
      const edgeSymbol = this.edgeSymbol
      const values = Array.from(asSet).filter(identity => identity)
      const every = (fn: Function) => {
        for (let index = 0; index  str === "0" || str === "1")) return { atomTypeId: PreludeAtomTypeIds.bitAtom }
  
      if (
        every((str: string) => {
          const num = parseInt(str)
          if (isNaN(num)) return false
          return num.toString() === str
        })
      ) {
        return { atomTypeId: PreludeAtomTypeIds.integerAtom }
      }
  
      if (every((str: string) => str.match(/^-?\d*.?\d+$/))) return { atomTypeId: PreludeAtomTypeIds.floatAtom }
  
      const bools = new Set(["1", "0", "true", "false", "t", "f", "yes", "no"])
      if (every((str: string) => bools.has(str.toLowerCase()))) return { atomTypeId: PreludeAtomTypeIds.booleanAtom }
  
      // todo: cleanup
      const enumLimit = 30
      if (instanceCount > 1 && maxAtomsOnLine === 1 && allValues.length > asSet.size && asSet.size  {
    const code = `testParser
   root`
  
    const mock = new MockCodeMirror(
      () =>
        new ParsersCodeMirrorMode(
          "parsersParser",
          () => ParsersProgram,
          () => code
        )
    )
    const tokenLines = mock.getTokenLines(code)
    equal(tokenLines.join(" "), `def bracket atom`)
  }
  
  testParticles.iris = equal => {
    const irisParser = new HandParsersProgram(irisParsers).compileAndReturnRootParser()
    const goodCode = `6.1 3 4.9 2 virginica`
    const codeWithMissingAtom = `6.1 3 4.9  virginica`
    // Act
    const tokenLines = new MockCodeMirror(
      () =>
        new ParsersCodeMirrorMode(
          "irisParser",
          () => irisParser,
          () => goodCode
        )
    ).getTokenLines(goodCode)
    // Assert
    equal(tokenLines.join(" "), `number bracket number bracket number bracket number bracket atom`)
  
    // Act
    const tokenLines2 = new MockCodeMirror(
      () =>
        new ParsersCodeMirrorMode(
          "irisParser",
          () => irisParser,
          () => codeWithMissingAtom
        )
    ).getTokenLines(codeWithMissingAtom)
    // Assert
    equal(tokenLines2.join(" "), `number bracket number bracket number bracket bracket atom`)
  }
  
  testParticles.codeMirrorTest2 = equal => {
    const code = `testParser
   root
  foobarParser`
  
    const mock = new MockCodeMirror(
      () =>
        new ParsersCodeMirrorMode(
          "parsersParser",
          () => ParsersProgram,
          () => code
        )
    )
    const tokenLines = mock.getTokenLines(code)
    equal(tokenLines.length, 3)
    equal(tokenLines.join(" "), `def bracket atom def`)
  }
  
  testParticles.regressionTest = equal => {
    const code = Disk.read(__dirname + "/ParsersCodeMirrorMode.regression.stamp")
  
    const mock = new MockCodeMirror(
      () =>
        new ParsersCodeMirrorMode(
          "stampParser",
          () => stamp,
          () => code
        )
    )
    const tokenLines = mock.getTokenLines(code)
    equal(tokenLines.length, 217)
  }
  
  testParticles.regression2 = equal => {
    const code = `object
   prettier
    object`
  
    const mock = new MockCodeMirror(
      () =>
        new ParsersCodeMirrorMode(
          "dugParser",
          () => DugProgram,
          () => code
        )
    )
    const tokenLines = mock.getTokenLines(code)
    equal(tokenLines.length, 3)
    equal(tokenLines.join(" "), `keyword bracket string bracket bracket keyword`)
  }
  
  /*NODE_JS_ONLY*/ if (!module.parent) TestRacer.testSingleFile(__filename, testParticles)
  
  export { testParticles }
  
 ParsersCodeMirrorMode.ts
  import { particlesTypes } from "../products/particlesTypes"
  
  /* Used for Types Only, but we want this line to remain in the combined intermediate TS program */ import * as CodeMirrorLib from "codemirror"
  
  // Adapted from https://github.com/NeekSandhu/codemirror-textmate/blob/master/src/tmToCm.ts
  enum CmToken {
    Atom = "atom",
    Attribute = "attribute",
    Bracket = "bracket",
    Builtin = "builtin",
    Comment = "comment",
    Def = "def",
    Error = "error",
    Header = "header",
    HR = "hr",
    Keyword = "keyword",
    Link = "link",
    Meta = "meta",
    Number = "number",
    Operator = "operator",
    Property = "property",
    Qualifier = "qualifier",
    Quote = "quote",
    String = "string",
    String2 = "string-2",
    Tag = "tag",
    Type = "type",
    Variable = "variable",
    Variable2 = "variable-2",
    Variable3 = "variable-3"
  }
  
  const tmToCm = {
    comment: {
      $: CmToken.Comment
    },
  
    constant: {
      // TODO: Revision
      $: CmToken.Def,
      character: {
        escape: {
          $: CmToken.String2
        }
      },
      language: {
        $: CmToken.Atom
      },
      numeric: {
        $: CmToken.Number
      },
      other: {
        email: {
          link: {
            $: CmToken.Link
          }
        },
        symbol: {
          // TODO: Revision
          $: CmToken.Def
        }
      }
    },
  
    entity: {
      name: {
        class: {
          $: CmToken.Def
        },
        function: {
          $: CmToken.Def
        },
        tag: {
          $: CmToken.Tag
        },
        type: {
          $: CmToken.Type,
          class: {
            $: CmToken.Variable
          }
        }
      },
      other: {
        "attribute-name": {
          $: CmToken.Attribute
        },
        "inherited-class": {
          // TODO: Revision
          $: CmToken.Def
        }
      },
      support: {
        function: {
          // TODO: Revision
          $: CmToken.Def
        }
      }
    },
  
    invalid: {
      $: CmToken.Error,
      illegal: { $: CmToken.Error },
      deprecated: {
        $: CmToken.Error
      }
    },
  
    keyword: {
      $: CmToken.Keyword,
      operator: {
        $: CmToken.Operator
      },
      other: {
        "special-method": CmToken.Def
      }
    },
    punctuation: {
      $: CmToken.Operator,
      definition: {
        comment: {
          $: CmToken.Comment
        },
        tag: {
          $: CmToken.Bracket
        }
        // 'template-expression': {
        //     $: CodeMirrorToken.Operator,
        // },
      }
      // terminator: {
      //     $: CodeMirrorToken.Operator,
      // },
    },
  
    storage: {
      $: CmToken.Keyword
    },
  
    string: {
      $: CmToken.String,
      regexp: {
        $: CmToken.String2
      }
    },
  
    support: {
      class: {
        $: CmToken.Def
      },
      constant: {
        $: CmToken.Variable2
      },
      function: {
        $: CmToken.Def
      },
      type: {
        $: CmToken.Type
      },
      variable: {
        $: CmToken.Variable2,
        property: {
          $: CmToken.Property
        }
      }
    },
  
    variable: {
      $: CmToken.Def,
      language: {
        // TODO: Revision
        $: CmToken.Variable3
      },
      other: {
        object: {
          $: CmToken.Variable,
          property: {
            $: CmToken.Property
          }
        },
        property: {
          $: CmToken.Property
        }
      },
      parameter: {
        $: CmToken.Def
      }
    }
  }
  
  const textMateScopeToCodeMirrorStyle = (scopeSegments: string[], style: particlesTypes.stringMap = tmToCm): CmToken => {
    const matchingBranch = style[scopeSegments.shift()]
    return matchingBranch ? textMateScopeToCodeMirrorStyle(scopeSegments, matchingBranch) || matchingBranch.$ || null : null
  }
  
  interface particleCodeMirrorState {
    atomIndex: number
  }
  
  class ParsersCodeMirrorMode {
    constructor(name: string, getRootParserFn: () => particlesTypes.ParticleProgramParser, getProgramCodeFn: (instance: CodeMirrorLib.EditorFromTextArea) => string, codeMirrorLib: typeof CodeMirrorLib = undefined) {
      this._name = name
      this._getRootParserFn = getRootParserFn
      this._getProgramCodeFn = getProgramCodeFn || (instance => (instance ? instance.getValue() : this._originalValue))
      this._codeMirrorLib = codeMirrorLib
    }
  
    private _name: string
    private _getProgramCodeFn: (cmInstance: CodeMirrorLib.EditorFromTextArea) => string
    private _getRootParserFn: () => particlesTypes.ParticleProgramParser
    private _codeMirrorLib: typeof CodeMirrorLib
    private _cachedSource: string
    private _cachedProgram: particlesTypes.particleProgram
    private _cmInstance: CodeMirrorLib.EditorFromTextArea
    private _originalValue: string
  
    _getParsedProgram() {
      const source = this._getProgramCodeFn(this._cmInstance) || ""
      if (!this._cachedProgram || this._cachedSource !== source) {
        this._cachedSource = source
        this._cachedProgram = new (this._getRootParserFn())(source)
      }
      return this._cachedProgram
    }
  
    private _getExcludedIntelliSenseTriggerKeys(): particlesTypes.stringMap {
      return {
        "8": "backspace",
        "9": "tab",
        "13": "enter",
        "16": "shift",
        "17": "ctrl",
        "18": "alt",
        "19": "pause",
        "20": "capslock",
        "27": "escape",
        "33": "pageup",
        "34": "pagedown",
        "35": "end",
        "36": "home",
        "37": "left",
        "38": "up",
        "39": "right",
        "40": "down",
        "45": "insert",
        "46": "delete",
        "91": "left window key",
        "92": "right window key",
        "93": "select",
        "112": "f1",
        "113": "f2",
        "114": "f3",
        "115": "f4",
        "116": "f5",
        "117": "f6",
        "118": "f7",
        "119": "f8",
        "120": "f9",
        "121": "f10",
        "122": "f11",
        "123": "f12",
        "144": "numlock",
        "145": "scrolllock"
      }
    }
  
    token(stream: CodeMirrorLib.StringStream, state: particleCodeMirrorState) {
      return this._advanceStreamAndReturnTokenType(stream, state)
    }
  
    fromTextAreaWithAutocomplete(area: HTMLTextAreaElement, options: any) {
      this._originalValue = area.value
      const defaultOptions = {
        lineNumbers: true,
        mode: this._name,
        tabSize: 1,
        indentUnit: 1,
        hintOptions: {
          hint: (cmInstance: CodeMirrorLib.EditorFromTextArea, options: any) => this.codeMirrorAutocomplete(cmInstance, options)
        }
      }
  
      Object.assign(defaultOptions, options)
  
      this._cmInstance = this._getCodeMirrorLib().fromTextArea(area, defaultOptions)
      this._enableAutoComplete(this._cmInstance)
      return this._cmInstance
    }
  
    _enableAutoComplete(cmInstance: CodeMirrorLib.EditorFromTextArea) {
      const excludedKeys = this._getExcludedIntelliSenseTriggerKeys()
      const codeMirrorLib = this._getCodeMirrorLib()
      cmInstance.on("keyup", (cm: CodeMirrorLib.EditorFromTextArea, event: KeyboardEvent) => {
        // https://stackoverflow.com/questions/13744176/codemirror-autocomplete-after-any-keyup
        if (!cm.state.completionActive && !excludedKeys[event.keyCode.toString()])
          // Todo: get typings for CM autocomplete
          (codeMirrorLib.commands).autocomplete(cm, null, { completeSingle: false })
      })
    }
  
    _getCodeMirrorLib() {
      return this._codeMirrorLib
    }
  
    async codeMirrorAutocomplete(cmInstance: CodeMirrorLib.EditorFromTextArea, options: any) {
      const cursor = cmInstance.getDoc().getCursor()
      const codeMirrorLib = this._getCodeMirrorLib()
      const result = await this._getParsedProgram().getAutocompleteResultsAt(cursor.line, cursor.ch)
  
      // It seems to be better UX if there's only 1 result, and its the atom the user entered, to close autocomplete
      if (result.matches.length === 1 && result.matches[0].text === result.atom) return null
  
      return result.matches.length
        ? {
            list: result.matches,
            from: codeMirrorLib.Pos(cursor.line, result.startCharIndex),
            to: codeMirrorLib.Pos(cursor.line, result.endCharIndex)
          }
        : null
    }
  
    register() {
      const codeMirrorLib = this._getCodeMirrorLib()
      codeMirrorLib.defineMode(this._name, () => this)
      codeMirrorLib.defineMIME("text/" + this._name, this._name)
      return this
    }
  
    private _advanceStreamAndReturnTokenType(stream: CodeMirrorLib.StringStream, state: particleCodeMirrorState): string {
      let nextCharacter = stream.next()
      const lineNumber = (stream).lineOracle.line + 1 // state.lineIndex
      const AtomBreakSymbol = " "
      const ParticleBreakSymbol = "\n"
      while (typeof nextCharacter === "string") {
        const peek = stream.peek()
  
        if (nextCharacter === AtomBreakSymbol) {
          if (peek === undefined || peek === ParticleBreakSymbol) {
            stream.skipToEnd() // advance string to end
            this._incrementLine(state)
          }
          if (peek === AtomBreakSymbol && state.atomIndex) {
            // If we are missing a atom.
            // TODO: this is broken for a blank 1st atom. We need to track AtomBreakSymbol level.
            state.atomIndex++
          }
          return "bracket"
        }
        if (peek === AtomBreakSymbol) {
          state.atomIndex++
          return this._getAtomStyle(lineNumber, state.atomIndex)
        }
        nextCharacter = stream.next()
      }
  
      state.atomIndex++
      const style = this._getAtomStyle(lineNumber, state.atomIndex)
  
      this._incrementLine(state)
      return style
    }
  
    private _getAtomStyle(lineIndex: particlesTypes.int, atomIndex: particlesTypes.int): string {
      try {
        const program = this._getParsedProgram()
  
        // todo: if the current atom is an error, don't show red?
        if (!program.getAtomPaintAtPosition) console.log(program)
        const paint = program.getAtomPaintAtPosition(lineIndex, atomIndex)
        const style = paint ? textMateScopeToCodeMirrorStyle(paint.split(".")) : undefined
  
        return style || "noPaintDefinedInParsers"
      } catch (err) {
        console.error(err)
        return "noPaintDefinedInParsers"
      }
    }
  
    // todo: remove.
    startState(): particleCodeMirrorState {
      return {
        atomIndex: 0
      }
    }
  
    _incrementLine(state: particleCodeMirrorState) {
      state.atomIndex = 0
    }
  }
  
  export { ParsersCodeMirrorMode }
  
 ParsersCompiler.test.ts
  #!/usr/bin/env ts-node
  
  import { particlesTypes } from "../products/particlesTypes"
  
  const { Particle } = require("../products/Particle.js")
  const { Disk } = require("../products/Disk.node.js")
  const { Utils } = require("../products/Utils.js")
  const { TestRacer } = require("../products/TestRacer.js")
  const { ParsersCompiler } = require("../products/ParsersCompiler.js")
  
  const testParticles: particlesTypes.testParticles = {}
  
  testParticles.compileParsersAndCreateProgram = equal => {
    // Arrange
    const jibberishRootDir = __dirname + "/../langs/jibberish/"
    const programPath = jibberishRootDir + "sample.jibberish"
    const parsersPath = jibberishRootDir + "jibberish.parsers"
  
    // Act
    const program = ParsersCompiler.compileParsersAndCreateProgram(programPath, parsersPath)
    const result = program.execute()
  
    // Assert
    equal(program.constructor.name, "jibberishParser", "parent program class parsed correctly")
    equal(result, 42)
  }
  
  testParticles.combineTests = equal => {
    // Arrange
    const combined = ParsersCompiler.combineFiles([__dirname + "/*.swarm"])
  
    // Act/Assert
    equal(combined.toString().includes("constructWithParagraph"), true, "Included something from a swarm file")
  }
  
  testParticles.diskTests = equal => {
    // Arrange
    const path = __dirname + `/temp-disk.csv`
  
    // Assert
    equal(Disk.exists(path), false, "file does not exist")
  
    // Arrange
    const particle = Particle.fromCsv(Particle.iris)
    particle.toDisk(path)
  
    // Act/Assert
    equal(Disk.exists(path), true, "file exists")
    equal(Particle.fromDisk(path).toString(), particle.toString(), "particle unchanged")
  
    // Cleanup
    Disk.rm(path)
  
    // Assert
    equal(Disk.exists(path), false, "file does not exist")
  }
  
  testParticles.findProjectRoot = equal => {
    const dir = Utils.findProjectRoot(__dirname, "scrollsdk")
    equal(typeof dir, "string")
    equal(dir.includes("parsers"), false, "correct parent dir selected")
  
    try {
      const result = Utils.findProjectRoot("/foo/bar/", "scrollsdk")
      equal(result, false, "error should have been thrown")
    } catch (err) {
      equal(true, true, "error thrown")
    }
  
    try {
      Utils.findProjectRoot(__dirname + "/../", "fakeproject")
      equal(true, false, "error should have been thrown")
    } catch (err) {
      equal(true, true, "error thrown")
    }
  }
  
  /*NODE_JS_ONLY*/ if (!module.parent) TestRacer.testSingleFile(__filename, testParticles)
  
  export { testParticles }
  
 ParsersCompiler.ts
  const fs = require("fs")
  const path = require("path")
  
  const { Utils } = require("../products/Utils.js")
  const { Particle } = require("../products/Particle.js")
  const { HandParsersProgram } = require("./Parsers.js")
  import { particlesTypes } from "../products/particlesTypes"
  
  enum CompileTarget {
    nodejs = "nodejs",
    browser = "browser"
  }
  
  class ParsersCompiler {
    static compileParsersAndCreateProgram = (programPath: particlesTypes.filepath, parsersPath: particlesTypes.filepath) => {
      // tod: remove?
      const rootParser = this.compileParsersFileAtPathAndReturnRootParser(parsersPath)
      return new rootParser(fs.readFileSync(programPath, "utf8"))
    }
  
    static compileParsersForNodeJs(pathToParsers: particlesTypes.absoluteFilePath, outputFolder: particlesTypes.absoluteFolderPath, usePrettier = true, scrollsdkProductsPath = __dirname) {
      return this._compileParsers(pathToParsers, outputFolder, CompileTarget.nodejs, usePrettier, scrollsdkProductsPath)
    }
  
    static formatCode = (programCode: string, parsersPath: particlesTypes.filepath) => {
      // tod: remove?
      const rootParser = this.compileParsersFileAtPathAndReturnRootParser(parsersPath)
      const program = new rootParser(programCode)
      return program.format().toString()
    }
  
    static formatFileInPlace = (programPath: particlesTypes.filepath, parsersPath: particlesTypes.filepath) => {
      // tod: remove?
      const original = Particle.fromDisk(programPath)
      const formatted = this.formatCode(original.toString(), parsersPath)
      if (original === formatted) return false
      new Particle(formatted).toDisk(programPath)
      return true
    }
  
    private static _compileParsers(pathToParsers: particlesTypes.absoluteFilePath, outputFolder: particlesTypes.absoluteFolderPath, target: CompileTarget, usePrettier: boolean, scrollsdkProductsPath?: particlesTypes.requirePath) {
      const isNodeJs = CompileTarget.nodejs === target
      const parsersCode = Particle.fromDisk(pathToParsers)
      const program = new HandParsersProgram(parsersCode.toString())
      const outputFilePath = path.join(outputFolder, `${program.parsersName}.${target}.js`)
  
      let result = isNodeJs ? program.toNodeJsJavascript(scrollsdkProductsPath) : program.toBrowserJavascript()
  
      if (isNodeJs)
        result =
          "#! /usr/bin/env node\n" +
          result.replace(
            /}\s*$/,
            `
  if (!module.parent) new ${program.rootParserId}(Particle.fromDisk(process.argv[2]).toString()).execute()
  }
  `
          )
  
      if (usePrettier) result = require("prettier").format(result, require("../package.json").prettier)
  
      fs.writeFileSync(outputFilePath, result, "utf8")
  
      if (isNodeJs) fs.chmodSync(outputFilePath, 0o755)
      return outputFilePath
    }
  
    static compileParsersForBrowser(pathToParsers: particlesTypes.absoluteFilePath, outputFolder: particlesTypes.absoluteFolderPath, usePrettier = true) {
      return this._compileParsers(pathToParsers, outputFolder, CompileTarget.browser, usePrettier)
    }
  
    static compileParsersFileAtPathAndReturnRootParser = (parsersPath: particlesTypes.filepath) => {
      // todo: remove
      if (!fs.existsSync(parsersPath)) throw new Error(`Parsers file does not exist: ${parsersPath}`)
      const parsersCode = fs.readFileSync(parsersPath, "utf8")
      const parsersProgram = new HandParsersProgram(parsersCode)
      return parsersProgram.compileAndReturnRootParser()
    }
  
    static combineFiles = (globPatterns: particlesTypes.globPattern[]) => {
      const glob = require("glob")
      const files = Utils.flatten(globPatterns.map(pattern => glob.sync(pattern)))
      const content = files.map((path: particlesTypes.filepath) => fs.readFileSync(path, "utf8")).join("\n")
  
      return new Particle(content)
    }
  }
  
  export { ParsersCompiler }
  
 UnknownParsers.expected.parsers
  cueAtom
  anyAtom
  integerAtom
  booleanAtom
  floatAtom
  foobarParser
   root
   inScope fileParser
  fileParser
   inScope sizeParser digitsParser openParser tempParser descriptionParser editsParser accountParser
   cue file
   atoms cueAtom anyAtom
  sizeParser
   cue size
   atoms cueAtom integerAtom
  digitsParser
   cue digits
   atoms cueAtom integerAtom integerAtom
  openParser
   cue open
   atoms cueAtom booleanAtom
  tempParser
   cue temp
   atoms cueAtom floatAtom
  descriptionParser
   cue description
   catchAllAtomType anyAtom
   atoms cueAtom
  editsParser
   inScope editsSubparticleParser
   cue edits
   atoms cueAtom
  editsSubparticleParser
   inScope dataParser
   atoms cueAtom
  dataParser
   cue data
   atoms cueAtom anyAtom
  accountParser
   inScope balanceParser transactionsParser sourceParser
   cue account
   atoms cueAtom
  balanceParser
   cue balance
   atoms cueAtom floatAtom
  transactionsParser
   cue transactions
   atoms cueAtom integerAtom
  sourceParser
   cue source
   atoms cueAtom booleanAtom anyAtom integerAtom
 UnknownParsers.expectedEmoji.parsers
  cueAtom
  emojiLangParser
   root
   inScope _9000_55357_56696_55356_57104Parser
  _9000_55357_56696_55356_57104Parser
   inScope _55357_56520Parser _55357_56521Parser
   cue ⌨🕸🌐
   atoms cueAtom
  _55357_56520Parser
   inScope _55356_57318_55357_56846Parser
   cue 📈
   atoms cueAtom
  _55356_57318_55357_56846Parser
   cue 🏦😎
   atoms cueAtom
  _55357_56521Parser
   inScope _55357_56489Parser
   cue 📉
   atoms cueAtom
  _55357_56489Parser
   cue 💩
   atoms cueAtom
 UnknownParsers.sample.scroll
  file rain
   size 28
   digits 321 4324
   open true
   temp 32.1
   description Lorem ipsum, unless ipsum lorem.
   edits
    0
     data Test
    1
     data Test2
   account
    balance 24
    transactions 32
    source no http://www.foo.foo 32
  file test
   digits 321 435
   size 3
   description None.
   open false
   temp 32.0
   account
    balance 32.12
    transactions 321
    source yes http://to.to.to 31
 parsers.swarm
  #! /usr/bin/env node /usr/local/bin/scrollsdk
  test parsersSample
   arrange
    require ../products/Parsers.js HandParsersProgram
    constructWithParagraph
     testlangParser
      root
      inScope baseParser
     anyAtom
     atomAtom
      extends anyAtom
     baseParser
      cue base
     cueAtom
     blockParser
      cue block
      extends baseParser
      inScope baseParser
     toParser
      cue to
      extends blockParser
      atoms cueAtom atomAtom
      tags test
      compiler
       stringTemplate to {atomAtom}
       closeSubparticles end
   runTimeCuesInScope
    assertLengthIs 1
   getParserDefinitionByParserId toParser
    assertTypeIs object
   topParserDefinitions
    assertLengthIs 3
   extensionName
    assertStringIs testlang
   isDefined notDefined
    assertStringIs false
   isDefined toParser
    assertStringIs true
   getAllErrors
    assertLengthIs 0
 readme.scroll
  title Parsers TypeScript Implementation
  
  This folder contains Parsers implemented in TypeScript.
  
  See the folder `langs/parsers/` for documentation on Parsers.

stamp
 ScrollFileSystem.test.ts
  #!/usr/bin/env ts-node
  const { Particle } = require("../products/Particle.js")
  const { ScrollFileSystem, ScrollFile } = require("../products/ScrollFileSystem.js")
  const { TestRacer } = require("../products/TestRacer.js")
  const path = require("path")
  import { particlesTypes } from "../products/particlesTypes"
  
  const testParticles: particlesTypes.testParticles = {}
  
  testParticles.disk = async equal => {
    const sfs = new ScrollFileSystem()
    // Arrange/Act/Assert
    const file = await sfs.getFusedFile(path.join(__dirname, "..", "readme.scroll"))
    equal(file.scrollProgram.toString().length > 0, true)
  }
  
  /*NODE_JS_ONLY*/ if (!module.parent) {
    // Update TestRacer to handle async tests
    const runTests = async () => {
      await TestRacer.testSingleFile(__filename, testParticles)
    }
    runTests()
  }
  
  export { testParticles }
  
 ScrollFileSystem.ts
  // todo: as much as we can, remove ScrollFileSystem and move these capabilities into the root Particle class.
  const fsp = require("fs").promises
  const path = require("path")
  
  import { particlesTypes } from "../products/particlesTypes"
  const { Disk } = require("../products/Disk.node.js")
  const { Utils } = require("../products/Utils.js")
  const { Particle } = require("../products/Particle.js")
  const { HandParsersProgram } = require("../products/Parsers.js")
  const parsersParser = require("../products/parsers.nodejs.js")
  
  const PARSERS_EXTENSION = ".parsers"
  const SCROLL_EXTENSION = ".scroll"
  
  interface OpenedFile {
    absolutePath: particlesTypes.filepath
    content: string
    exists: boolean
    stats: any // https://nodejs.org/api/fs.html#class-fsstats
  }
  
  interface Storage {
    read(absolutePath: string): Promise
    exists(absolutePath: string): Promise
    list(absolutePath: string): Promise
    write(absolutePath: string, content: string): Promise
    getMTime(absolutePath: string): Promise
    getCTime(absolutePath: string): Promise
    dirname(absolutePath: string): string
    join(...absolutePath: string[]): string
  }
  
  // Add URL regex pattern
  const urlRegex = /^https?:\/\/[^ ]+$/i
  
  const isUrl = (path: string) => urlRegex.test(path)
  
  // URL content cache with pending requests tracking
  const urlCache: { [url: string]: { content: string; timestamp: number; exists: boolean } } = {}
  const pendingRequests: { [url: string]: Promise } = {}
  
  async function fetchWithCache(url: string) {
    const now = Date.now()
    const cached = urlCache[url]
  
    if (cached) return cached
  
    // If there's already a pending request for this URL, return that promise
    if (pendingRequests[url]) {
      return pendingRequests[url]
    }
  
    // Create new request and store in pending
    const requestPromise = (async () => {
      try {
        const response = await fetch(url)
        if (!response.ok) throw new Error(`HTTP error! status: ${response.status}`)
        const content = await response.text()
  
        const result = {
          content,
          timestamp: now,
          exists: true
        }
  
        urlCache[url] = result
        return result
      } catch (error) {
        console.error(`Error fetching ${url}:`, error)
        const result = {
          content: "",
          timestamp: now,
          exists: false
        }
        urlCache[url] = result
        return result
      } finally {
        delete pendingRequests[url]
      }
    })()
  
    pendingRequests[url] = requestPromise
    return requestPromise
  }
  
  class DiskWriter implements Storage {
    fileCache: { [filepath: string]: OpenedFile } = {}
  
    async _read(absolutePath: particlesTypes.filepath) {
      if (isUrl(absolutePath)) {
        const result = await fetchWithCache(absolutePath)
        return {
          absolutePath,
          exists: result.exists,
          content: result.content,
          stats: { mtimeMs: Date.now(), ctimeMs: Date.now() }
        }
      }
  
      const { fileCache } = this
      if (fileCache[absolutePath]) return fileCache[absolutePath]
      try {
        const stats = await fsp.stat(absolutePath)
        const content = await fsp.readFile(absolutePath, {
          encoding: "utf8",
          flag: "r" // explicit read flag
        })
        const normalizedContent = content.includes("\r") ? content.replace(/\r/g, "") : content
        fileCache[absolutePath] = {
          absolutePath,
          exists: true,
          content: normalizedContent,
          stats
        }
      } catch (error) {
        fileCache[absolutePath] = {
          absolutePath,
          exists: false,
          content: "",
          stats: { mtimeMs: 0, ctimeMs: 0 }
        }
      }
      return fileCache[absolutePath]
    }
  
    async exists(absolutePath: string) {
      if (isUrl(absolutePath)) {
        const result = await fetchWithCache(absolutePath)
        return result.exists
      }
      const file = await this._read(absolutePath)
      return file.exists
    }
  
    async read(absolutePath: string) {
      const file = await this._read(absolutePath)
      return file.content
    }
  
    async createReadStream(absolutePath: string) {
      const fd = await fsp.open(absolutePath)
      return fd.createReadStream({
        encoding: "utf8"
      })
    }
  
    async list(folder: string) {
      if (isUrl(folder)) {
        return [] // URLs don't support directory listing
      }
      return Disk.getFiles(folder)
    }
  
    async write(fullPath: string, content: string) {
      if (isUrl(fullPath)) {
        throw new Error("Cannot write to URL")
      }
      Disk.writeIfChanged(fullPath, content)
    }
  
    async getMTime(absolutePath: string) {
      if (isUrl(absolutePath)) {
        const cached = urlCache[absolutePath]
        return cached ? cached.timestamp : Date.now()
      }
      const file = await this._read(absolutePath)
      return file.stats.mtimeMs
    }
  
    async getCTime(absolutePath: string) {
      if (isUrl(absolutePath)) {
        const cached = urlCache[absolutePath]
        return cached ? cached.timestamp : Date.now()
      }
      const file = await this._read(absolutePath)
      return file.stats.ctimeMs
    }
  
    dirname(absolutePath: string) {
      if (isUrl(absolutePath)) {
        return absolutePath.substring(0, absolutePath.lastIndexOf("/"))
      }
      return path.dirname(absolutePath)
    }
  
    join(...segments: string[]) {
      const firstSegment = segments[0]
      if (isUrl(firstSegment)) {
        // For URLs, we need to handle joining differently
        const baseUrl = firstSegment.endsWith("/") ? firstSegment : firstSegment + "/"
        return new URL(segments.slice(1).join("/"), baseUrl).toString()
      }
      return path.join(...segments)
    }
  }
  
  // Update MemoryWriter to support URLs
  class MemoryWriter implements Storage {
    constructor(inMemoryFiles: particlesTypes.diskMap) {
      this.inMemoryFiles = inMemoryFiles
    }
  
    inMemoryFiles: particlesTypes.diskMap
  
    async read(absolutePath: particlesTypes.filepath) {
      if (isUrl(absolutePath)) {
        const result = await fetchWithCache(absolutePath)
        return result.content
      }
      const value = this.inMemoryFiles[absolutePath]
      if (value === undefined) {
        return ""
      }
      return value
    }
  
    async createReadStream(absolutePath: string) {
      return await this.read(absolutePath)
    }
  
    async exists(absolutePath: string) {
      if (isUrl(absolutePath)) {
        const result = await fetchWithCache(absolutePath)
        return result.exists
      }
      return this.inMemoryFiles[absolutePath] !== undefined
    }
  
    async write(absolutePath: particlesTypes.filepath, content: string) {
      if (isUrl(absolutePath)) {
        throw new Error("Cannot write to URL")
      }
      this.inMemoryFiles[absolutePath] = content
    }
  
    async list(absolutePath: particlesTypes.filepath) {
      if (isUrl(absolutePath)) {
        return []
      }
      return Object.keys(this.inMemoryFiles).filter(filePath => filePath.startsWith(absolutePath) && !filePath.replace(absolutePath, "").includes("/"))
    }
  
    async getMTime(absolutePath: string) {
      if (isUrl(absolutePath)) {
        const cached = urlCache[absolutePath]
        return cached ? cached.timestamp : Date.now()
      }
      return 1
    }
  
    async getCTime(absolutePath: string) {
      if (isUrl(absolutePath)) {
        const cached = urlCache[absolutePath]
        return cached ? cached.timestamp : Date.now()
      }
      return 1
    }
  
    dirname(path: string) {
      if (isUrl(path)) {
        return path.substring(0, path.lastIndexOf("/"))
      }
      return Utils.posix.dirname(path)
    }
  
    join(...segments: string[]) {
      const firstSegment = segments[0]
      if (isUrl(firstSegment)) {
        const baseUrl = firstSegment.endsWith("/") ? firstSegment : firstSegment + "/"
        return new URL(segments.slice(1).join("/"), baseUrl).toString()
      }
      return Utils.posix.join(...segments)
    }
  }
  
  class ScrollFile {
    constructor(codeAtStart: string, absoluteFilePath = "", fileSystem = new ScrollFileSystem({})) {
      this.fileSystem = fileSystem
      this.filePath = absoluteFilePath
      this.codeAtStart = codeAtStart
      this.timestamp = 0
      this.scrollProgram = new fileSystem.defaultParser(undefined, absoluteFilePath)
      this.scrollProgram.setFile(this)
    }
  
    exists = true
  
    private async _readCodeFromStorage() {
      if (this.codeAtStart !== undefined) return this // Code provided
      const { filePath } = this
      if (!filePath) {
        this.codeAtStart = ""
        return this
      }
      this.codeAtStart = await this.fileSystem.read(filePath)
    }
  
    async singlePassFuse() {
      if (!this._fuseRequest) this._fuseRequest = this._singlePassFuse()
      return await this._fuseRequest
    }
  
    async _singlePassFuse() {
      const { fileSystem, filePath, codeAtStart } = this
      if (codeAtStart !== undefined) {
        await this.scrollProgram.appendFromStream(codeAtStart)
      } else {
        if (!(await fileSystem.exists(filePath))) {
          this.exists = false
          this.isFused = true
          return this
        }
        this.timestamp = await fileSystem.getCTime(filePath)
        const stream = await fileSystem.createReadStream(filePath)
        await this.scrollProgram.appendFromStream(stream)
      }
      this.scrollProgram.wake()
      // What happens if we encounter a new parser?
      // very frequently if we encounter 1 parser we will encounter a sequence of parsers so
      // perhaps on wake, for now, we switch into collecting parsers mode
      // and then when we hit a non parser, only at that moment do we recompile the parsers
    }
  }
  let scrollFileSystemIdNumber = 0
  class ScrollFileSystem implements Storage {
    constructor(inMemoryFiles: particlesTypes.diskMap, standardParserDirectory?: string) {
      if (inMemoryFiles) this._storage = new MemoryWriter(inMemoryFiles)
      else this._storage = new DiskWriter()
      scrollFileSystemIdNumber = scrollFileSystemIdNumber + 1
      this.scrollFileSystemIdNumber = scrollFileSystemIdNumber
      this.standardParserDirectory = standardParserDirectory
      if (standardParserDirectory) this._loadDefaultParser()
    }
  
    standardParserDirectory?: string
  
    defaultParserCode = ""
    defaultParser = Particle
    defaultFileClass = ScrollFile
  
    newFile(codeAtStart: string, absoluteFilePath) {
      return new this.defaultFileClass(codeAtStart, absoluteFilePath, this)
    }
  
    private _loadDefaultParser() {
      const { standardParserDirectory } = this
      const defaultParserFiles = Disk.getFiles(standardParserDirectory).filter(file => file.endsWith(PARSERS_EXTENSION))
      this._setDefaultParser(
        standardParserDirectory,
        defaultParserFiles,
        defaultParserFiles.map(filePath => Disk.read(filePath))
      )
      return this
    }
  
    private _setDefaultParser(standardParserDirectory: string, defaultParserFiles: string[], contents: string[]) {
      const defaultParser = ScrollFileSystem._combineParsers(defaultParserFiles, contents)
      this.defaultParserCode = defaultParser.parsersCode
      this.defaultParser = defaultParser.parser
    }
  
    async read(absolutePath: particlesTypes.filepath) {
      return await this._storage.read(absolutePath)
    }
  
    async createReadStream(absolutePath: string) {
      return await this._storage.createReadStream(absolutePath)
    }
  
    async exists(absolutePath: particlesTypes.filepath) {
      return await this._storage.exists(absolutePath)
    }
  
    async write(absolutePath: particlesTypes.filepath, content: string) {
      return await this._storage.write(absolutePath, content)
    }
  
    async list(absolutePath: particlesTypes.filepath) {
      return await this._storage.list(absolutePath)
    }
  
    dirname(absolutePath: string) {
      return this._storage.dirname(absolutePath)
    }
  
    join(...segments: string[]) {
      return this._storage.join(...segments)
    }
  
    async getMTime(absolutePath: string) {
      return await this._storage.getMTime(absolutePath)
    }
  
    async getCTime(absolutePath: string) {
      return await this._storage.getCTime(absolutePath)
    }
  
    productCache = []
    async writeProduct(absolutePath, content) {
      this.productCache.push(absolutePath)
      return await this.write(absolutePath, content)
    }
  
    private _storage: Storage
    private _parserCache: { [concatenatedFilepaths: string]: any } = {}
  
    makeRelativePath(importer: string, importee: string) {
      const folder = this.dirname(importer)
      let absoluteImportFilePath = this.join(folder, importee)
      if (isUrl(importee)) absoluteImportFilePath = importee
      else if (isUrl(folder)) absoluteImportFilePath = folder + "/" + importee
      return absoluteImportFilePath
    }
  
    static sortParsers(code: string) {
      return new parsersParser(code)._sortParticlesByInScopeOrder()._sortWithParentParsersUpTop()
    }
  
    static _combineParsers(filePaths: string[], fileContents: string[], baseParsersCode = "") {
      const parserDefinitionRegex = /^[a-zA-Z0-9_]+Parser$/
      const atomDefinitionRegex = /^[a-zA-Z0-9_]+Atom/
  
      const mapped = fileContents.map((content, index) => {
        const filePath = filePaths[index]
        if (filePath.endsWith(PARSERS_EXTENSION)) return content
  
        return new Particle(content)
          .filter((particle: particlesTypes.particle) => particle.getLine().match(parserDefinitionRegex) || particle.getLine().match(atomDefinitionRegex))
          .map((particle: particlesTypes.particle) => particle.asString)
          .join("\n")
      })
  
      const asOneFile = mapped.join("\n").trim()
      const sorted = this.sortParsers(baseParsersCode + "\n" + asOneFile)
      const parsersCode = sorted.asString
      return {
        parsersParser: sorted,
        parsersCode,
        parser: new HandParsersProgram(parsersCode).compileAndReturnRootParser()
      }
    }
  
    setDefaultParserFromString(contents: string) {
      this._setDefaultParser("", ["scroll"], [contents])
    }
  
    private _fusedFiles = {}
    async getFusedFile(absolutePath: string) {
      const file = await this.getFile(absolutePath)
      await file.singlePassFuse()
      return file
    }
  
    async getFile(absolutePath: string) {
      if (this._fusedFiles[absolutePath]) return this._fusedFiles[absolutePath]
      const file = new ScrollFile(undefined, absolutePath, this)
      this._fusedFiles[absolutePath] = file
      return file
    }
  
    getFusedFilesInFolderIfCached(folderPath, requester) {
      folderPath = Utils.ensureFolderEndsInSlash(folderPath)
      const hit = this._folderCache[folderPath]
      if (!hit) console.log(`Warning: '${folderPath}' not yet loaded in '${this.scrollFileSystemIdNumber}'. Requested by '${requester.filePath}'`)
      return hit || []
    }
  
    private _folderCache = {}
    // todo: this is weird. i know we evolved our way here but we should step back and clean this up.
    async getFusedFilesInFolder(folderPath, extension) {
      folderPath = Utils.ensureFolderEndsInSlash(folderPath)
      if (this._folderCache[folderPath]) return this._folderCache[folderPath]
      const allFiles = (await this.list(folderPath)).filter(file => file.endsWith(extension))
      const loadedFiles = []
      for (let filePath of allFiles) {
        loadedFiles.push(await this.getFusedFile(filePath))
      }
      this._folderCache[folderPath] = loadedFiles
      return this._folderCache[folderPath]
    }
  }
  
  export { ScrollFileSystem, ScrollFile }
  
 perf.js
  #!/usr/bin/env node
  
  /*
  This file contains a simple set of perf tests that can be run manually to keep fusion perf in check.
  */
  
  // rm perf.cpuprofile; rm perf.heapprofile; node --cpu-prof --cpu-prof-name=perf.cpuprofile --heap-prof --heap-prof-name=perf.heapprofile perf.js
  
  const fs = require("fs")
  const path = require("path")
  const { Utils } = require("../products/Utils.js")
  const { Timer } = Utils
  const { Particle } = require("../products/Particle.js")
  const { Fusion } = require("../products/Fusion.js")
  const { ScrollFile } = require("scroll-cli")
  
  class PerfTest {
    constructor(folderPath) {
      this.folderPath = folderPath
      this.timer = new Timer()
      this.files = []
      this.simpleStrings = []
      this.particles = []
      this.fusedFiles = []
      this.scrollFiles = []
    }
  
    gatherFiles() {
      this.files = fs
        .readdirSync(this.folderPath)
        .filter(file => file.endsWith(".scroll"))
        .map(file => path.join(this.folderPath, file))
      console.log(`Found ${this.files.length} .scroll files`)
      this.tick("Finding files")
      return this
    }
  
    readToStrings() {
      this.simpleStrings = this.files.map(file => fs.readFileSync(file, "utf8"))
      this.tick("Reading files to strings")
      return this
    }
  
    parseToParticles() {
      this.particles = this.simpleStrings.map(str => new Particle(str))
      this.tick("Parsing to Particles")
      return this
    }
  
    async fuseFiles() {
      const fusion = new Fusion()
      this.fusedFiles = await Promise.all(this.files.map(file => fusion.fuseFile(file)))
      this.tick("Fusing files")
      return this
    }
  
    parseAsScroll() {
      this.scrollFiles = this.simpleStrings.map(str => new ScrollFile(str))
      this.tick("Parsing as Scroll")
      return this
    }
  
    tick(message) {
      this.printMemoryUsage()
      console.log("")
      this.timer.tick(message)
      console.log("----------")
    }
  
    printMemoryUsage() {
      const used = process.memoryUsage()
      console.log("\nMemory Usage:")
      for (let key in used) {
        console.log(`${key}: ${Math.round((used[key] / 1024 / 1024) * 100) / 100} MB`)
      }
    }
  
    async runAll() {
      this.tick("Starting performance tests...\n")
      this.gatherFiles().readToStrings().parseToParticles()
      await this.fuseFiles()
      this.parseAsScroll()
    }
  }
  
  // Run the tests
  const dir = "/Users/breck/pldb.io/concepts"
  const perfTest = new PerfTest(dir)
  perfTest.runAll().catch(console.error)
  
 readme.scroll
  # ScrollFileSystem
  
  Allows Scroll to have URL imports.
  
  Currently contains the import code logic that "fuses" files together (but that is moving toward Scroll and Particles)

stamp
 Utils.swarm
  #! /usr/bin/env node /usr/local/bin/scrollsdk
  arrange
   require ../products/Utils.js Utils
   static
  test stringToPermalink
   stringToPermalink 
    assertStringIs 
   stringToPermalink
    withParagraph
     hello%> world
    assertStringIs hello-world
   stringToPermalink hello.world
    assertStringIs hello.world
  test stripHtml
   stripHtml hello
    assertStringIs hello
  test strip2
   stripHtml
    withParagraph
     some text
      if
       we
        have
    assertParagraphIs
     some text
      if
       we
        have
  test getRandomString
   getRandomString 12
    assertLengthIs 12
   getRandomString 13
    assertLengthIs 13
  test linkify
   linkify http://cnn.com
    assertStringIs http://cnn.com
  test linkifyParens
   linkify http://wikipedia.com/wiki/foo_(ProgLang)
    assertStringIs http://wikipedia.com/wiki/foo_(ProgLang)
  test removeFileExtension
   removeFileExtension foobar.csv
    assertStringIs foobar
   removeFileExtension none
    assertStringIs none
   removeFileExtension 
    assertStringIs 
  test getPathWithoutFileName
   getPathWithoutFileName /foobar.js
    assertStringIs 
   getPathWithoutFileName /dog/foo.js
    assertStringIs /dog
   getPathWithoutFileName a/b/c/d/
    assertStringIs a/b/c/d
   getPathWithoutFileName a/b/c/d
    assertStringIs a/b/c
  test getFileExtension
   getFileExtension foobar.csv
    assertStringIs csv
   getFileExtension none
    assertStringIs 
 Utils.test.ts
  #!/usr/bin/env ts-node
  
  // todo: make isomorphic
  
  import { particlesTypes } from "../products/particlesTypes"
  const { Utils } = require("../products/Utils.js")
  const { Particle } = require("../products/Particle.js")
  const { TestRacer } = require("../products/TestRacer.js")
  
  const testParticles: particlesTypes.testParticles = {}
  
  testParticles.version = equal => {
    // Arrange/Act/Assert
    equal(!!Particle.getVersion(), true)
  }
  
  testParticles.titleToPermalink = equal => {
    // Arrange/Act/Assert
    equal(Utils.titleToPermalink("C#"), "c-sharp")
  }
  
  testParticles.isAbsoluteUrl = equal => {
    // AAA
    equal(Utils.isAbsoluteUrl("https://"), true)
    equal(Utils.isAbsoluteUrl("http://"), true)
    equal(Utils.isAbsoluteUrl("link.html"), false)
  }
  
  testParticles.getNextOrPrevious = equal => {
    // A/A/A
    equal(Utils.getNextOrPrevious([1, 2, 3], 2), 3)
  }
  
  testParticles.getRandomCharacters = equal => {
    // AAA
    equal(Utils.getRandomCharacters(9).length, 9)
  }
  
  testParticles.didYouMean = equal => {
    // Arrange/Act/Assert
    const didYouMean = Utils.didYouMean
    equal(didYouMean("lamr", ["couch", "sofa", "lamp"]), "lamp")
    equal(didYouMean("asfsaf", ["couch", "sofa", "lamp"]), undefined)
    equal(didYouMean("famp", ["couch", "camp", "lamp"]), "camp")
    equal(didYouMean("height", ["Height", "weight", "sign"]), "Height")
  }
  
  testParticles.getLineIndexAtCharacterPosition = equal => {
    // Arrange/Act/Assert
    equal(Utils.getClassNameFromFilePath(`foobar/FooBam.js`), "FooBam")
  }
  
  testParticles.getParentFolder = equal => {
    // Arrange/Act/Assert
    equal(Utils.getParentFolder(`foobar/FooBam.js`), "foobar/")
    equal(Utils.getParentFolder(`/`), "/")
    equal(Utils.getParentFolder(`/bam`), "/")
    equal(Utils.getParentFolder(`/bam/`), "/")
    equal(Utils.getParentFolder(`/bam/boom`), "/bam/")
    equal(Utils.getParentFolder(`/bam/boom/`), "/bam/")
    equal(Utils.getParentFolder(`/bam/boom/bah`), "/bam/boom/")
  }
  
  testParticles.getUniqueAtomsArray = equal => {
    equal(Utils.getUniqueAtomsArray(`hi hi hey`).length, 2)
  }
  
  testParticles.ucfirst = equal => {
    equal(Utils.ucfirst(`hi`), "Hi")
  }
  
  testParticles.getLineIndexAtCharacterPosition = equal => {
    // Arrange/Act/Assert
    equal(Utils.getLineIndexAtCharacterPosition(`abc`, 0), 0)
    equal(Utils.getLineIndexAtCharacterPosition(`abc`, 2), 0)
    equal(Utils.getLineIndexAtCharacterPosition(`abc\n`, 3), 0)
    equal(Utils.getLineIndexAtCharacterPosition(`abc\na`, 4), 1)
    equal(Utils.getLineIndexAtCharacterPosition(``, 0), 0)
  }
  
  testParticles.graphSort = equal => {
    // Arrange
    const a = new Particle(`dog animal
  animal
  retriever dog
  car
  cat animal
  house`)
    a.sort(
      Utils._makeGraphSortFunction(
        (particle: any) => particle.getAtom(0),
        (particle: any) => particle.getAtom(1)
      )
    )
  
    // Assert
    equal(
      a.toString(),
      `animal
  car
  house
  cat animal
  dog animal
  retriever dog`
    )
  }
  
  testParticles.makeRandomParticles = equal => {
    // Arrange/Act/Assert
    equal(new Particle(Utils.makeRandomParticles(2)).topDownArray.length, 3)
  }
  
  testParticles.makeSemiRandomFn = equal => {
    const rand = Utils.makeSemiRandomFn(1)
    const first = rand()
    const expected = 0.7098480789645691
    equal(first, expected)
    equal(Utils.makeSemiRandomFn(1)(), expected)
    equal(rand() !== first, true)
  
    equal(Utils.randomUniformFloat(0, 100, 2), 97.42682568175951)
    equal(Utils.randomUniformInt(0, 100, 2), 97)
  }
  
  /*NODE_JS_ONLY*/ if (!module.parent) TestRacer.testSingleFile(__filename, testParticles)
  
  export { testParticles }
  
 Utils.ts
  import { particlesTypes } from "../products/particlesTypes"
  
  class Timer {
    constructor() {
      this._tickTime = Date.now() - (Utils.isNodeJs() ? 1000 * process.uptime() : 0)
      this._firstTickTime = this._tickTime
    }
  
    private _tickTime: number
    private _firstTickTime: number
  
    tick(msg?: string) {
      const elapsed = Date.now() - this._tickTime
      if (msg) console.log(`${elapsed}ms ${msg}`)
      this._tickTime = Date.now()
      return elapsed
    }
  
    getTotalElapsedTime() {
      return Date.now() - this._firstTickTime
    }
  }
  
  class Utils {
    static getFileExtension(filepath = "") {
      const match = filepath.match(/\.([^\.]+)$/)
      return (match && match[1]) || ""
    }
  
    static ensureFolderEndsInSlash(folder: string) {
      return folder.replace(/\/$/, "") + "/"
    }
  
    static runCommand(instance: any, command = "", param: string = undefined) {
      const run = (name: string) => {
        console.log(`Running ${name}:`)
        instance[name](param)
      }
  
      if (instance[command + "Command"]) return run(command + "Command")
  
      // Get commands from both the child and parent classes
      const classes = [Object.getPrototypeOf(instance), Object.getPrototypeOf(Object.getPrototypeOf(instance))]
      const allCommands = classes.map(classInstance => Object.getOwnPropertyNames(classInstance).filter(atom => atom.endsWith("Command"))).flat()
      allCommands.sort()
  
      const commandAsNumber = parseInt(command) - 1
  
      if (command.match(/^\d+$/) && allCommands[commandAsNumber]) return run(allCommands[commandAsNumber])
  
      console.log(`\n❌ No command provided. Available commands:\n\n` + allCommands.map((name, index) => `${index + 1}. ${name.replace("Command", "")}`).join("\n") + "\n")
    }
  
    static removeReturnChars(str = "") {
      return str.replace(/\r/g, "")
    }
  
    static isAbsoluteUrl(url: string) {
      return url.startsWith("https://") || url.startsWith("http://")
    }
  
    static removeEmptyLines(str = "") {
      return str.replace(/\n\n+/g, "\n")
    }
  
    static shiftRight(str = "", numSpaces = 1) {
      let spaces = " ".repeat(numSpaces)
      return str.replace(/\n/g, `\n${spaces}`)
    }
  
    static getLinks(str = "") {
      const _re = new RegExp("(^|[ \t\r\n])((ftp|http|https):(([A-Za-z0-9$_.+!*(),;/?:@&~=-])|%[A-Fa-f0-9]{2}){2,}(#([a-zA-Z0-9][a-zA-Z0-9$_.+!*(),;/?:@&~=%-]*))?([A-Za-z0-9$_+!*();/?:~-]))", "g")
      return str.match(_re) || []
    }
  
    // Only allow text content and inline styling. Don't allow HTML tags or any nested scroll tags or escape characters.
    static escapeScrollAndHtml(content = "") {
      return content.replace(/ atom.includes(delimiter))
      if (hit) throw `Delimiter "${delimiter}" found in hit`
    }
  
    // https://github.com/rigoneri/indefinite-article.js/blob/master/indefinite-article.js
    static getIndefiniteArticle(phrase: string) {
      // Getting the first atom
      const match = /\w+/.exec(phrase)
      let atom
      if (match) atom = match[0]
      else return "an"
  
      var l_atom = atom.toLowerCase()
      // Specific start of atoms that should be preceded by 'an'
      var alt_cases = ["honest", "hour", "hono"]
      for (var i in alt_cases) {
        if (l_atom.indexOf(alt_cases[i]) == 0) return "an"
      }
  
      // Single letter atom which should be preceded by 'an'
      if (l_atom.length == 1) {
        if ("aedhilmnorsx".indexOf(l_atom) >= 0) return "an"
        else return "a"
      }
  
      // Capital atoms which should likely be preceded by 'an'
      if (atom.match(/(?!FJO|[HLMNS]Y.|RY[EO]|SQU|(F[LR]?|[HL]|MN?|N|RH?|S[CHKLMNPTVW]?|X(YL)?)[AEIOU])[FHLMNRSX][A-Z]/)) {
        return "an"
      }
  
      // Special cases where a atom that begins with a vowel should be preceded by 'a'
      const regexes = [/^e[uw]/, /^onc?e\b/, /^uni([^nmd]|mo)/, /^u[bcfhjkqrst][aeiou]/]
      for (var i in regexes) {
        if (l_atom.match(regexes[i])) return "a"
      }
  
      // Special capital atoms (UK, UN)
      if (atom.match(/^U[NK][AIEO]/)) {
        return "a"
      } else if (atom == atom.toUpperCase()) {
        if ("aedhilmnorsx".indexOf(l_atom[0]) >= 0) return "an"
        else return "a"
      }
  
      // Basic method of atoms that begin with a vowel being preceded by 'an'
      if ("aeiou".indexOf(l_atom[0]) >= 0) return "an"
  
      // Instances where y follwed by specific letters is preceded by 'an'
      if (l_atom.match(/^y(b[lor]|cl[ea]|fere|gg|p[ios]|rou|tt)/)) return "an"
  
      return "a"
    }
  
    static htmlEscaped(content = "") {
      return content.replace(/()[\]\\.,;:\s@"]+(\.[^()[\]\\.,;:\s@"]+)*)|(".+"))@((\[[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\])|(([a-zA-Z\-0-9]+\.)+[a-zA-Z]{2,}))$/)
    }
  
    static capitalizeFirstLetter(str: string) {
      return str.charAt(0).toUpperCase() + str.slice(1)
    }
  
    // generate a random alpha numeric hash:
    static getRandomCharacters(length: number) {
      const characters = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789"
      let result = ""
      for (let i = 0; i  {
        if (!dirName) throw new Error(`dirName undefined when attempting to findProjectRoot for project "${projectName}" starting in "${startingDirName}"`)
        const parts = dirName.split("/")
        const filename = parts.join("/") + "/" + "package.json"
        if (fs.existsSync(filename) && JSON.parse(fs.readFileSync(filename, "utf8")).name === projectName) return parts.join("/") + "/"
        parts.pop()
        return parts
      }
  
      let result = getProjectName(startingDirName)
      while (typeof result !== "string" && result.length > 0) {
        result = getProjectName(result.join("/"))
      }
      if (result.length === 0) throw new Error(`Project root "${projectName}" in folder ${startingDirName} not found.`)
      return result
    }
  
    static titleToPermalink(str: string) {
      return str
        .replace(/[\/\_\:\\\[\]]/g, "-")
        .replace(/π/g, "pi")
        .replace(/`/g, "tick")
        .replace(/\$/g, "dollar-sign")
        .replace(/\*$/g, "-star")
        .replace(/^\*/g, "star-")
        .replace(/\*/g, "-star-")
        .replace(/\'+$/g, "q")
        .replace(/^@/g, "at-")
        .replace(/@$/g, "-at")
        .replace(/@/g, "-at-")
        .replace(/[\'\"\,\ū]/g, "")
        .replace(/^\#/g, "sharp-")
        .replace(/\#$/g, "-sharp")
        .replace(/\#/g, "-sharp-")
        .replace(/[\(\)]/g, "")
        .replace(/\+\+$/g, "pp")
        .replace(/\+$/g, "p")
        .replace(/^\!/g, "bang-")
        .replace(/\!$/g, "-bang")
        .replace(/\!/g, "-bang-")
        .replace(/\&/g, "-n-")
        .replace(/[\+ ]/g, "-")
        .replace(/[^a-zA-Z0-9\-\.]/g, "")
        .toLowerCase()
    }
  
    static escapeRegExp(str: string) {
      return str.replace(/[.*+?^${}()|[\]\\]/g, "\\$&")
    }
  
    static sum(arr: number[]) {
      return arr.reduce((curr, next) => curr + next, 0)
    }
  
    static removeNonAscii(str: string) {
      // https://stackoverflow.com/questions/20856197/remove-non-ascii-character-in-string
      return str.replace(/[^\x00-\x7F]/g, "")
    }
  
    //http://stackoverflow.com/questions/37684/how-to-replace-plain-urls-with-links#21925491
    static linkify = (text: string, target = "_blank") => {
      let replacedText
      let replacePattern1
      let replacePattern2
      let replacePattern3
  
      //URLs starting with http://, https://, or ftp://
      replacePattern1 = /(\b(https?|ftp):\/\/[-A-Z\(\)0-9+&@#\/%?=~_|!:,.;]*[-A-Z0-9+\(\)&@#\/%=~_|])/gim
      replacedText = text.replace(replacePattern1, `$1`)
  
      //URLs starting with "www." (without // before it, or it'd re-link the ones done above).
      replacePattern2 = /(^|[^\/])(www\.[\S]+(\b|$))/gim
      replacedText = replacedText.replace(replacePattern2, `$1$2`)
  
      //Change email addresses to mailto:: links.
      replacePattern3 = /(([a-zA-Z0-9\-\_\.])+@[a-zA-Z\_]+?(\.[a-zA-Z]{2,6})+)/gim
      replacedText = replacedText.replace(replacePattern3, '$1')
  
      return replacedText
    }
  
    static getMethodFromDotPath(context: any, str: string) {
      const methodParts = str.split(".")
      while (methodParts.length > 1) {
        const methodName = methodParts.shift()
        if (!context[methodName]) throw new Error(`${methodName} is not a method on ${context}`)
        context = context[methodName]()
      }
      const final = methodParts.shift()
      return [context, final]
    }
  
    static requireAbsOrRelative(filePath: particlesTypes.filepath, contextFilePath: particlesTypes.filepath) {
      if (!filePath.startsWith(".")) return require(filePath)
      const path = require("path")
      const folder = this.getPathWithoutFileName(contextFilePath)
      const file = path.resolve(folder + "/" + filePath)
      return require(file)
    }
  
    // Removes last ".*" from this string
    static removeFileExtension(filename: particlesTypes.filepath) {
      return filename ? filename.replace(/\.[^\.]+$/, "") : ""
    }
  
    static getFileName(path: particlesTypes.filepath) {
      const normalizedPath = path.replace(/\\/g, "/")
      const parts = normalizedPath.split("/")
      return parts.pop()
    }
  
    static getPathWithoutFileName(path: particlesTypes.filepath) {
      const normalizedPath = path.replace(/\\/g, "/")
      const parts = normalizedPath.split("/")
      parts.pop()
      return parts.join("/")
    }
  
    // todo: switch algo to: http://indiegamr.com/generate-repeatable-random-numbers-in-js/?
    static makeSemiRandomFn = (seed = Date.now()) => {
      return () => {
        const semiRand = Math.sin(seed++) * 10000
        return semiRand - Math.floor(semiRand)
      }
    }
  
    static randomUniformInt = (min: particlesTypes.int, max: particlesTypes.int, seed = Date.now()) => {
      return Math.floor(Utils.randomUniformFloat(min, max, seed))
    }
  
    static randomUniformFloat = (min: number, max: number, seed = Date.now()) => {
      const randFn = Utils.makeSemiRandomFn(seed)
      return min + (max - min) * randFn()
    }
  
    static getRange = (startIndex: number, endIndexExclusive: number, increment = 1) => {
      const range = []
      for (let index = startIndex; index  0; index--) {
        const tempIndex = Math.floor(randFn() * (index + 1))
        ;[arr[index], arr[tempIndex]] = [arr[tempIndex], arr[index]]
      }
      return arr
    }
  
    // Only allows a-zA-Z0-9-_  (And optionally .)
    static _permalink(str: string, reg: RegExp) {
      return str.length ? str.toLowerCase().replace(reg, "").replace(/ /g, "-") : ""
    }
  
    static isValueEmpty(value: any) {
      return value === undefined || value === "" || (typeof value === "number" && isNaN(value)) || (value instanceof Date && isNaN(value))
    }
  
    static stringToPermalink(str: string) {
      return this._permalink(str, /[^a-z0-9- _\.]/gi)
    }
  
    static getAvailablePermalink(permalink: string, doesFileExistSyncFn: (permalink: string) => boolean) {
      const extension = this.getFileExtension(permalink)
      permalink = this.removeFileExtension(permalink)
      const originalPermalink = permalink
      let num = 2
      let suffix = ""
      let filename = `${originalPermalink}${suffix}.${extension}`
  
      while (doesFileExistSyncFn(filename)) {
        filename = `${originalPermalink}${suffix}.${extension}`
        suffix = "-" + num
        num++
      }
  
      return filename
    }
  
    static getNextOrPrevious(arr: any[], item: any) {
      const length = arr.length
      const index = arr.indexOf(item)
      if (length === 1) return undefined
      if (index === length - 1) return arr[index - 1]
      return arr[index + 1]
    }
  
    static toggle(currentValue: any, values: any[]) {
      const index = values.indexOf(currentValue)
      return index === -1 || index + 1 === values.length ? values[0] : values[index + 1]
    }
  
    static getClassNameFromFilePath(filepath: particlesTypes.filepath) {
      return this.removeFileExtension(this.getFileName(filepath))
    }
  
    static joinArraysOn(joinOn: string, arrays: any[], columns: string[][]) {
      const rows: any = {}
      let index = 0
      if (!columns) columns = arrays.map(arr => Object.keys(arr[0]))
      arrays.forEach((arr, index) => {
        const cols = columns[index]
  
        arr.forEach((row: any) => {
          const key = joinOn ? row[joinOn] : index++
          if (!rows[key]) rows[key] = {}
          const obj = rows[key]
          cols.forEach(col => (obj[col] = row[col]))
        })
      })
      return Object.values(rows)
    }
    static getParentFolder(path: string) {
      if (path.endsWith("/")) path = this._removeLastSlash(path)
      return path.replace(/\/[^\/]*$/, "") + "/"
    }
  
    static _removeLastSlash(path: string) {
      return path.replace(/\/$/, "")
    }
  
    static _listToEnglishText(list: string[], limit = 5) {
      const len = list.length
      if (!len) return ""
      if (len === 1) return `'${list[0]}'`
      const clone = list.slice(0, limit).map(item => `'${item}'`)
      const last = clone.pop()
      if (len /".split("").find(idea => !str.includes(idea))
      if (!del) throw new Error("Could not find a delimiter")
      return del
    }
  
    static flatten(arr: any) {
      if (arr.flat) return arr.flat()
      return arr.reduce((acc: any, val: any) => acc.concat(val), [])
    }
  
    static escapeBackTicks(str: string) {
      return str.replace(/\`/g, "\\`").replace(/\$\{/g, "\\${")
    }
  
    static ucfirst(str: string) {
      return str.charAt(0).toUpperCase() + str.slice(1)
    }
  
    // Adapted from: https://github.com/dcporter/didyoumean.js/blob/master/didYouMean-1.2.1.js
    static didYouMean(str: string = "", options: string[] = [], caseSensitive = false, threshold = 0.4, thresholdAbsolute = 20) {
      if (!caseSensitive) str = str.toLowerCase()
  
      // Calculate the initial value (the threshold) if present.
      const thresholdRelative = threshold * str.length
      let maximumEditDistanceToBeBestMatch
      if (thresholdRelative !== null && thresholdAbsolute !== null) maximumEditDistanceToBeBestMatch = Math.min(thresholdRelative, thresholdAbsolute)
      else if (thresholdRelative !== null) maximumEditDistanceToBeBestMatch = thresholdRelative
      else if (thresholdAbsolute !== null) maximumEditDistanceToBeBestMatch = thresholdAbsolute
  
      // Get the edit distance to each option. If the closest one is less than 40% (by default) of str's length, then return it.
      let closestMatch
      const len = options.length
      for (let optionIndex = 0; optionIndex  maxInt) return maxInt + 1
  
      // Slow path.
      const matrix = []
  
      // Set up the first row ([0, 1, 2, 3, etc]).
      for (let bIndex = 0; bIndex  maxInt) minJ = bIndex - maxInt
        maxJ = bLength + 1
        if (maxJ > maxInt + bIndex) maxJ = maxInt + bIndex
        // Loop over the rest of the rows.
        for (let aIndex = 1; aIndex  maxJ) matrix[bIndex][aIndex] = maxInt + 1
          // Otherwise do the normal Levenshtein thing.
          else {
            // If the characters are the same, there's no change in edit distance.
            if (stringB.charAt(bIndex - 1) === stringA.charAt(aIndex - 1)) matrix[bIndex][aIndex] = matrix[bIndex - 1][aIndex - 1]
            // Otherwise, see if we're substituting, inserting or deleting.
            else
              matrix[bIndex][aIndex] = Math.min(
                matrix[bIndex - 1][aIndex - 1] + 1, // Substitute
                Math.min(
                  matrix[bIndex][aIndex - 1] + 1, // Insert
                  matrix[bIndex - 1][aIndex] + 1
                )
              ) // Delete
          }
  
          // Either way, update colMin.
          if (matrix[bIndex][aIndex]  maxInt) return maxInt + 1
      }
      // If we made it this far without running into the max, then return the final matrix value.
      return matrix[bLength][aLength]
    }
  
    static getLineIndexAtCharacterPosition(str: string, index: number): number {
      const lines = str.split("\n")
      const len = lines.length
      let position = 0
      for (let lineNumber = 0; lineNumber = index) return lineNumber
      }
    }
  
    static resolvePath(filePath: string, programFilepath: string) {
      // For use in Node.js only
      if (!filePath.startsWith(".")) return filePath
      const path = require("path")
      const folder = this.getPathWithoutFileName(programFilepath)
      return path.resolve(folder + "/" + filePath)
    }
  
    static resolveProperty(obj: Object, path: string | string[], separator = ".") {
      const properties = Array.isArray(path) ? path : path.split(separator)
      return properties.reduce((prev: any, curr) => prev && prev[curr], obj)
    }
  
    static appendCodeAndReturnValueOnWindow(code: particlesTypes.javascriptCode, name: string): any {
      const script = document.createElement("script")
      script.innerHTML = code
      document.head.appendChild(script)
      return (window)[name]
    }
  
    static formatStr(str: string, catchAllAtomDelimiter = " ", parameterMap: particlesTypes.stringMap) {
      return str.replace(/{([^\}]+)}/g, (match, path) => {
        const val = parameterMap[path]
        if (val === undefined) return ""
        return Array.isArray(val) ? val.join(catchAllAtomDelimiter) : val
      })
    }
  
    static stripHtml(text: string) {
      return text && text.replace ? text.replace(//gm, "") : text
    }
  
    static getUniqueAtomsArray(allAtoms: string) {
      const atoms = allAtoms.replace(/\n/g, " ").split(" ")
      const index: particlesTypes.stringMap = {}
      atoms.forEach(atom => {
        if (!index[atom]) index[atom] = 0
        index[atom]++
      })
      return Object.keys(index).map(key => {
        return {
          atom: key,
          count: index[key]
        }
      })
    }
  
    static getRandomString(length = 30, letters = "abcdefghijklmnopqrstuvwxyz0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ".split(""), seed = Date.now()) {
      let str = ""
      const randFn = Utils._getPseudoRandom0to1FloatGenerator(seed)
      while (length) {
        str += letters[Math.round(Math.min(randFn() * letters.length, letters.length - 1))]
        length--
      }
      return str
    }
  
    // todo: add seed!
    static makeRandomParticles(lines = 1000, seed = Date.now()) {
      let str = ""
      let letters = " 123abc".split("")
      const randFn = Utils._getPseudoRandom0to1FloatGenerator(seed)
      while (lines) {
        let indent = " ".repeat(Math.round(randFn() * 6))
        let bit = indent
        let rand = Math.floor(randFn() * 30)
  
        while (rand) {
          bit += letters[Math.round(Math.min(randFn() * letters.length, letters.length - 1))]
          rand--
        }
  
        bit += "\n"
        str += bit
        lines--
      }
      return str
    }
  
    // adapted from https://gist.github.com/blixt/f17b47c62508be59987b
    // 1993 Park-Miller LCG
    static _getPseudoRandom0to1FloatGenerator(seed: number) {
      return function () {
        seed = Math.imul(48271, seed) | 0 % 2147483647
        return (seed & 2147483647) / 2147483648
      }
    }
  
    static sampleWithoutReplacement(population: any[] = [], quantity: number, seed: number) {
      const prng = this._getPseudoRandom0to1FloatGenerator(seed)
      const sampled: { [index: number]: boolean } = {}
      const populationSize = population.length
      if (quantity >= populationSize) return population.slice(0)
      const picked = []
      while (picked.length ) {
      const map: particlesTypes.stringMap = {}
      arr.forEach(val => (map[val] = true))
      return map
    }
  
    static _replaceNonAlphaNumericCharactersWithCharCodes(str: string) {
      return str
        .replace(/[^a-zA-Z0-9]/g, (sub: string) => {
          return "_" + sub.charCodeAt(0).toString()
        })
        .replace(/^([0-9])/, "number$1")
    }
  
    static mapValues(object: Object, fn: (key: string) => T) {
      const result: { [key: string]: T } = {}
      Object.keys(object).forEach(key => {
        result[key] = fn(key)
      })
      return result
    }
  
    static javascriptTableWithHeaderRowToObjects(dataTable: Array): particlesTypes.rawRowJavascriptObject[] {
      dataTable = dataTable.slice()
      const header = dataTable.shift()
      return dataTable.map((row: any) => {
        const obj: any = {}
        header.forEach((colName: string, index: particlesTypes.int) => (obj[colName] = row[index]))
        return obj
      })
    }
  
    static interweave(arrayOfArrays: any[][]) {
      const lineCount = Math.max(...arrayOfArrays.map(arr => arr.length))
      const totalArrays = arrayOfArrays.length
      const result: any[] = []
      arrayOfArrays.forEach((lineArray, arrayIndex) => {
        for (let lineIndex = 0; lineIndex  {
        const particleAFirst = -1
        const particleBFirst = 1
  
        const accessor = arrayOfFns[0] // todo: handle accessors
        const av = accessor(objectA)
        const bv = accessor(objectB)
        let result = av  bv ? particleBFirst : 0
        if (av === undefined && bv !== undefined) result = particleAFirst
        else if (bv === undefined && av !== undefined) result = particleBFirst
        return result
      }
    }
  
    static _makeGraphSortFunctionFromGraph(idAccessor: particlesTypes.idAccessorFunction, graph: { [id: string]: Set }) {
      return (particleA: particlesTypes.particle, particleB: particlesTypes.particle) => {
        const particleAFirst = -1
        const particleBFirst = 1
  
        const particleAUniqueId = idAccessor(particleA)
        const particleBUniqueId = idAccessor(particleB)
  
        const particleAExtendsParticleB = graph[particleAUniqueId].has(particleBUniqueId)
        const particleBExtendsParticleA = graph[particleBUniqueId].has(particleAUniqueId)
  
        if (particleAExtendsParticleB) return particleBFirst
        else if (particleBExtendsParticleA) return particleAFirst
  
        const particleAExtendsSomething = graph[particleAUniqueId].size > 1
        const particleBExtendsSomething = graph[particleBUniqueId].size > 1
  
        if (!particleAExtendsSomething && particleBExtendsSomething) return particleAFirst
        else if (!particleBExtendsSomething && particleAExtendsSomething) return particleBFirst
  
        if (particleAUniqueId > particleBUniqueId) return particleBFirst
        else if (particleAUniqueId  {
        // -1 === a before b
        const particleAUniqueId = idAccessor(particleA)
        const particleAExtends = extendsIdAccessor(particleA)
        const particleBUniqueId = idAccessor(particleB)
        const particleBExtends = extendsIdAccessor(particleB)
        const particleAExtendsParticleB = particleAExtends === particleBUniqueId
        const particleBExtendsParticleA = particleBExtends === particleAUniqueId
  
        const particleAFirst = -1
        const particleBFirst = 1
  
        if (!particleAExtends && !particleBExtends) {
          // If neither extends, sort by cue
          if (particleAUniqueId > particleBUniqueId) return particleBFirst
          else if (particleAUniqueId  particleBExtends) return particleBFirst
        else if (particleAExtends  particleBUniqueId) return particleBFirst
        else if (particleAUniqueId  2) {
              var lastSlashIndex = res.lastIndexOf("/")
              if (lastSlashIndex !== res.length - 1) {
                if (lastSlashIndex === -1) {
                  res = ""
                  lastSegmentLength = 0
                } else {
                  res = res.slice(0, lastSlashIndex)
                  lastSegmentLength = res.length - 1 - res.lastIndexOf("/")
                }
                lastSlash = i
                dots = 0
                continue
              }
            } else if (res.length === 2 || res.length === 1) {
              res = ""
              lastSegmentLength = 0
              lastSlash = i
              dots = 0
              continue
            }
          }
          if (allowAboveRoot) {
            if (res.length > 0) res += "/.."
            else res = ".."
            lastSegmentLength = 2
          }
        } else {
          if (res.length > 0) res += "/" + path.slice(lastSlash + 1, i)
          else res = path.slice(lastSlash + 1, i)
          lastSegmentLength = i - lastSlash - 1
        }
        lastSlash = i
        dots = 0
      } else if (code === 46 /*.*/ && dots !== -1) {
        ++dots
      } else {
        dots = -1
      }
    }
    return res
  }
  
  function _posixFormat(sep, pathObject) {
    var dir = pathObject.dir || pathObject.root
    var base = pathObject.base || (pathObject.name || "") + (pathObject.ext || "")
    if (!dir) {
      return base
    }
    if (dir === pathObject.root) {
      return dir + base
    }
    return dir + sep + base
  }
  
  var posix = {
    // path.resolve([from ...], to)
    resolve: function resolve() {
      var resolvedPath = ""
      var resolvedAbsolute = false
      var cwd
  
      for (var i = arguments.length - 1; i >= -1 && !resolvedAbsolute; i--) {
        var path
        if (i >= 0) path = arguments[i]
        else {
          if (cwd === undefined) cwd = process.cwd()
          path = cwd
        }
  
        posix_assertPath(path)
  
        // Skip empty entries
        if (path.length === 0) {
          continue
        }
  
        resolvedPath = path + "/" + resolvedPath
        resolvedAbsolute = path.charCodeAt(0) === 47 /*/*/
      }
  
      // At this point the path should be resolved to a full absolute path, but
      // handle relative paths to be safe (might happen when process.cwd() fails)
  
      // Normalize the path
      resolvedPath = normalizeStringPosix(resolvedPath, !resolvedAbsolute)
  
      if (resolvedAbsolute) {
        if (resolvedPath.length > 0) return "/" + resolvedPath
        else return "/"
      } else if (resolvedPath.length > 0) {
        return resolvedPath
      } else {
        return "."
      }
    },
  
    normalize: function normalize(path) {
      posix_assertPath(path)
  
      if (path.length === 0) return "."
  
      var isAbsolute = path.charCodeAt(0) === 47 /*/*/
      var trailingSeparator = path.charCodeAt(path.length - 1) === 47 /*/*/
  
      // Normalize the path
      path = normalizeStringPosix(path, !isAbsolute)
  
      if (path.length === 0 && !isAbsolute) path = "."
      if (path.length > 0 && trailingSeparator) path += "/"
  
      if (isAbsolute) return "/" + path
      return path
    },
  
    isAbsolute: function isAbsolute(path) {
      posix_assertPath(path)
      return path.length > 0 && path.charCodeAt(0) === 47 /*/*/
    },
  
    join: function join() {
      if (arguments.length === 0) return "."
      var joined
      for (var i = 0; i  0) {
          if (joined === undefined) joined = arg
          else joined += "/" + arg
        }
      }
      if (joined === undefined) return "."
      return posix.normalize(joined)
    },
  
    relative: function relative(from, to) {
      posix_assertPath(from)
      posix_assertPath(to)
  
      if (from === to) return ""
  
      from = posix.resolve(from)
      to = posix.resolve(to)
  
      if (from === to) return ""
  
      // Trim any leading backslashes
      var fromStart = 1
      for (; fromStart  length) {
            if (to.charCodeAt(toStart + i) === 47 /*/*/) {
              // We get here if `from` is the exact base path for `to`.
              // For example: from='/foo/bar'; to='/foo/bar/baz'
              return to.slice(toStart + i + 1)
            } else if (i === 0) {
              // We get here if `from` is the root
              // For example: from='/'; to='/foo'
              return to.slice(toStart + i)
            }
          } else if (fromLen > length) {
            if (from.charCodeAt(fromStart + i) === 47 /*/*/) {
              // We get here if `to` is the exact base path for `from`.
              // For example: from='/foo/bar/baz'; to='/foo/bar'
              lastCommonSep = i
            } else if (i === 0) {
              // We get here if `to` is the root.
              // For example: from='/foo'; to='/'
              lastCommonSep = 0
            }
          }
          break
        }
        var fromCode = from.charCodeAt(fromStart + i)
        var toCode = to.charCodeAt(toStart + i)
        if (fromCode !== toCode) break
        else if (fromCode === 47 /*/*/) lastCommonSep = i
      }
  
      var out = ""
      // Generate the relative path based on the path difference between `to`
      // and `from`
      for (i = fromStart + lastCommonSep + 1; i  0) return out + to.slice(toStart + lastCommonSep)
      else {
        toStart += lastCommonSep
        if (to.charCodeAt(toStart) === 47 /*/*/) ++toStart
        return to.slice(toStart)
      }
    },
  
    _makeLong: function _makeLong(path) {
      return path
    },
  
    dirname: function dirname(path) {
      posix_assertPath(path)
      if (path.length === 0) return "."
      var code = path.charCodeAt(0)
      var hasRoot = code === 47 /*/*/
      var end = -1
      var matchedSlash = true
      for (var i = path.length - 1; i >= 1; --i) {
        code = path.charCodeAt(i)
        if (code === 47 /*/*/) {
          if (!matchedSlash) {
            end = i
            break
          }
        } else {
          // We saw the first non-path separator
          matchedSlash = false
        }
      }
  
      if (end === -1) return hasRoot ? "/" : "."
      if (hasRoot && end === 1) return "//"
      return path.slice(0, end)
    },
  
    basename: function basename(path, ext) {
      if (ext !== undefined && typeof ext !== "string") throw new TypeError('"ext" argument must be a string')
      posix_assertPath(path)
  
      var start = 0
      var end = -1
      var matchedSlash = true
      var i
  
      if (ext !== undefined && ext.length > 0 && ext.length = 0; --i) {
          var code = path.charCodeAt(i)
          if (code === 47 /*/*/) {
            // If we reached a path separator that was not part of a set of path
            // separators at the end of the string, stop now
            if (!matchedSlash) {
              start = i + 1
              break
            }
          } else {
            if (firstNonSlashEnd === -1) {
              // We saw the first non-path separator, remember this index in case
              // we need it if the extension ends up not matching
              matchedSlash = false
              firstNonSlashEnd = i + 1
            }
            if (extIdx >= 0) {
              // Try to match the explicit extension
              if (code === ext.charCodeAt(extIdx)) {
                if (--extIdx === -1) {
                  // We matched the extension, so mark this as the end of our path
                  // component
                  end = i
                }
              } else {
                // Extension does not match, so our result is the entire path
                // component
                extIdx = -1
                end = firstNonSlashEnd
              }
            }
          }
        }
  
        if (start === end) end = firstNonSlashEnd
        else if (end === -1) end = path.length
        return path.slice(start, end)
      } else {
        for (i = path.length - 1; i >= 0; --i) {
          if (path.charCodeAt(i) === 47 /*/*/) {
            // If we reached a path separator that was not part of a set of path
            // separators at the end of the string, stop now
            if (!matchedSlash) {
              start = i + 1
              break
            }
          } else if (end === -1) {
            // We saw the first non-path separator, mark this as the end of our
            // path component
            matchedSlash = false
            end = i + 1
          }
        }
  
        if (end === -1) return ""
        return path.slice(start, end)
      }
    },
  
    extname: function extname(path) {
      posix_assertPath(path)
      var startDot = -1
      var startPart = 0
      var end = -1
      var matchedSlash = true
      // Track the state of characters (if any) we see before our first dot and
      // after any path separator we find
      var preDotState = 0
      for (var i = path.length - 1; i >= 0; --i) {
        var code = path.charCodeAt(i)
        if (code === 47 /*/*/) {
          // If we reached a path separator that was not part of a set of path
          // separators at the end of the string, stop now
          if (!matchedSlash) {
            startPart = i + 1
            break
          }
          continue
        }
        if (end === -1) {
          // We saw the first non-path separator, mark this as the end of our
          // extension
          matchedSlash = false
          end = i + 1
        }
        if (code === 46 /*.*/) {
          // If this is our first dot, mark it as the start of our extension
          if (startDot === -1) startDot = i
          else if (preDotState !== 1) preDotState = 1
        } else if (startDot !== -1) {
          // We saw a non-dot and non-path separator before our dot, so we should
          // have a good chance at having a non-empty extension
          preDotState = -1
        }
      }
  
      if (
        startDot === -1 ||
        end === -1 ||
        // We saw a non-dot character immediately before the dot
        preDotState === 0 ||
        // The (right-most) trimmed path component is exactly '..'
        (preDotState === 1 && startDot === end - 1 && startDot === startPart + 1)
      ) {
        return ""
      }
      return path.slice(startDot, end)
    },
  
    format: function format(pathObject) {
      if (pathObject === null || typeof pathObject !== "object") {
        throw new TypeError('The "pathObject" argument must be of type Object. Received type ' + typeof pathObject)
      }
      return _posixFormat("/", pathObject)
    },
  
    parse: function parse(path) {
      posix_assertPath(path)
  
      var ret = { root: "", dir: "", base: "", ext: "", name: "" }
      if (path.length === 0) return ret
      var code = path.charCodeAt(0)
      var isAbsolute = code === 47 /*/*/
      var start
      if (isAbsolute) {
        ret.root = "/"
        start = 1
      } else {
        start = 0
      }
      var startDot = -1
      var startPart = 0
      var end = -1
      var matchedSlash = true
      var i = path.length - 1
  
      // Track the state of characters (if any) we see before our first dot and
      // after any path separator we find
      var preDotState = 0
  
      // Get non-dir info
      for (; i >= start; --i) {
        code = path.charCodeAt(i)
        if (code === 47 /*/*/) {
          // If we reached a path separator that was not part of a set of path
          // separators at the end of the string, stop now
          if (!matchedSlash) {
            startPart = i + 1
            break
          }
          continue
        }
        if (end === -1) {
          // We saw the first non-path separator, mark this as the end of our
          // extension
          matchedSlash = false
          end = i + 1
        }
        if (code === 46 /*.*/) {
          // If this is our first dot, mark it as the start of our extension
          if (startDot === -1) startDot = i
          else if (preDotState !== 1) preDotState = 1
        } else if (startDot !== -1) {
          // We saw a non-dot and non-path separator before our dot, so we should
          // have a good chance at having a non-empty extension
          preDotState = -1
        }
      }
  
      if (
        startDot === -1 ||
        end === -1 ||
        // We saw a non-dot character immediately before the dot
        preDotState === 0 ||
        // The (right-most) trimmed path component is exactly '..'
        (preDotState === 1 && startDot === end - 1 && startDot === startPart + 1)
      ) {
        if (end !== -1) {
          if (startPart === 0 && isAbsolute) ret.base = ret.name = path.slice(1, end)
          else ret.base = ret.name = path.slice(startPart, end)
        }
      } else {
        if (startPart === 0 && isAbsolute) {
          ret.name = path.slice(1, startDot)
          ret.base = path.slice(1, end)
        } else {
          ret.name = path.slice(startPart, startDot)
          ret.base = path.slice(startPart, end)
        }
        ret.ext = path.slice(startDot, end)
      }
  
      if (startPart > 0) ret.dir = path.slice(0, startPart - 1)
      else if (isAbsolute) ret.dir = "/"
  
      return ret
    },
  
    sep: "/",
    delimiter: ":",
    win32: null,
    posix: null
  }
  
  posix.posix = posix
  
  Utils.posix = posix
  
  export { Utils }

stamp
 Disk.node.ts
  const fs = require("fs")
  const path = require("path")
  
  import { particlesTypes } from "../products/particlesTypes"
  
  class Disk {
    static getParticle = () => require("../products/Particle.js").Particle // todo: cleanup
    static rm = (path: particlesTypes.filepath) => fs.unlinkSync(path)
    static getCleanedString = (str: string) => str.replace(/[\,\t\n]/g, " ")
    static makeExecutable = (path: particlesTypes.filepath) => fs.chmodSync(path, 0o755)
    static strCount = (str: string, reg: string) => (str.match(new RegExp(reg, "gi")) || []).length
    static read = (path: particlesTypes.filepath) => {
      try {
        return fs.readFileSync(path, "utf8")
      } catch (err) {
        console.error(`Error reading '$path'`)
        throw err
      }
    }
    static touch = (path: particlesTypes.filepath) => (Disk.exists(path) ? true : Disk.write(path, ""))
    static copy = (source: particlesTypes.filepath, destination: particlesTypes.filepath) => Disk.write(destination, Disk.read(source))
    static mkdir = (path: particlesTypes.filepath) => fs.mkdirSync(path, { recursive: true })
    static getRecursive = (path: particlesTypes.filepath) => Disk.recursiveReaddirSyncSimple(path)
    static readJson = (path: particlesTypes.filepath) => JSON.parse(Disk.read(path))
    static getFileNameWithoutExtension = (filepath: particlesTypes.filepath) => path.parse(filepath).name
    static write = (path: particlesTypes.filepath, content: string) => fs.writeFileSync(path, content, "utf8")
    // Do not overwrite to preserve mtimes for cache
    static writeIfChanged = (filepath: string, content: string) => {
      if (!Disk.exists(filepath) || Disk.read(filepath) !== content) Disk.write(filepath, content)
    }
    static writeJson = (path: particlesTypes.filepath, content: any) => fs.writeFileSync(path, JSON.stringify(content, null, 2), "utf8")
    static createFileIfDoesNotExist = (path: particlesTypes.filepath, initialString = "") => {
      if (!fs.existsSync(path)) Disk.write(path, initialString)
    }
    static exists = (path: particlesTypes.filepath) => fs.existsSync(path)
    static dir = (dir: particlesTypes.absoluteFolderPath) => fs.readdirSync(dir).filter((file: particlesTypes.filepath) => file !== ".DS_Store")
    static getFullPaths = (dir: particlesTypes.absoluteFolderPath) => Disk.dir(dir).map((file: particlesTypes.filepath) => path.join(dir, file))
    static getFiles = (dir: particlesTypes.absoluteFolderPath) => Disk.getFullPaths(dir).filter((file: particlesTypes.filepath) => fs.statSync(file).isFile())
    static getFolders = (dir: particlesTypes.absoluteFolderPath) => Disk.getFullPaths(dir).filter((file: particlesTypes.filepath) => fs.statSync(file).isDirectory())
    static isDir = (path: particlesTypes.absoluteFilePath) => fs.statSync(path).isDirectory()
    static getFileName = (fileName: particlesTypes.filepath) => path.parse(fileName).base
    static append = (path: particlesTypes.filepath, content: string) => fs.appendFileSync(path, content, "utf8")
    static appendAsync = (path: particlesTypes.filepath, content: string, callback: Function) => fs.appendFile(path, content, "utf8", callback)
    static readCsvAsParticles = (path: particlesTypes.filepath) => Disk.getParticle().fromCsv(Disk.read(path))
    static readSsvAsParticles = (path: particlesTypes.filepath) => Disk.getParticle().fromSsv(Disk.read(path))
    static readTsvAsParticles = (path: particlesTypes.filepath) => Disk.getParticle().fromTsv(Disk.read(path))
    static insertIntoFile = (path: particlesTypes.filepath, content: string, delimiter: string) => Disk.write(path, Disk.stickBetween(content, Disk.read(path), delimiter))
    static detectAndReadAsParticles = (path: particlesTypes.filepath) => Disk.detectDelimiterAndReadAsParticles(Disk.read(path))
    static getAllOf = (particle: particlesTypes.particle, prop: string) => particle.filter((particle: particlesTypes.particle) => particle.getAtom(0) === prop)
    static getDelimitedParticlesAsParticles = (particle: particlesTypes.particle, delimiter: string = undefined) => Disk.detectDelimiterAndReadAsParticles(particle.subparticlesToString())
    static sleep = (ms: particlesTypes.int) => new Promise(resolve => setTimeout(resolve, ms))
    static readParticles = (path: particlesTypes.filepath) => new (Disk.getParticle())(Disk.read(path))
    static sizeOf = (path: particlesTypes.filepath) => fs.statSync(path).size
    static stripHtml = (text: string) => (text && text.replace ? text.replace(//gm, "") : text)
    static stripParentheticals = (text: string) => (text && text.replace ? text.replace(/\((?:.|\n)*?\)/gm, "") : text)
    static escape = (str: string) => str.replace(/[-\/\\^$*+?.()|[\]{}]/g, "\\$&")
    static hasLine = (path: particlesTypes.filepath, line: string) => Disk.read(path).includes(line)
    static mv = (source: particlesTypes.filepath, dest: particlesTypes.filepath) => {
      if (Disk.exists(dest) && false) {
        console.log(`${dest} exists. Skipping`)
      } else {
        Disk.write(dest, Disk.read(source))
        Disk.rm(source)
      }
    }
    static stickBetween = (content: string, dest: any, delimiter: string) => {
      const parts = dest.split(delimiter)
      return [parts[0], content, parts[2]].join(delimiter)
    }
    // todo: move to particle base class
    static detectDelimiterAndReadAsParticles = (str: string) => {
      const line1 = str.split("\n")[0]
      const Particle = Disk.getParticle()
      if (line1.includes("\t")) return Particle.fromTsv(str)
      else if (line1.includes(",")) return Particle.fromCsv(str)
      else if (line1.includes("|")) return Particle.fromDelimited(str, "|")
      else if (line1.includes(";")) return Particle.fromDelimited(str, ";")
      // todo: add more robust. align with choose delimiter
      return Particle.fromSsv(str)
    }
    static deleteDuplicates = (particle: particlesTypes.particle, prop1: any, prop2: any, reverse = false) => {
      const map: any = {}
      Disk.getAllOf(particle, prop1).forEach((particle: particlesTypes.particle) => {
        const val = particle.get(prop2)
        console.log(val)
        if (map[val] && reverse) {
          map[val].destroy()
          map[val] = particle
        } else if (map[val]) {
          particle.destroy()
        } else map[val] = particle
      })
    }
    // todo: remove.
    static getLastFolderName = (path: particlesTypes.filepath) => {
      const parts = path.replace(/\/$/, "").split("/")
      const last = parts.pop()
      return fs.statSync(path).isDirectory() ? last : parts.pop()
    }
    static appendUniqueLine = (path: string, line: string) => {
      const file = Disk.read(path)
      if (file.match(new RegExp("^" + Disk.escape(line), "m"))) return true
      const prefix = !file || file.endsWith("\n") ? "" : "\n"
      return Disk.append(path, prefix + line + "\n")
    }
    static move = (particle: particlesTypes.particle, newPosition: particlesTypes.int) => {
      particle.parent.insertLineAndSubparticles(particle.getLine(), particle.subparticlesToString(), newPosition)
      particle.destroy()
    }
    static _getTextUrl = async (url: particlesTypes.url) => {
      // todo: https://visionmedia.github.io/superagent/
      // build well tested version of this.
      // have a mock server returning with all sorts of things.
      const res = await Disk.getUrl(url)
      // todo: leave it up to user to specfiy text ro body
      return res.body || res.text || ""
    }
    static getUrl = async (url: particlesTypes.url) => {
      const superagent = require("superagent")
      const agent = superagent.agent()
      const res = await agent.get(url)
      return res
    }
    static download = async (url: particlesTypes.url, destination: particlesTypes.filepath) => {
      const result = await Disk._getTextUrl(url)
      Disk.write(destination, result)
    }
    static downloadPlain = async (url: particlesTypes.url, destination: particlesTypes.filepath) => {
      const result = await Disk.getUrl(url)
      Disk.write(destination, result.text)
    }
    static downloadJson = async (url: particlesTypes.url, destination: particlesTypes.filepath) => {
      const result = await Disk._getTextUrl(url)
      if (destination) Disk.writeJson(destination, result)
      return result
    }
    static buildMapFrom = (particle: particlesTypes.particle, key: string, value: string) => {
      const map: particlesTypes.stringMap = {}
      particle.forEach((subparticle: particlesTypes.particle) => {
        map[subparticle.get(key)] = subparticle.get(value)
      })
      return map
    }
    static csvToMap = (path: string, columnName: string) => {
      const particle = Disk.readCsvAsParticles(path)
      const map: particlesTypes.stringMap = {}
      particle.forEach((subparticle: particlesTypes.particle) => {
        const key = subparticle.get(columnName)
        map[key] = subparticle.toObject()
      })
      return map
    }
    /**
     * Take an object like {".gitignore" : "ignore/", "parsers/root.parsers": "foo"}
     * and recreate on the filesystem as files and folders. Each key is 1 file.
     * */
    static writeObjectToDisk = (baseFolder: string, obj: any) => {
      Object.keys(obj).forEach(filename => {
        const filePath = path.join(baseFolder, filename)
        if (filename.includes("/")) Disk.mkdir(path.dirname(filePath))
        if (!fs.existsSync(filePath)) Disk.writeIfChanged(filePath, obj[filename])
      })
    }
  
    static recursiveReaddirSyncSimple = (filepath: string) => {
      let list: string[] = []
      const files = fs.readdirSync(filepath)
      let stats
  
      files.forEach(function (file: any) {
        stats = fs.lstatSync(path.join(filepath, file))
        if (stats.isDirectory()) list = list.concat(Disk.recursiveReaddirSyncSimple(path.join(filepath, file)))
        else list.push(path.join(filepath, file))
      })
  
      return list
    }
    static recursiveReaddirSync = (folder: string, callback: any) =>
      fs.readdirSync(folder).forEach((filename: string) => {
        try {
          const fullPath = path.join(folder, filename)
          const isDir = fs.lstatSync(fullPath).isDirectory()
          if (filename.includes("node_modules")) return // Do not recurse into node_modules folders
          if (isDir) Disk.recursiveReaddirSync(fullPath, callback)
          else callback(fullPath)
        } catch (err) {
          // Ignore errors
        }
      })
  }
  
  export { Disk }
  
 Disk.test.ts
  #!/usr/bin/env ts-node
  
  import { particlesTypes } from "../products/particlesTypes"
  const { Disk } = require("../products/Disk.node.js")
  const { TestRacer } = require("../products/TestRacer.js")
  
  const testParticles: particlesTypes.testParticles = {}
  
  testParticles.exists = equal => {
    // Arrange/Act/Assert
    equal(Disk.exists(__filename), true)
  }
  
  /*NODE_JS_ONLY*/ if (!module.parent) TestRacer.testSingleFile(__filename, testParticles)
  
  export { testParticles }
  
 readme.scroll
  title Disk
  
  This folder contains some simple wrappers around `fs`.
  
  It will likely be removed in the future.
